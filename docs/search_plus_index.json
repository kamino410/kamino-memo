{"./":{"url":"./","title":"トップ","keywords":"","body":"かみのの勉強メモです。 目次 数学 素朴集合論 集合 集合の演算 写像 公理的集合論 ZFC公理系 数理論理学 古典命題論理 述語論理 代数学 群 環 剰余環・合同類 オイラー関数とオイラーの定理 線形代数 行列式・対角和 特性多項式 特殊な行列 階数・逆行列 零因子 固有値問題 相似変換 ジョルダン標準形・対角化 線形写像・線形変換 ベクトル空間 内積空間 解析学 関数の極限と連続性 微分と導関数 高階微分 偏微分と偏導関数 多変数関数の極値 双曲線関数 逆三角関数 級数 特殊な級数1 微分方程式1 微分方程式2 畳み込み ラプラス変換 フーリエ変換 凸集合・凸関数 ラグランジュ乗数法 ベクトル解析 ※現状の記事は数学的に色々不正確 内積・外積 三重積 ベクトル値関数 ベクトル場 確率・統計 データの尺度水準 統計量 要約統計量（代表値） 標本空間・事象 確率・確率空間 条件付き確率 確率変数 確率分布 計画数学 グラフ理論 グラフ フロー マトロイド グラフとマトロイド 最小木問題 単一始点最短経路問題 最大流問題 2部グラフのマッチング問題 プログラムにおけるグラフ表現 線形計画法 概要 双対問題 シンプレックス法 2段階法 感度解析と再最適化 線形計画問題を解くプログラム 非線形計画法 無制約最小化問題 等式制約付き最小化問題 一般の制約付き最小化問題 力学 概論 単位系 材料力学 概要 応力・ひずみ 変形特性 単純な梁の弾性応力解析 流体力学 用語 概要 理想流体 数値解析 有限要素法 1次元の重み付き残差法 2次元の重み付き残差法（ラプラス方程式） 数値計算例 制御理論 概論 概要 線形システム 古典制御理論 伝達関数1 伝達関数2 伝達関数3 インパルス応答とステップ応答 過渡応答 1次系の応答 2次系の応答 極・零点と過渡応答 線形システムの安定性 フィードバック制御系の特性 根軌跡 周波数応答 ベクトル軌跡 ボード線図 フィードバック制御系の内部安定性 ナイキストの安定判別法 ゲイン余裕・位相余裕 現代制御理論 状態方程式 状態方程式の解・遷移行列 可制御性・可観測性 可制御正準形・可観測正準形 正準分解 伝達関数行列と実現問題 リアプノフの安定性理論 極配置 オブザーバ 計算機科学 信号処理 概要 連続時間信号のフーリエ解析 離散時間信号のフーリエ解析 アルゴリズム アルゴリズムのコスト ソートアルゴリズム1 ソートアルゴリズム2 ソートアルゴリズム3 貪欲法 動的計画法１ 動的計画法２ ハッシュ法 ヒープ・プライオリティキュー 二分探索木 文字列探索 Union-Find木 2部グラフ判定 状態空間表現 ナイーブな探索 ヒューリスティック探索 ゲーム木の探索 最小木問題 単一始点最短経路問題 最急降下法 ユークリッドの互除法 素数・素因数分解 冪乗 高速フーリエ変換 知識表現 プロダクションシステム フレーム 意味ネットワーク 機械学習 人工知能の歴史 概要 ニューラルネットの基礎 深層学習 読書メモ パターン認識と機械学習1 scikit-learnでMNIST 言語処理 言語処理100本ノック1 言語処理100本ノック2 言語処理100本ノック3 言語処理100本ノック4 グラフィック 3次元コンピューターグラフィックス Zhangの方法によるカメラキャリブレーション ベジェ曲線 3D技術 セキュリティ 暗号技術のすべて読書メモ サイバー攻撃 マルウェア RSA暗号 情報理論 概要 情報量 マルコフ情報源 離散通信路 符号化 ハフマン符号化 誤り検出・訂正符号 アーキテクチャ 浮動小数点数 チューリングマシン ノイマン型コンピューター その他用語 ネットワーク Computer Networks読書メモ 参照モデル トポロジー ベースバンド伝送 IPアドレス ssh 人力飛行機 カメラ計測 翼型のベジェ曲線表現 開発関係 デバイス SteamVR / HTC Vive CPU GPU Prolog 概要 Git 自分用の設定 Python 環境 matplotlib template 行列演算 JUMAN/KNP C/C++ メモ ファイル・文字列 ビット配列を用いた演算 シーケンシャル処理 C# .Netの歴史 GitBook 自分用の設定 Keyboard 自分用の設定 その他 プリミティブ型のサイズ 任意精度演算 ANSIエスケープシーケンス プロセス間通信 参考文献 金子 晃, 『数理基礎論講義 ー論理・集合・位相ー』, サイエンス社, 2010 中島 匠一, 『代数と数論の基礎』, 共立出版株式会社, 2000 江口 正晃/久保 泉/熊原 啓作/小泉 伸, 『基礎微分積分学 第3版』, 学術図書出版社, 2007 宿久 洋/村上 享/原 恭彦, 『確率と統計の基礎Ⅰ 増補改訂版』, ミネルヴァ書房, 2013 繁野 麻衣子, 『ネットワーク最適化とアルゴリズム』, 朝倉書店, 2010 矢部 博, 『工学基礎 最適化とその応用』, 数理工学社, 2006 山下 信雄, 『非線形計画法』, 朝倉書店, 2015 杉山 弘/遠藤 剛/新井 隆景, 『流体力学 第2版』, 森北出版株式会社, 2014 中山 司, 『流れ解析のための有限要素法入門』, 東京大学出版会, 2008 杉江 俊治/藤田 政之, 『フィードバック制御入門』, コロナ社, 1999 吉川 恒夫/井村 順一, 『現代制御論』, コロナ社, 2014 宇野 俊夫, 『独習 TCP/IP～IPv6対応～』, 翔泳社, 2010 秋葉 拓哉/岩田 陽一/北川 宣稔, 『プログラミングコンテストチャレンジブック 第2版』, マイナビ出版, 2012 IPUSIRON, 『暗号技術のすべて』, 株式会社翔泳社, 2017 J. Glenn Brookshear (神林 靖/長尾 高宏 訳), 『入門コンピュータ科学～ITを支える技術と理論の基礎知識～』, アスキー・メディアワークス, 2014 近藤 嘉雪, 『定本 Cプログラマのためのアルゴリズムとデータ構造』, SB Creative, 1998 "},"mathematics/native_set_theory/set.html":{"url":"mathematics/native_set_theory/set.html","title":"集合","keywords":"","body":"集合（set） 定義 次の条件を満たす「ものの集まり」を集合という。 任意のものについて、それがそのあつまりに属するか否かが明確である その集まりに属する任意の2つのもの（元・要素／element）x,y について、x=y であるか否かが明確である 公理系 実際に集合に関する理論を組み立てる際、上記の定義だけでは多くの問題が生じる。 典型的な例としてラッセルのパラドックスが有名である。 ラッセルのパラドックス 集合は「自分自身を内包しないもの」というルールを定めて A={X | X∉X} の性質があるものを集合として認めることにする。 ここで集合自身は集合のルールを満たすのか（自身を内包するのか／A∈A？）を考える。 A∈A とすると X∉X が集合として認められる条件なので A は集合ではないことになる（矛盾） A∉A とすると A も集合として認められるので A∈A が成立する（矛盾） この問題の本質は、「すべての集合を含むような集合」は集合の公理を満たさないという点である。 数学においては 集合の公理の一部しか満たさないものとして、クラス（class）・族（family）などの呼び方で区別する 議論に際して十分大きな集合（ユニバース）U を定義して、登場する集合は U の部分集合として表現する などの方法でこのパラドックスを回避することがある。 このように数学的な基礎理論を固める必要性が示唆されたことを受けて、上記の条件にいくつかの公理を追加して集合の定義とする公理的集合論が存在する。 一般によく用いられる公理系としてZFC公理系がある。 逆に公理的集合論と区別して、上記の定義のみに基づく議論を素朴集合論という。 集合の表現方法 内包的表現（intensional expression） 集合の元の性質を記述し、それを満たす元を集めたものを集合として記述する方法 外延的表現（extensional expression） 集合の元を実際に書き並べる記述法 元が無限個のときには厳密さに欠ける表現となる "},"mathematics/native_set_theory/operations.html":{"url":"mathematics/native_set_theory/operations.html","title":"集合の演算","keywords":"","body":"素朴集合論の集合演算（native set theory） 集合の定義に基づく、単なるものの集まりとしての集合の性質について述べられたものである。 基本となる記号 集合 A,B,⋯ 要素 x,y,⋯ 包含記号 A⊂B 集合論の部分集合の定義は A⊂B⇔∀x(x∈A⇒x∈B) とするのが一般的 A⊊B は真部分集合と呼ぶことで区別する また、暗黙的に次のような記号が使われることが多い。 整数（integers）の集合 Z 有理数（rational numbers）の集合 Q 実数（real numbers）の集合 R 複素数（complex numbers）の集合 C 等号の公理 一般に等号 = が満たす次のような性質が集合においても成立することを前提として議論を進める。 厳密な定義の例はZFC公理系へ。 反射律 A=A 対称律 A=B⇒B=A 推移律 (A=B∧B=C)⇒A=C 和集合・共通部分（積集合）（union / intersection） 定義 和集合 A∪B:={x | x∈A∨x∈B} 共通部分（積集合）A∩B:={x | x∈A∧x∈B} 性質 A∪A=A, A∩A=A（冪等律） A∪B=B∪A, A∩B=B∩A（可換律） (A∪B)∪C=A∪(B∪C), (A∩B)∩C=A∩(B∩C)（結合律） (A∪B)∩C=(A∩C)∪(B∩C), (A∩B)∪C=(A∪C)∩(B∪C)（分配律） A∩(A∪B)=A, A∪(A∩B)=A（吸収律） A∪B⊃A, A∪B⊃B (C⊃A∧C⊃B)→C⊃A∪B A∩B⊂A, A∩B⊂B (C⊂A∧C⊂B)→C⊂A∩B A⊂B→((A∩B=A)∧(A∪B=B)) 空集合（empty set） 定義 ∅={} 性質 どのような集合にも属する ∀A(∅∈A) ∀A(A∩∅=∅) ∀A(A∪∅=A) 補集合（complement） 定義 全体集合を X として Ac:={x∈X | x∉A} 性質 A∩Ac=∅ A∪Ac=X (A∪B)c=Ac∩Bc, (A∩B)c=Ac∪Bc（ド・モルガンの法則） 集合差（difference） 定義 A∖B:={x | x∈A∧x∉B} 性質 全体集合を X として Ac=X∖A A∖B=A∩Bc 対称差（symmetric difference） 定義 A⊖B:=(A∖B)∪(B∖A) 直積／デカルト積（direct product / Cartesian product） 定義 A×B:={(x,y) | x∈A∧y∈B} "},"mathematics/native_set_theory/mapping.html":{"url":"mathematics/native_set_theory/mapping.html","title":"写像","keywords":"","body":"写像（mapping） 定義 集合 X,Y があり、集合 X の各元について対応するただ１つの Y の元が定まっているとき、この対応を X から Y への写像 fという。 このときの X を始集合（源/source）、Y を終集合（行き先/target/destination）と呼ぶ。 特に終集合が数であるとき f を関数と呼ぶ。 また、f が部分集合 W⊂X についてのみ定義されているとき W を写像の定義域と呼ぶ。 写像の表現方法 内包的表現（intensional expression） x∈X に対応する行き先 y∈Y を式などで記述する方法 外延的表現（extensional expression） x∈X に対応する行き先 y∈Y を一組ずつ記述する方法 元が無限個のときには厳密さに欠ける表現となる グラフ（graph） 写像 f:X→Y について、直積 X×Y の部分集合 Γf:={(x,f(s)) | x∈X}⊂X×Y を f のグラフという。 像・逆像（image / inverse image） 写像 f:X→Y があるとき、 A⊂X の各元の行き先の集合 f(A) を A の像と呼ぶ。 f(A):={f(x) | x∈A}={y∈Y | ∃x∈X(y=f(x))} また、B⊂Y の各元を行き先に持つ X の元の集合 f−1(B) を B の逆像と呼ぶ。 f−1(B):={x∈X | f(x)∈B} 写像の分類 全射 写像 f:X→Y があるとき、すべての x∈X に対して対応する x∈X が存在するとき、f は全射であるという。 ∀y∈Y(∃x∈X(y=f(x))) 単射 写像 f:X→Y があるとき、すべての x∈X がそれぞれ異なる y∈Y に対応するとき、f は単射であるという。 ∀x1,x2∈X((f(x1)=f(x2))→(x1=x2)) 全単射 写像 f:X→Y が全射かつ単射であるとき、f は全単射であるという。 "},"mathematics/axiomatic_set_theory/zfc_set_theory.html":{"url":"mathematics/axiomatic_set_theory/zfc_set_theory.html","title":"ZFC公理系","keywords":"","body":"ZFC公理系 集合で述べたような集合の定義にツェルメロ＝フレンケルの公理系（ZF）と選択公理（C）を加えた公理系。 集合の公理系として現在最も一般的である。 公理 ZF1. 空集合の存在 元を1つも含まない集合が存在する、という公理。 ZF2と併せると空集合はただ一つに定まるため、これを ∅ と表す。 ∃x∀u¬(u∈x) ZF2. 外延性公理 同じ元から成る集合は等しい、という公理。 ∀x∀y(∀u(u∈x≡u∈y)→x=y) ZF3. 非順序対の存在 任意の2つの元 x,y のみを元とする集合 {x,y} が存在する、という公理。 このような集合を対という。 この公理を用いて非順序対を定義できる。 ∀x∀y∃z∀u(u∈z≡(u=x∨u=y)) ZF4. 和集合の公理 集合を元とする任意の集合 x があり、x に含まれる集合のいずれか（ v ）に要素 u が含まれているとする。 このときすべての u を含むような集合 y （つまり v の和集合）が存在する、という公理。 ∀x∃y∀u(u∈y≡∃v(u∈v∧v∈x)) ZF5. 冪集合の公理 集合 x のすべての部分集合を要素とするような集合 y が存在する、という公理。 ∀x∃y∀u(u∈y≡u⊂x) ZF6. 置換公理 任意の論理式 A(u,v) を u→v の射影を行う関数であると見立てる。 この関数が単射であるとき、集合 x の各要素の写像の集まり y も集合である、という公理。 ∀u∀v∀ω(A(u,v)∧A(u,ω)→v=ω)→∀x∃y∀v(v∈y≡∃u(u∈x∧A(u,v))) ZF7. 正則性公理 論理式 A(x) が真になる集合 x が存在するなら、x∋x1∋x2∋⋯∋x′ となる順序が最小の x′ が存在する、という公理。 ∃xA(x)→∃x(A(x)∧¬∃y(A(y)∧y∈x)) また同値な表現である以下の論理式が用いられる事がある。 ∀x(∀y(y∈x→A(y))→∀xA(x)) ∀x(x≠∅→∀x∃y(y∈x∧x∩y=∅)) ZF8. 無限公理 無限集合が1つは存在することを保証する公理。 ∃(∃u(u∈x)∧∀u(u∈x→∃v(v∈x∧u⊂v∧¬v=u))) 素朴に書き換えると ∃x(x≠∅∧(∀u∈x∃v∈x(u⊊v))) 選択公理 元が互いに交わらず空集合を含まない集合 x について、x に含まれる集合から要素を1つずつ取り出したものも集合である、という公理。  ∀x[∅∉x∧∀u∀v((u∈x∧v∈x∧¬u=v)→u∩v=∅) →∃y(y⊂σ(x)∧∀u(u∈x→∃z(z∈u∧z∈y∧∀w(w∈u∧w∈y→w=z))))] "},"mathematics/mathematical_logic/classical_propositional_logic.html":{"url":"mathematics/mathematical_logic/classical_propositional_logic.html","title":"古典命題論理","keywords":"","body":"古典命題論理（classical propositional logic） 真偽が定まる記述のことを命題（proposition）という。 古典論理学は命題間の関係を記述する分野である。 命題変数の関係の記述には命題論理式（論理式）を用いる。 命題論理式の構成要素 命題定数 「真である」という命題を ⊤、「偽である」という命題を ⊥ と表す。 命題変数 任意の命題を代表する記号を命題変数という。 命題演算子 p∨q（論理和） p,q いずれもが偽のとき p∨q は偽、それ以外は真 p∧q（論理積） p,q いずれもが真のとき p∧q は真、それ以外は偽 ¬p（否定） p が真（偽）なら ¬p は偽（真） p→q（含意） p が真で q が偽のとき p→q は偽、それ以外は真 p≡q（同値） p,q の真偽が一致するとき真、それ以外は偽 論理式の分類 恒真式（tautology） 論理式に含まれる命題変数がどのような値を取っても常に値が真になる論理式。A が恒真式であることを ⊨A と表す。 充足可能（satisfiable） 論理式に含まれる命題変数の値をうまく選べば値が真になる論理式。 充足不可能（unsatisfiable） 論理式に含まれる命題変数がどのような値を取っても常に値が偽になる論理式。 恒真式の例 任意の命題に対して成立する恒真式は、与えられた命題の真偽を判定する際に定理として利用できる。 A∧A≡A, A∨A≡A（冪等性） (A∧B)∧C≡A∧(B∧C)(A∨B)∨C≡A∨(B∨C)（結合律） A∧B≡B∧A, A∨B≡B∨A（交換律） A∧(A∨B)≡A, A∨(A∧B)≡A（吸収律） A∧(B∧C)≡(A∧B)∨(A∧C)A∨(B∧C)≡(A∨B)∧(A∨C)（分配律） ¬¬A≡A（2重否定律） ¬(A∨B)≡¬A∧¬B¬(A∧B)≡¬A∨¬B（ド・モルガンの法則） A→B≡¬A∨B A∧¬A≡⊥, A∨¬A≡⊤（排中律） A∨⊥≡A, A∨⊤≡⊤ A∧⊤≡A, A∧⊥≡⊥ A∧(A→B)→B（前件肯定） ¬B∧(A→B)→¬A（後件否定） (A≡B)≡((A→B)∧(B→A)) 双対原理（duality principle） 次の組み合わせはそれぞれ双対の関係であるという。 ∧,∨ ⊤,⊥ ¬A,A 上記以外の命題定数・演算子を含まない論理式を A とすると、それらを双対で置き換えた論理式 A∗ を双対式という。 双対式について成立する次の定理を双対原理という。 ⊨(A→B)→(B∗→A∗) ⊨(A≡B)→(A∗≡B∗) "},"mathematics/mathematical_logic/predicate_logic.html":{"url":"mathematics/mathematical_logic/predicate_logic.html","title":"述語論理","keywords":"","body":"述語論理（predicate logic） 変数を含んだ命題のことを述語という。 述語はそのままでは真偽が定まっていないが、変数の値が決まると通常の命題になり真偽が定まる。 述語の論理を扱う体系を述語論理という。 一階述語論理（first-order predicate logic） 最も単純な述語論理の体系。 言語（language） 対象領域 D 論理演算子 ∨, ∧, →, ¬ 限定子 ∀, ∃ 対象変数 x, y, … 対象定数 c, d, … 関数記号 f, g, … 述語記号 P, Q, … 区切り記号 \",\" () ※ここでいう言語とは、記号を利用して何かを記述する体系を指している。 項（term） 項は次のように帰納的に定義されるもののことである。 対象変数、対象定数は項である f が m 変数の関数記号であり、t1,⋯,tm が項なら、f(t1,⋯,tm) もまた項である 論理式 一階述語論理における論理式は次のように帰納的に定義される。 P が n 変数の述語記号で、t1,⋯,tn が項なら、P(t1,⋯,tn) は論理式である（これらを原子論理式（atomic formula）または素式（prime formula）と呼ぶ） A,B がともに論理式なら、これらを論理演算子で結合したものすなわち (A∧B)、(A∨B)、(A→B)、(¬A) はいずれも論理式である A が論理式で x が対象変数なら、これらを限定子で結合したものすなわち (∀xA)、(∃xA) はいずれも論理式である 自由変数・束縛変数 限定子と共に用いられる対象変数 ∀x,∃x を束縛変数（bound variable）、そうでないものを自由変数（free variable）という。 代入 自由変数を項で置き換えることを x への t の代入・x の t による置換と呼び、A[t/x] と表す。 厳密には次のように帰納的に定義される。 s を項とするとき、s におけるすべての x へ t を代入して得られる項を s[t/x] とする A が原子論理式 P(s1,⋯,sn) のとき、A[t/x]=P(s1[t/x],⋯,sn[t/x]) とする A[t/x],B[t/x] を論理演算子で結合したものは C[t/x]=A[t/x]∗B[t/x] とする A が ∀zB,∃B なら、 z=x のときは A[tx]=A（そのまま）とする z≠x のときは z が t に出現しなければそれぞれ A[t/x]=∀z(B[t/x]), ∃z(B[t/x]) とし、z が t に出現するときは予め A の中の z を A にも t にも現れない対象変数 u で書き換えそれぞれ ∀u((B[u/z])[t/x]), ∃u((B[u/z])[t/x]) とする 冠頭標準形 論理式の同値変換により限定子を前に括りだしたものを冠頭標準形という。 (∀or∃)x1⋯(∀or∃)xnP(x1,⋯,xn) 節形式 論理式の同値変換により冠頭標準形の限定子の後の論理式を次の形式にしたものを節形式という。 原子論理式または原子論理式の否定をリテラル（literal）という リテラルを選言 ∨ で結んだものを節（clause）という 節を連言 ∧ で結んだものの外側に限定子を付けたものを節形式（clause form）という（連言で結んだ部分を母式という） (∀or∃)x1⋯(∀or∃)xn(C1∧⋯∧Cn) ※ Ci は節 スコーレム標準形 節形式の存在記号による束縛変数を削除したものをスコーレム標準形という。 スコーレム関数は新しい変数を導入するため論理式の等価性は失われる。 しかし、変換後が充足可能なら変換前も充足可能という充足可能性は等価のままである（つまり恒偽であるかは保たれる）。 ∀x1⋯∀xn(C1∧⋯∧Cn) スコーレム標準形への変換は次のように行う。 ∃xP(x) は P(a) へ変換する ∀x∃y∃zP(x,y,z) は ∀xP(x,y,f(x,y)) へ変換する（f を スコーレム関数と呼ぶ） "},"mathematics/algebra/group.html":{"url":"mathematics/algebra/group.html","title":"群","keywords":"","body":"群（group） 定義 ある集合 G について演算 ∗ が定義されているとする。これらが次の公理を満たすとき、(G,∗) は群（ぐん）であるという。 群の公理 σ,τ,ρ∈G としたとき次の条件を満たす。 σ∗(τ∗ρ)=(σ∗τ)∗ρ （結合律） ϵ∗σ=σ∗ϵ=σ を満たす ϵ∈G が存在する（単位元の存在） σ∗ξ=ξ∗σ=ϵ を満たす ξ∈G が存在する（逆元の存在） 逆元は σ−1 と表現されることが多い。 性質 群の単位元・逆元は次の性質を満たす。 単位元は唯1つに定まる ある元に対する逆元は唯1つに定まる また任意の σ,τ∈G と m,n∈Z に対して次の性質を満たす。 (σ−1)−1=σ (σ∗τ)−1=τ−1∗σ−1 σ−n=(σ−1)n=(σn)−1 σn∗σm=σn+m 位数（order） 群 G の元の個数（正確には G の濃度）を群 G の位数といい、 |G| で表す。 位数が有限の群を有限群（finite group）といい、位数が無限の群を無限群（infinite gorup）と呼ぶ。 単位群（unit group） G=ϵ において演算 ∗ が ϵ∗ϵ=ϵ で定義されるとき、これを単位群という。 単位群は位数1の群であり、また位数1の群は単位群しか存在しない。 可換群／アーベル群（commutative group） 集合 G が次の条件を満たすとき、G は可換群であるという。 G は群である すべての σ,τ∈G について σ∗τ=τ∗σ が成立する 可換群を利用して楕円関数などの理論を打ち立てたニールス・アーベルの名前を取ってアーベル群と呼ぶことがある。 "},"mathematics/algebra/ring.html":{"url":"mathematics/algebra/ring.html","title":"環","keywords":"","body":"環（ring） 定義 ある集合 R について加法（+）・乗法（×）が定義されているとする。 これらが次の公理を満たすとき、(R,+,×) は環（かん）であるという。 環の公理 a,b,c∈R としたとき次の条件を満たす。 a+b∈R （加法に関して閉じている） (a+b)+c=a+(b+c) （加法の結合律） a+b=b+a （加法の可換律） a+δ=δ+a=a を満たす δ∈R が存在する（加法単位元／零元の存在） a+x=δ を満たす x∈R が存在する（逆元の存在） a×b∈R （乗法に関して閉じている） (a×b)×c=a×(b×c) （乗法の結合律） a×ϵ=ϵ×a=a を満たす ϵ∈R が存在する（乗法に関する単位元の存在） (a+b)×c=a×c+b×c を満たす（右分配律） a×(b+c)=a×b+a×c を満たす（左分配律） ※文献によっては「乗法に関する単位元を要求しない」など異なる定義をすることがある。 ※吸収元の存在はこれらの条件から導けるため記述されない。 零環（zero ring） R={0} を零環という。 零環も上記の環の定義を満たしていることがわかる。 可換環（commutative ring） 集合 R が次の条件を満たすとき、R は可換環であるという。 R は環である すべての a,b∈R について a×b=b×a が成立する 実数や複素数は可換環だが、行列や四元数は可換環ではない環である。 部分環（subring） 集合 R の部分集合 W が次の条件を満たすとき、W は R の部分環であるという。 a,b∈W ⇒ a+b∈W a∈W ⇒ −a∈W a,b∈W ⇒ a×b∈W 1R∈W （1Rは R の単位元） この条件から、加減乗について閉じており、単位元を含むことが保証されるので W も環であることがわかる。 "},"mathematics/algebra/residue_ring.html":{"url":"mathematics/algebra/residue_ring.html","title":"剰余環・合同類","keywords":"","body":"剰余環・合同類 合同類（congruent class） 定義 整数 a,t∈Z 、自然数 m∈N に関して {a+mt | t∈Z} を a の定める m を法とする合同類といい、a(mod m) または a+mZ などと表す。 また x,y∈a(mod m) の関係にあるとき、x,y は合同であるという。 この『合同』とは整数上のある同値関係を定義したものであると言える。 法 m が定まれば整数全体は m 個の剰余類に分割される。 この剰余類をまとめて Z/mZ と表記する。 Z/mZ は剰余環としての性質を満たす。 "},"mathematics/algebra/eulers_theorem.html":{"url":"mathematics/algebra/eulers_theorem.html","title":"オイラー関数とオイラーの定理","keywords":"","body":"オイラー関数とオイラーの定理（Euler's totient function / theorem） オイラーのトーシェント関数・オイラーのφ関数（Euler's totient / phi function） ϕ(n) を n までの自然数のうち n と互いに素であるものの個数としたとき、これをオイラーのトーシェント関数（オイラーのφ関数・オイラー関数）と呼ぶ。 性質 m,n が互いに素な自然数であるとき ϕ(mn)=ϕ(m)ϕ(n) 素数 p について ϕ(pn)=pn−pn−1 pn 以下の p の倍数は pn−1 個あるため 自然数 n が Πkj=1Pmjj と素因数分解されるとき ϕ(p)=nΠkj=1(1−1/pj) オイラーの定理 n 以下で n と互いに素な自然数 a について aϕ(n)≡1  (mod n) が成立する。 法 n に関する合同 ある整数 a,b について a mod n=b mod n であるとき、a,b は法 n に関して合同であるといい、a≡b  (mod n) と表す。 "},"mathematics/linear_algebra/determinant.html":{"url":"mathematics/linear_algebra/determinant.html","title":"行列式・対角和","keywords":"","body":"行列式（determinant） 定義 正方行列に対して次の式で定義される値を行列式という。 ∑ϕ∈Ssgn(ϕ)x1ϕ(1)x2ϕ(2)…xnϕ(n) この式は  nPn(=n!)の順列から1つ取り出す 取り出した順列に基づいて各列の異なる行の要素同士を掛け合わせる (1…n)の要素同士を入れ替えて取り出した順列をつくるときの入れ替え操作の回数の偶奇を調べ、正負を決める という操作を繰り返し、それらを足し合わせたものになっている。 幾何的には各列ベクトルが張る体積要素（2次元なら平行四辺形、3次元なら平衡六面体）の大きさを示すものとして理解できる。 性質 行列式は次のような性質を満たす。 その1 行・列に対する対称性 |At|=|A| その2 n重線型性 ∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣a1⋮a′i⋮an∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣ + ∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣a1⋮a′′i⋮an∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣ = ∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣a1⋮a′i+a′′i⋮an∣∣ ∣ ∣ ∣ ∣ ∣ ∣∣ |kA|=k|A|   (k∈R) その3 行・列ベクトルを入れ替えると行列式の符号が逆転する（交代性） ∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣a1⋮ai⋮aj⋮an∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣ = − ∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣a1⋮aj⋮ai⋮an∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣ その4 乗算 |AB|=|A|⋅|B| |An|=|A|n 対角和 n 次正方行列の対角成分の和を対角和と呼び、次のように表す。 trA=n∑i=0aii "},"mathematics/linear_algebra/characteristic_polynomial.html":{"url":"mathematics/linear_algebra/characteristic_polynomial.html","title":"特性多項式","keywords":"","body":"特性多項式 定義 正方行列 A に対して定義される次のような多項式を行列 A の特性多項式・固有多項式と呼ぶ。 Φ(λ)=det(λI−A) 特性多項式は行列の性質と密接に関係しており、固有値問題で利用されるほか、以下に示すケーリー・ハミルトンの定理が種々の定理の証明に利用される。 ケーリー・ハミルトンの定理（Cayley-Hamilton theorem） 行列 A の特性多項式が Φ(A) であるとき、 Φ(A)=An+αn−1An−1+⋯+α1A+α0I=0 を満たす。 ケーリー・ハミルトンの定理による次数下げ ケーリーハミルトンの定理の利用例の1つ。 上記の式を次のように変形する。 An=−αn−1An−1−⋯−α1A−α0I この式を繰り返し適用することで、任意の n 次正方行列の多項式は A0∼An−1 の一次多項式まで次数を下げることができる。 "},"mathematics/linear_algebra/characteristic_matrix.html":{"url":"mathematics/linear_algebra/characteristic_matrix.html","title":"特殊な行列","keywords":"","body":"特殊な行列 実行列・エルミート行列（real-valued matrix / Hermitian matrix） 成分が実数値を取る行列を実行列、複素数値を取る行列をエルミート行列という。 正方行列（square matrix） サイズが n×n である行列。 ∣∣ ∣ ∣∣a11⋯a1n⋮⋱⋮an1⋯ann∣∣ ∣ ∣∣ 対称行列（symmetric matrix） A=At を満たす行列。 ∣∣ ∣ ∣∣a11⋯a1n⋮⋱⋮an1⋯ann∣∣ ∣ ∣∣    (aij=aji) aij=aji 対角行列（diagonal matrix） 正方行列かつ対角成分以外が0である行列。 ∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣a110⋯⋯00a22⋱⋱⋮⋮⋱⋱⋱⋮⋮⋱⋱an−1,n−100⋯⋯0ann∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣ aij={αij(i=j)0else 三角行列（triangular matrix） 正方行列かつ対角成分より右上もしくは左下側の成分がすべて0の行列。 ∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣a11a12⋯⋯a1n0a22⋱⋱⋮⋮⋱⋱⋱⋮⋮⋱⋱an−1,n−1an−1,n0⋯⋯0ann∣∣ ∣ ∣ ∣ ∣ ∣ ∣ ∣∣ aij={αij(i≤j)0else 正則行列（regular matrix） 全ての列・行ベクトルが一次独立（線形独立）な行列。同値の条件として、逆行列が存在する行列でもある。詳しい性質については階数・逆行列を参照。 A−1A=I 直交行列（orthogonal matrix） 転置行列と逆行列が等しくなる正方行列。 AT=A−1 次のような性質がある。 行列式は ±1（1=det(E)=det(AAT)=det(A2)2） 各行（列）ベクトルは n 次ベクトル空間の正規直交基底 正定値行列・負定値行列（positive definite matrix / negative definite matrix） 実正方行列かつ 0)\">∀v∈Rn (vTAv>0) を満たす行列を正定値行列という。 エルミート正方行列については 0 \\wedge \\mathrm{Im}(v^* A v) = 0)\">∀v∈Rn(Re(v∗Av)>0∧Im(v∗Av)=0) を満たすものをいう（ただし v∗ は v の共軛転置行列）。 また不等式が ≥ になるとき、半正定値行列（positive-semidefinite matrix）・非負定値行列（nonnegative-definite matrix）という。 不等号が逆転したものを負定値業列・半不定地行列・非正定値行列という。 "},"mathematics/linear_algebra/inverse_matrix.html":{"url":"mathematics/linear_algebra/inverse_matrix.html","title":"階数・逆行列","keywords":"","body":"階数（rank） 行列の階数の定義は、次の同値な条件のいずれかで示されることが多い。 列ベクトルの線型独立なものの最大個数 行ベクトルの線型独立なものの最大個数 行列に左基本変形（行基本変換）を施したとき0ベクトルでない行の個数 行列に右基本変形（列基本変換）を施したとき0ベクトルでない列の個数 性質 m×nの行列Aの階数をrank(A)とする。 A≤min(m,n) A=min(m,n) のとき フルランク であるという Amin(m,n) のとき ランク落ち・ランク不足 という rank(A)=rank(At) rank(A+B)≤rank(A)+rank(B) rank(AB)≤min(rank(A),rank(B)) 逆行列（inverse matrix） n 次正方行列 A に対して AB=I=BA を満たす行列 B を逆行列といい、A−1 と表現する。 逆行列が存在する条件 逆行列が存在するかは次の同値な条件によって示される。 AB=I なる B が存在する BA=I なる B が存在する A,B は正則行列である rank(A)=n A が左基本変形（行基本変換）のみで単位行列に変換できる 行ベクトルが線形独立 A が右基本変形（列基本変換）のみで単位行列に変換できる 列ベクトルが線形独立 detA≠0 A の固有値がすべて非零 性質 detA=detA−1 (A−1)−1=A (AB)−1=B−1A−1 "},"mathematics/linear_algebra/zero_divisor.html":{"url":"mathematics/linear_algebra/zero_divisor.html","title":"零因子","keywords":"","body":"零因子（zero divisor） 行列における零因子は A≠0, B≠0 において AB=O になるものとして定義される。 A を B の左零因子、B を A の右零因子という。 性質 零因子 A,B に逆行列は存在しない 零因子 A,B の行列式は 0 になる A−1AB=0⇒B=0 となってしまうため逆行列が存在すると零因子の定義から外れる "},"mathematics/linear_algebra/eigenvalue.html":{"url":"mathematics/linear_algebra/eigenvalue.html","title":"固有値問題","keywords":"","body":"固有値問題（eigen） 固有値・固有ベクトル・固有空間（eigenvalue, eigenvector） 任意の正方行列 A に対して Ax=λx   (x≠0) を満たすような λ,x の組み合わせ（固有対）を求める問題を固有値問題という。 またこのときの λ を固有値、x を λ に対する固有ベクトルといい、固有ベクトルが張る V の部分空間 W(λ;T)={u∈V | Tu=λu} を固有値 λ の固有空間という。 固有ベクトルは変換行列 A を通してもベクトルの方向が変わらないようなベクトルのことであり、固有値は固有ベクトルの長さがもとのベクトルの何倍になるかを示している。 なお、エルミート行列の固有値もすべて実数になることが知られている。 求め方 Ax=λx(A−λI)x=0 ここで (A−λI) が正則であるとすれば、 (A−λI)−1(A−λI)x=0x=0 となり、固有対が存在しないことになる。ここから次の定理が導かれる。 det[A−λI]=0　⇔　固有対が存在する すなわち A の特性方程式を解くことで固有値が得られる。 固有値が得られればそこから固有空間も導出することができる。 重複度・固有値の数 特性方程式に重解が含まれるとき、重複した解の数を d として、対応する固有対を重複度 d の固有対 という。たとえば2重解に対応する固有対の重複度は2である。 重複度を考慮した固有対の数は行列の次数 n と等しくなる。 固有ベクトルの一次独立性 任意の行列 A の固有対は次の定理を満たす（一次独立の定義と特性方程式を合わせれば容易に証明できる）。 異なる固有値の固有ベクトルは互いに一次独立である 対角和・行列式と固有値 ジョルダン標準形を考慮すれば次のような関係が導ける。 trA=n∑i=1λidetA=n∏i=1λi "},"mathematics/linear_algebra/similarity_transformation.html":{"url":"mathematics/linear_algebra/similarity_transformation.html","title":"相似変換","keywords":"","body":"相似変換（similarity_transformation） 任意の正方行列 A,B について B=P−1AP を満たすとき、A と B は相似（similar）であるという。 また、変換行列 P を用いたこの変換を P に関する相似変換と呼ぶ。 性質 相似変換は次のような同値関係の公理を満たす。 A と A は相似である（反射律） A と B が相似　⇔　B と A が相似（対象律） A と B が相似かつ A と C が相似　⇒　A と C は相似（推移律） また相似変換では行列の様々な性質が保存される。 階数（rank） 対角和（trace） 行列式 特性多項式 固有値（固有ベクトルは一般に保存されない） 互いに相似な行列は同じ線形写像を異なる基底に関して記述したものと解釈できる。 "},"mathematics/linear_algebra/diagonalization.html":{"url":"mathematics/linear_algebra/diagonalization.html","title":"ジョルダン標準形・対角化","keywords":"","body":"ジョルダン標準形（Jordan normal form）・対角化（diagonalization） 以下、実正方行列について言及する。 相似変換の項目で述べたように、正方行列の間には同値関係（相似）を定義でき、相似な行列の間では階数・行列式・固有値などが保存される。 そのため、相似な行列の集合の中でも簡単な表現を標準形として定義しておけば、標準形について検証するだけでそれに相似な行列全体の議論に帰着でき便利である。 このような標準形としてジョルダン標準形・対角行列がよく用いられる。 ジョルダン標準形 任意の n 次正方行列 A の固有値とその重複度が λi,ki   (i=1∼n) であるとき、次のような行列と相似になる。 Ji=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣λi10λi1λi⋱⋱10λi⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦   (k×k)J=⎡⎢ ⎢⎣J10⋱0Jn⎤⎥ ⎥⎦ この行列をジョルダン標準形という。 任意の正方行列は固有値の並び順の任意性を除けばただ1つのジョルダン標準形と相似である。 対角化 B が対角行列になるような相似変換を施すことを特に対角化という。 対角行列は累乗の計算が簡単に行えるため、様々な場面で対角化が利用される。 対角化可能性 n 次実正方行列 A の相異なる実固有値を λ1,⋯,λr としたとき、次の定理が成立する。 ∑ri=1dim(W(λi;A))=n⇔　dim(W(λi;A))=λi の重複度⇔　A は対角化可能 2つ目の条件が同値になるのは、固有ベクトルの自由度が対応する固有値の重複度を超えることは原理的にありえないため（dim(W(λi;A))≤λi の重複度）。 手順 n 次正方行列 A の固有値がすべて異なる場合は簡単に対角化と変換行列を得られる。 n 次正方行列 A の固有値がすべて異なる⇔　A の固有ベクトルを並べて変換行列 P とすると得られる相似な行列は A の固有値を対角成分に持つ対角行列になる 重複度2以上の固有値を含む場合はそれぞれの固有値を求め、上記の式に従って固有空間の次元を確認する。 対角化が可能な場合は次の定理が成り立つ。 n 次正方行列 A が対角化可能である　⇔　A の1次独立な固有ベクトルを並べて変換行列 P とすると得られる相似な行列は A の固有値を対角成分に持つ対角行列になる（固有ベクトルと対応する順に固有値が並ぶ） 対称行列の対角化 対称行列が対角化可能であるとき、変換行列 P は直交行列になることが知られている。 固有値がすべて異なる場合は通常の対角化の際に固有ベクトルを正規化するだけで直交行列 P が得られる。 一方、固有値に重複がある場合はグラムシュミットの正規直交化法などを用いて固有ベクトルの集まりから正規直交基底の組を導出する必要がある。 "},"mathematics/linear_algebra/linear_mapping.html":{"url":"mathematics/linear_algebra/linear_mapping.html","title":"線形写像・線形変換","keywords":"","body":"線形写像・線形変換（linear mapping / linear transformation） 定義 U,V を K 上のベクトル空間とする。 U 上のベクトルと V 上のベクトルを対応させる写像 f:U→V,f(x)=y について次の条件を満たすとき、f は U から V への線形写像であるという（写像の定義）。 f(x1+x2)=f(x1)+f(x2)   (x1,x2∈U) f(kx)=kf(x)   (x∈U,k∈K) 特に同じベクトル空間 U から U への線形写像を線形変換という。 定義から明らかであるように V は U の部分空間である。 U の次元を n、V の次元を mとするとき、線型写像は m×n の行列 A を用いて f(x)=Ax と表される。 像と核（image / kernel） 線形写像 f:U→V に対して U 全体の像 f(U) を f の像といい Im(f)={y | y=f(x), x∈U} と表す。 また、0V の原像 f−1(0V) を f の核といい Ker(f)={x | x∈U, f(x)=0V} と表す。 つまり写像によって原点に移されるようなベクトルの集まりを示している。 線形写像の定義より Im(f), Ker(f) は共に U の部分空間である。 また定義より f(Im(f))⊂V, f(Ker(f))⊂V となるため、Im(f), Ker(f) は共に f の不変部分空間である。 階数と退化次数 線形写像 f:U→V の像 Im(f) の次元を f の階数といい rank(f)=dim(Im(f))=dim(V) と表す。 また、f の核 Ker(f) の次元を f の退化次数といい null(f)=dim(Ker(f)) と表す。 直観的には、写像によって dim(Ker(f)) 次元の部分空間 Ker(f) が 0 次元である原点に「つぶされている」つまり退化次数の分だけ次元が下がっていることを示している。 像の次数と退化次数を合わせれば元のベクトル空間の次数になっているはずなので、 rank(U)=rank(f)+null(f) が成立する。 階数と全射・単射 上記の定義から、f の階数と写像の種類の間には次のような関係が得られる。 rank(f)=dimU　⇔　線形写像 f:U→V は単射 rank(f)=dimV　⇔　線形写像 f:U→V は全射 "},"mathematics/linear_algebra/vector_space.html":{"url":"mathematics/linear_algebra/vector_space.html","title":"ベクトル空間","keywords":"","body":"ベクトル空間 / 線形空間（vector space / linear space） ベクトル（大きさ・方向・向きを持った量）同士の和とベクトルのスカラー（大きさだけを持つ量）積が定義されたような数学的構造をベクトル空間・線形空間と呼ぶ。 特にベクトルの大きさ・スカラーが実数を取るときは実ベクトル空間、複素数を取るときは複素ベクトル空間と呼ぶ。 定義 K 上のベクトルの集合 V について以下が成立する。 u,v,w∈V、λ,μ∈K=(R or C) として ベクトルの加法の公理 u+v∈V (u+v)+w=u+(v+w) （結合則） u+v=v+u （交換則） u+0=0+u=x となる元が唯一存在する （零元の存在） u+u′=u′+u=0 となる元が唯一存在する （逆元の存在） スカラー乗法の公理 λx∈V (λ+μ)u=λu+μu λ(u+v)=λu+λv (λμ)u=λ(μu) 1u=u 一次独立と一次従属 V を K 上のベクトル空間とする。 x1,⋯,xm∈V,  ci∈K について、 c1x1+⋯+cmxm を x1,⋯,xm の一次結合（線形結合）といい、 c1x1+⋯+cmxm=0 を満たすことを x1,⋯,xm の一次関係（線形関係）という。また、ci=0 にて一次関係が満たされるのは自明であり、これを自明な一次関係という。 x1,⋯,xm について自明な一次関係しか成立しない場合、x1,⋯,xm は一次独立（線形独立）であるという。 逆に非自明な一次関係が成立する場合、x1,⋯,xm は一次従属（線形従属）であるという。 基底と次元 複数のベクトル v1,⋯,vn∈V が一次独立であり、任意の v∈V が v1,⋯,vn の一次結合で表されるとき、v1,⋯,vn は V の基底であるという。 v′=c1x1+⋯+cmxm  (ci∈K) また、基底が含むベクトルの個数 n をベクトル空間 V の次元といい dimV と表す。 極大線形独立系 ベクトル空間の有限部分集合 W⊂V 内の有限個のベクトル v1,⋯,vn∈W が一次独立であり、任意の v′∈W が v1,⋯,vn の一次結合で表されるとき、 v1,⋯,vn∈W は W の極大線形独立系であるという。 言い換えれば W 内のベクトルを一次結合で表現するのに必要十分な基底を極大線形独立系と呼ぶ。 基底変換 ベクトル空間 V について2つの極大線形独立系 {v1,⋯,vn}, {v′1⋯,v′n} を基底として得たとき、互いの要素は相手の要素の一次結合として表現できる。 つまり正則行列 P を用いて {v′1⋯,v′n}=P{v1,⋯,vn} のような変換が定義できる。これを基底変換と呼び、P を基底変換行列という。 逆に V の基底 v1,⋯,vn と detP≠0 なる行列 P を用いて定義される {v′1⋯,v′n}=P{v1,⋯,vn} も一次独立であり、V の基底である。 部分空間 K 上のベクトル空間 V の空でない部分集合 W が u,v∈W,   λ,μ∈K について線形性 λu+μv∈W を満たすとき、W も K 上のベクトル空間である。このとき W を V の線型部分空間と呼ぶ。 また、ベクトル {v′1⋯,v′n} の一次結合によってあらわされる空間 S=span({v′1⋯,v′n}) を {v′1⋯,v′n} によって張られる部分空間といい、{v′1⋯,v′n} を S の生成系という。 V の部分空間の例としては次のようなものがあげられる。 V 自身 V の零元からなる{0} KV={av | a∈K,v∈V} 原点を含む点・直線・平面・超平面 原点を含まなければ λ=μ=0 のときの線形性が満たされないため 原点を含まない点・直線・平面・超平面はアフィン空間と呼ばれる 不変部分空間 K 上のベクトル空間 V の部分空間 W について線形写像 f:V→V を考える。 W 上の任意のベクトルの変換も W 上のベクトルになるとき、W を f の不変部分空間であるという（つまり V∩¯W 上に像ができることはない）。 ∀x(x∈W→f(x)∈W) 和空間（sum space） K 上のベクトル空間 X,Y の基底の一次関係で表される点の集合を和空間といい X+Y で表す。 ベクトル空間はもともと加法・スカラー乗法について閉じているため、和空間もこれらについて閉じている、すなわちベクトル空間である。 和空間の次元は次の性質を満たす。 dim(X+Y)=dimX+dimY−dim(X∩Y) 直和・補空間（direct sum / complementary subspace） K 上のベクトル空間 V の部分空間 X,Y について X∩Y={0} かつ ∀v∈V(v∈X∨v∈Y) を満たすとき、V は X,Y の直和であるといい、V=X⊕Y と表す。 また、このとき X,Y は互いの補空間であるという。 すなわち、直和は互いに原点以外を共有しない部分空間を組み合わせることで表現される和空間であり、代数学的には加群の直和に相当する。 和空間の次元の性質に着目すれば、直和である和空間の次元は次の性質を満たす。 dim(X+Y)=dimX+dimY "},"mathematics/linear_algebra/inner_product_space.html":{"url":"mathematics/linear_algebra/inner_product_space.html","title":"内積空間","keywords":"","body":"内積空間（inner product space） K 上のベクトル空間 V に内積 B(u,v) を導入したものを内積空間と呼ぶ。 内積空間上のベクトル u,v が B(u,v)=0 を満たすとき、u,v は直交するという。 ここでいう内積 B(u,v) は幾何ベクトルの内積のことではなく、より一般的に2つのベクトルをスカラーに移すような積 B:V×V→K のことを指す。 内積の導入により、内積空間ではベクトル間の角度・長さ（ノルム）が定義できるようになる。 なお、内積抜きにノルムだけを定義することもでき、そのような空間をノルム空間と呼ぶ。 また、無限次元の複素数上の内積空間をヒルベルト空間という。 正規直交基底（orthonormal basis） 各ベクトルのノルムが 1 であり、ベクトル同士の内積が 0 になるような基底を正規直交基底という。 直交補空間（orthogonal complementary space） 内積空間 V の部分空間 X に対して X⊥={v∈V | ∀x∈X(B(v,x)=0)} を満たす点の集合を X の直交補空間という。 直交補空間は次の性質を満たす。 X⊂Y→X⊥⊃Y⊥ B が非退化かつ V が有限次元なら dimX+dimX⊥=dimV 特に有限次元ベクトル空間において B(x,y) を x,y の内積として定義した場合、つまり有限次元内積空間における直交補空間は次の性質を満たす。 (X⊥)⊥=X X∩X⊥={0} 直交射影 内積空間 V 上のベクトルからある部分空間上の成分だけを取り出す写像を直交射影という。 V 上の正規直交基底 e1,⋯,en とすれば、V から ei への直交射影を表す行列 Pi は次のように表される。 Pi=eieTi また、p∈{e1,⋯,en}2 で表される平面・超平面への直交射影を表す行列 Pp は各基底への射影の和となる。 Pp=∑Pi=∑eieTi  (i∈p) "},"mathematics/analysis/limit_continuity.html":{"url":"mathematics/analysis/limit_continuity.html","title":"関数の極限と連続性","keywords":"","body":"関数の極限と連続性 関数の定義 実数全体の集合 R の部分集合 D⊂R において、D の全ての元を R 上に移すような写像 f:D→R が存在するとき、f(x) を D を定義域とする関数という。 また、f の像を値域という。 以下では定義域 D が区間か区間の和になっているものだけを考える。 境界点 D 内の数列 {xn} と D 外の数列 {yn} について limn→∞xn=limn→∞yn=x0 を満たすようなものが存在するとき、点 x0 は D の境界点であるという。 極限値（limit） 定義域 D で定義された関数 f(x) について、領域 D 内の x が D 内のある点または境界点 x0 に漸近するとき、 limx→x0f(x)=a が成立するなら、a は x0 における f(x) の極限値であるという。 特に x_0\">x>x0 の範囲から近づくときを右極限、xx0 の範囲から近づくときを左極限といい、次のように表す。 limx→x0+0f(x),   limx→x0−0f(x) また、a=∞,−∞ となることを無限大に発散するという。 ε−δ 論法 極限値の厳密な定義は ε−δ 論法によって示される。 0\\ ^\\exists \\delta > 0\\ ((0∀ε>0 ∃δ>0 ((0|x−x0|δ)∧(x∈D)→|f(x)−a|ε) つまり任意の ε が定まれば、f(x) と a の差がある δ より小さくなる（漸近する）ことを述べている。 極限値の性質 f(x),g(x) が x=x0 の周辺で定義されており、limx→x0f(x)=α、limx→x0g(x)=β ならば以下が成り立つ。 limx→x0(f(x)+g(x))=α+β limx→x0cf(x)=cα limx→x0f(x)g(x)=αβ limx→x0f(x)g(x)=αβ  (β≠0) また、f(x),g(x),h(x) が領域 D で定義される関数で、D 内のある点または境界点 x0 と領域 D 内の x≠x0 に関して f(x)≤g(x)≤h(x) が満たされるとき、以下の性質が成立する。 x0 について f(x),g(x) に極限が存在する　⇒　limx→x0f(x)≤limx→x0g(x) limx→x0f(x)=limx→x0g(x)　⇒　limx→x0f(x)=limx→x0h(x)=limx→x0g(x) ランダウの記号（Landau symbol） 十分大きな x について定義された f(x),g(x) に対して x→∞ として、 f(x)/g(x)→0 なら f(x)=o(g(x)) と表す f(x)/g(x) が有界であるなら f(x)=O(g(x)) と表す これはランダウの記号の一種であり、極限の大小を比較するような証明などで利用される。 厳密な定義には ε−δ 論法を用いる。 不定形の極限 極限 limx→af(x)g(x) について、limx→af(x)=∞, limx→ag(x)=∞ となる場合や、limx→af(x)=0, limx→ag(x)=0 となる場合、また極限limx→af(x)g(x) について limx→af(x)=∞,limx→ag(x)=0 の場合などは、関数の収束の速さを調べなければ極限値を得ることができない。 このような極限を不定形の極限という。 定形の極限を求める方法の1つとしてロピタルの定理を利用する方法がある。 連続性（continuity） 関数 f(x) が定義域 D 内の全ての点 x0 で limx→x0f(x)=f(x0) を満たすとき、f(x) は x0 において連続であるという。 また、D 上の任意の点で f(x) が連続なら f(x) は D 上の連続関数であるという。 連続性の性質 f(x),g(x) が同じ定義域を持つ連続関数なら次の性質を満たす。 f(x)+g(x) も連続関数 cf(x)  (c∈R) も連続関数 f(x)g(x) も連続関数 f(x)g(x)  (g(x)≠0) も連続関数 また、f(x) の値域が g(x) の定義域に含まれるとき、 g(f(x)) も連続 連続関数の性質 有界性 関数 f(x) が定義域 D で連続で ∃k∈R ∀x∈D (f(x)≤k) を満たすとき、f(x) は上に有界であるといい、 ∃k∈R ∀x∈D (f(x)≥k) を満たすとき、f(x) は下に有界であるという。 上にも下にも有界であるとき、単に有界であるという。 単調増加性 関数 f(x) が定義域 D で連続であるとする。 xy→f(x)≤f(y)　⇒　f(x) は単調増加関数である xy→f(x)f(y)　⇒　f(x) は狭義の単調増加関数である xy→f(x)≥f(y)　⇒　f(x) は単調減少関数である f(y)\">xy→f(x)>f(y)　⇒　f(x) は狭義の単調減少関数である 中間値の定理 関数 f(x) が [a,b] で連続で、f(a)≠f(b) とする。 このとき、任意の η∈[f(a),f(b)] について f(ξ)=η を満たす aξb が少なくとも1つは存在する。 最大値と最小値 閉区間 [a,b] で有界かつ連続な関数 f(x) は閉区間内で最大値・最小値を取る。 "},"mathematics/analysis/differential.html":{"url":"mathematics/analysis/differential.html","title":"微分と導関数","keywords":"","body":"微分（differential） 微分可能性 定義域 D 上で定義される関数 f(x) と x0∈D について次のように定義される。 limx→x0f(x)−f(x0)x−x0 が存在する⇔　右極限 f′+(x0)=limx→x0f(x)−f(x0)x−x0 と左極限 f′+(x0)=limx→x0f(x)−f(x0)x−x0 が一致する⇔　微分可能である また条件を緩めて右極限のみが存在する場合を右微分可能、左極限のみが存在する場合を左微分可能という。 導関数（derivative） 定義域 D 上で定義される関数 f(x) が微分可能であるとき、 f′(x)=limh→0f(x+h)−f(x)h を導関数という。 導関数の性質 関数 f(x),g(x) が x=x0 の近くで定義され、いずれも微分可能であるとき、以下の性質が成立する。 (cf)′(x0)=cf′(x) (f±g)′(x0)=f′(x0)±g′(x0) (fg)′(x0)=f′(x0)g(x0)+f(x0)g′(x0) g(x0)≠0→(fg)′(x0)=f′(x0)g(x0)−f(x0)g′(x0)g(x0)2 極値 f(x) が x=x0 の近傍で f(x) \\ \\ (x_0 \\neq x)\">f(x0)>f(x)  (x0≠x) を満たすとき、f(x) は x0 で極大であるといい、f(x0) を極大値という。 同様に、不等号が ≥ であるときは広義の極大・広義の極大値、 であるときは極小・極小値、≤ であるときは広義の極小・広義の極小値という。 また、極大値と極小値をまとめて極値と呼ぶ。 極値の必要条件は次のように与えられる。 関数 f(x) が x=x0 の近傍で定義され C1 級であり、x0 で極値を持つ⇒　f′(x0)=0 極値の十分条件は次のように与えられる。 関数 f(x) が x=x0 の近傍で定義され Cn 級かつ f(i)(x0)=0  (i=1,⋯,n−1), f(n)(x0)≠0⇒　n が偶数かつ f(n)(x0)0 なら f(x0) は極大値　n が偶数かつ 0\">f(n)(x0)>0 なら f(x0) は極小値n が奇数なら f(x0) は極値ではない 平均値の定理（mean-value theorem） [a,b] を含む定義域で定義された関数 f(x) が (a,b) で微分可能であるとき、次の性質が成り立つ。 ∃c(acb)(f′(c)=f(b)−f(a)b−a) コーシーの平均値の定理（Cauchy's mean-value theorem） [a,b] を含む定義域で定義された関数 f(x),g(x) が (a,b) で微分可能であるとき、次の性質が成り立つ。 ∃c(acb)(f′(c)g′(x)=f(b)−f(a)g(b)−g(a)) ロピタルの定理（l'Hôpital's rule） a を含む開区間で微分可能な関数 f(x),g(x) について g′(x)≠0 とする。 このとき以下の性質が成り立つ。 f(a)=g(a)=0 かつ limx→af′(x)g′(x)=L が存在する⇔　limx→af(x)g(x)=L 同値な定理として、開区間 (a,∞) で微分可能な関数 f(x),g(x) について limx→∞f(x)=limx→∞g(x)=0 かつ limx→∞f′(x)g′(x)=L が存在する⇔　limx→∞f(x)g(x)=L がある。 また、a を含む開区間で a 以外の点で微分可能な関数 f(x),g(x) について、 limx→af(x)=limx→ag(x)=∞ かつ limx→af′(x)g′(x)=L が存在する⇔　limx→af(x)g(x)=L が成立する。 この定理は不定形の極限値を求める手段の1つである。 "},"mathematics/analysis/higher-order_differential.html":{"url":"mathematics/analysis/higher-order_differential.html","title":"高階微分","keywords":"","body":"高階微分 定義 関数 f(x) の導関数が微分可能であるとき、導関数の微分を2階の導関数という。 また、再帰的に n 回の微分を行った導関数を n 階の導関数といい、f(n)(x) と表す。 高階微分可能性 関数 f(x) が n 階の導関数を持つとき、f(x) は n 回微分可能であるという。 また、n 階の導関数が連続であるとき、f(x) は n 回連続微分可能あるいは Cn 級であるという。 無限回連続微分可能である関数は C∞ 級であるといえる。 ライプニッツの公式（Leibniz formula） 関数 f(x),g(x) が n 回微分可能であるとき、次の式が成立する。 (f⋅g)(n)=n∑k=0(nk)f(k)g(n−k) 合成関数の微分の式を展開することで得られる。 テイラーの定理（Taylor's theorem） [a,b] で n−1 回連続微分可能（C(n−1) 級）かつ (a,b) で n 回連続微分可能（Cn 級）である関数 f(x) は ∃c(acb)(f(b)=n−1∑k=0(b−a)kk!f(k)(a)+(b−a)nn!f(n)(c)) を満たす。 また、同値な定理として次のものがある。 ∀x,x0∈[a,b] ∃θ(0θ1)(f(x)=n−1∑k=0f(k)(x0)k!(x−x0)k+f(n)(x0+θ(x−x0))n!(x−x0)n) この表現を x0 周りのテイラーの定理という。 特に原点周りのテイラーの定理をマクローリンの定理という。 テイラー級数とテイラー展開（Taylor series / Taylor expansion） C∞ 級の関数にテイラーの定理を適用すると、 f(x)=∞∑k=0f(k)(x0)k!(x−x0)k のように任意の点を導関数を用いた級数で表現できる。 これを x0 周りのテイラー級数といい、このような形に式変形することを x0 周りのテイラー展開という。 特に原点周りのテイラー展開をマクローリン展開という。 テイラーの定理で登場した式はテイラー級数を次数 n−1 までで切り上げたものと解釈できる。 ラグランジュの剰余とコーシーの剰余（Lagrange remainder / Cauchy remainder） テイラー級数を次数 n−1 で切り上げた場合、余剰項が出る。 この余剰項を次のように表したものをラグランジュの剰余という。 Rn=f(n)(x0+θ(x−x0))n!(x−x0)n 同様に、θ (0θ1) の定義の仕方を変えて次のように表したものをコーシーの剰余という。 Rn=(1−θ)n−1(x−x0)n(n−1)!f(n)(x0+θ(x−x0)) オイラーの公式（Euler's formula） 関数 ex をマクローリン展開すると、 ex=∞∑n=0xnn! ここで、x に ix を代入すると、 ex=∞∑n=0(−1)n(2n)!x2n+i∞∑n=0(−1)n(2n+1)!x2n+1 となる。 すると第一項と第二項はそれぞれ cos(x),isin(x) のテイラー展開と一致するため、 eix=cos(x)+isin(x) が成り立つ。 これをオイラーの公式という。 "},"mathematics/analysis/partial_derivative.html":{"url":"mathematics/analysis/partial_derivative.html","title":"偏微分と偏導関数","keywords":"","body":"偏微分と偏導関数 偏微分可能性 D で定義された多変数関数 f(x1,⋯,xn) が xi=a において limΔxi→0f(x1,⋯, a+Δxi, ⋯, xn)−f(x1, ⋯, a, ⋯, xn)Δxi が存在するとき f は xi=a で偏微分可能であるという。 偏導関数（partial derivative） xi が偏微分可能な範囲で定義される関数 ∂f∂xi=limΔxi→0f(x1,⋯, xi+Δxi, ⋯, xn)−f(x1, ⋯, xi, ⋯, xn)Δxi を xi についての偏導関数という。 方向微分（directional derivative） あるベクトル v=(v1,v2,⋯,vn) に沿った微分 ∇vf(x)=limh→0f(x1+v1h, ⋯, xn+vnh)−f(x1, ⋯, xn)h を v についての方向微分という。 高階偏導関数 偏導関数をさらに偏微分した関数 fx1x1=(fx1)x1 , fx1x2=(fx1)x2 , fx2x1=(fx2)x1 , ⋯ , fxnxn=(fxn)xn を2階の偏導関数という。 このように偏微分を n 回適用したものを n 階偏導関数といい、これらを一般に高階偏導関数という。 高階連続偏微分可能性 多変数関数 f(x1,⋯,xn) が n 階の偏導関数を持つとき、f は n 回微分可能であるという。 また、n 階の偏導関数が連続であるとき、f は n 回連続微分可能あるいは Cn 級であるという。 無限回連続微分可能である関数は C∞ 級であるといえる。 定理 Cn 級関数は Cn−1 級関数である Cn 級関数の n 階までの偏導関数はその偏微分の順序によらず等しい 全微分 次のように定義される操作を全微分という。 df=n∑i=1∂f∂xidxi 各微分可能性の関係 多変数関数の微分可能性の関係は次のように記述される。 C1 級　⇒　全微分可能　⇒　方向微分可能　⇒　偏微分可能 "},"mathematics/analysis/extremum.html":{"url":"mathematics/analysis/extremum.html","title":"多変数関数の極値","keywords":"","body":"多変数関数の極値 2変数関数の極値 定義 関数 f(x,y) が点 P0 の近くで定義されているとき、近傍の点 P すべてで f(P)\">f(P0)>f(P) が成立するとき、f は P0 で極大であるといい f(P0) を極大値という。 1変数のとき同様に広義の極大値・極小値・広義の極小値も定義される。 極値の必要条件 極値は次の条件を満たす。 偏微分可能な関数 f(x,y) が点 (a,b) で広義の極値を取る⇒　fx(a,b)=fy(a,b)=0 極値の十分条件 極値であるか確かめるための条件の一例は次のように表される。 関数f(x,y) が C2 級であって fx(a,b)=0, fy(a,b)=0 を満たしているとき、 fxy(a,b)2−fxx(a,b)⋅fyy(a,b)0 かつ 0\">fxx(a,b)>0（ 0\">fyy(a,b)>0） なら (a,b) は極小点 fxy(a,b)2−fxx(a,b)⋅fyy(a,b)0 かつ fxx(a,b)0（fyy(a,b)0） なら (a,b) は極大点 0\">fxy(a,b)2−fxx(a,b)⋅fyy(a,b)>0 なら極値ではない "},"mathematics/analysis/hyperbolic.html":{"url":"mathematics/analysis/hyperbolic.html","title":"双曲線関数","keywords":"","body":"双曲線関数（hyperbolic） 定義 次のように定義される関数を双曲線関数という。 sinhx=ex−e−x2coshx=ex+e−x2tanhx=sinhxcoshx=ex−e−xex+e−x 性質 相互関係 cosh2x−sinh2x=1 微分 (sinhx)′=coshx (coshx)′=sinhx (tanhx)′=1cosh2x 積分 ∫sinhxdx=cosh+C ∫coshxdx=sinh+C 加法定理 sinh(α±β)=sinhαcoshβ±coshαsinhβ cosh(α±β)=coshαsinhβ±sinhαcoshβ tanh(α±β)=tanhα±tanhβ1±tanhαtanhβ 逆関数 x=sinhy　⇔　y=log(x+√x2+1) x=coshy　⇔　y=log(x±√x2−1) 積分への応用 √a2+x2 の形を含む積分は双曲線関数を利用した部分積分を用いることで計算できることが多い。 ∫√a2+x2dx を解く。 x=asinht とすると、 ∫√a2+x2dx=a2∫cosht⋅coshtdt=a2∫cosh2tdt=a22∫(1+cosh2t)dt=a22(t+12sinh2t)+C=a22(t+sinhtcosht)+C=a22sinh−1xa+x2√a2+x2+C=12{a2log(x+√a2+x2)+x√a2+x2}+C 同じく ∫1√a2+x2dx も x=asinht とすると、 ∫1√a2+x2dx=∫1acoshtacoshtdt=t+C=log(xa+√x2a2+1)+C=log(x+√a2+x2)+C′ ソースコード import numpy as np import matplotlib.pyplot as plt x = np.linspace(-2,2,200) cosh = np.cosh(x) sinh = np.sinh(x) tanh = np.tanh(x) plt.plot(x, cosh, label='$y=\\\\cosh x$') plt.plot(x, sinh, label='$y=\\\\sinh x$') plt.plot(x, tanh, label='$y=\\\\tanh x$') plt.legend() plt.show() "},"mathematics/analysis/inverse_trigonometric_function.html":{"url":"mathematics/analysis/inverse_trigonometric_function.html","title":"逆三角関数","keywords":"","body":"逆三角関数（inverse trigonometric function） 定義 三角関数の逆関数を逆三角関数という。 y=sinx⇔x=arcsiny⇔x=sin−1y y=cosx⇔x=arccosy⇔x=cos−1y y=tanx⇔x=arctany⇔x=tan−1y ある y に対して x が複数の解を持つようになるため、x の定義域に留意しなければならない。 微分 (arcsiny)′=1√1−x2 (arccosy)′=−1√1−x2 (arctany)′=11+x2 "},"mathematics/analysis/series.html":{"url":"mathematics/analysis/series.html","title":"級数","keywords":"","body":"級数（series） K 上の値を順に並べて {an}  (n=1,2,⋯) としたものを数列（sequence）という。 数列の部分和 Sn=∑ni=1ai を第 n 部分和という。 n→∞ としたときの和を級数といい、∑an で表す。 収束性 Sn が n→∞ で収束するとき、級数 ∑an は収束するという。 性質 ∑an,∑bn が収束するなら次の性質が成り立つ。 ∑(an+bn) は ∑an+∑bn に収束する ∑can  (c∈K) は c∑an に収束する コーシーの収束判定法 数列の収束性は次の性質を検証することで確かめられる。 数列 {an} が収束する⇔　 0 \\ ^\\exists N \\in \\mathbb{N} \\ (m,n\\geq N \\rightarrow ||a_m - a_n|| ∀ε>0 ∃N∈N (m,n≥N→||am−an||ε)⇔　∑n→∞an のとき an→0 この性質を満たす数列すなわち収束する数列をコーシー列（Cauchy sequence）・基本列（fundamental sequence）という。 級数の極限 コーシーの収束判定法を部分和の列 Sn に適用すると次の定理が得られる。 級数 ∑an が収束する⇔　 0\\ ^\\exists N \\in \\mathbb{N} \\ (m > n > N \\rightarrow |a_{n+1} + \\cdots + a_m | ∀m,n∈N ∀ε>0 ∃N∈N (m>n>N→|an+1+⋯+am|ε) この定理の応用として、次のような系が得られる。 これは級数が収束しないことの証明に用いることができる。 級数 ∑an が収束する　⇒　n→∞ のとき an→0 "},"mathematics/analysis/characteristic_series1.html":{"url":"mathematics/analysis/characteristic_series1.html","title":"特殊な級数1","keywords":"","body":"特殊な級数1 正項級数（positive term series） 定義 各項が正である級数 0)\">∑an (ai>0) を正項級数という。 比較判定法による収束判定 正項級数 ∑an,∑bn について、 0 \\ ^\\exists K > 0 \\ ^\\forall n > n_0\\ (a_n \\leq Kb_n) \">∃n0>0 ∃K>0 ∀n>n0 (an≤Kbn) が成立するとき、次の性質を満たす。 ∑bn が収束する　⇒　∑an も収束する ∑an が発散する　⇒　∑bn も発散する これはある n0 以降の項について常に an≤Kbn すなわち an=O(bn)（ランダウの記号）であるときの性質を利用したものである。 発散・収束を調べたい正項級数があるとき、発散・収束の仕方がわかっている級数を用意して比較すればよいということを示している。 コーシーの判定法による収束判定 正項級数 ∑an について、 limn→∞ n√an=r が存在するとき、次の性質を満たす。 0≤r1　⇒　∑an は収束する 1r≤∞　⇒　∑an は発散する ダランベールの判定法による収束判定 正項級数 ∑an について、 limn→∞an+1an=r が存在するとき、次の性質を満たす。 0≤r1　⇒　∑an は収束する 1r≤∞　⇒　∑an は発散する 交代級数（alternating series） 定義 隣り合う項がそれぞれ異符号であるような級数 0, i \\in \\{0,1\\})\">∑an=∑(−1)n−ibn  (bn>0,i∈{0,1}) を交代級数という。 ライプニッツの定理 交代級数 0, i \\in \\{0,1\\})\">∑an=∑(−1)n−ibn  (bn>0,i∈{0,1}) について、次の性質が成り立つ。 {bn} が減少数列で n→∞ のとき bn→0⇒　交代級数 ∑an は収束する "},"mathematics/analysis/differential_equation1.html":{"url":"mathematics/analysis/differential_equation1.html","title":"微分方程式1","keywords":"","body":"微分方程式1（differential equation） 定義 関数 f(x) の導関数と x を用いて表される方程式 F(x,y,y′,⋯,y(n))=0 を階数 n の常微分方程式という。 x のある区間 I で定義された Cn 級関数 ϕ(x) が F(x,ϕ(x),ϕ′(x),⋯,ϕ(n)(x))=0 を恒等的に満たすとき、ϕ(x) をこの微分方程式の解（solution）という。 また、x0,y(0),y′(0),⋯,y(n)(0) の値が与えられた下で解く問題を初期値問題といい、これらの条件を初期条件と呼ぶ。 解の種類 得られた解のうち、n 個の任意定数を含むものを一般解（general solution）といい、この定数を指定して得られる解を特殊解（particular solution）という。 また、一般解の形で表されない解を特異解（singular solution）という。 特異解は問題によって存在するケースと存在しないケースがある。 正規形 常微分方程式のうち、次の形で表されるものを正規形という。 y(n)=f(x,y,y′,⋯,y(n−1)) 正規形に変形できる微分方程式はある程度簡単に解を求める方法が確立されている。 逆に正規形に変形できない微分方程式を解くには様々な議論が必要になることが多い。 "},"mathematics/analysis/differential_equation2.html":{"url":"mathematics/analysis/differential_equation2.html","title":"微分方程式2","keywords":"","body":"微分方程式2（differential equation） 特殊な1階線形微分方程式 直接積分形 y′=f(x) 一般解 y′=f(x)dydx=f(x)∫dy=∫f(x)dxy=∫f(x)dx 変数分離形 y′=g(x)h(y)   (h(y)≠0) 一般解 y′=g(x)h(y)∫1h(y)dy=∫g(x)dx 一般の1階線形微分方程式 同次形 y′+P(s)y=0 一般解 y′+P(x)y=0∫1y=−∫P(x)dxlog|y|=−∫P(x)dxy=Ce−∫P(x)dx 非同次形 y′+P(x)y=Q(x) 一般解 同次形の定数項が u(x) であるとする。 {u(x)⋅e−∫P(x)dx}′+P(x)⋅u(x)⋅e−∫P(x)dx=Q(x)u′(x)⋅e−∫P(x)dx−u(x)⋅P(x)⋅e−∫P(x)dx+P(x)⋅u(x)⋅e−∫P(x)dx=Q(x)u′(x)⋅e−∫P(x)dx=Q(x) 直接積分形として処理して dudx=Q(x)e∫P(x)dxu(x)=∫Q(x)e∫P(x)dxdx+Cy=e−∫P(x)dx{∫Q(x)e∫P(x)dxdx+C} u(x) は任意の関数を表現できる形のためこれを一般解としてよい。 ベルヌーイの微分方程式 y′+P(x)y=Q(x)yn   (n≠0,1) 一般解 y′+P(x)y=Q(x)yn(−n+1)y−ny′+(−n+1)P(x)y−n+1=(−n+1)Q(x)(y−n+1)′+(−n+1)P(x)y−n+1=(−n+1)Q(x) 一階線形微分方程式の非同次形に当てはめて y−n+1=e−∫P(x)dx{(−n+1)∫Q(x)e∫(−n+1)P(x)dxdx+C} "},"mathematics/analysis/convolution.html":{"url":"mathematics/analysis/convolution.html","title":"畳み込み","keywords":"","body":"畳み込み 定義 次の式で定義される (g∗h)(x) を関数 g,h の畳み込みという。 (g∗h)(x)=∫∞−∞g(τ)h(x−τ)τck=∞∑l=−∞albk−l 関数 f,g ないし数列 a,b の一方を反転・並行移動させて重ね合わせ、その面積を計算したものに相当する。 応用 多項式の積 畳み込み演算の出現する構造の例として多項式の積がある。 このような多項式の積は多倍長整数の乗算などに利用される。 (aN−1xN−1+⋯+a1x+a0)(bM−1xM−1+⋯+b1x+b0)=N−1∑k=0M−1∑l=0akblxk+l=N+M−2∑k=0(k∑l=0albk−l)xk=N+M−2∑k=0ckxk 相関関数との関係 似た概念として相関関数がある。 相関関数の場合は反転を行わずに複素共役を取り平行移動・重ね合わせを行う。 rxy(τ)=∫∞−∞x(t)¯y(t−τ)dt "},"mathematics/analysis/laplace_transform.html":{"url":"mathematics/analysis/laplace_transform.html","title":"ラプラス変換","keywords":"","body":"ラプラス変換（Laplace Transform） ラプラス変換とは、関数y(t)を tの微積分⇔sの掛け算 となるような媒介変数sを用いてY(s)とするような関数変換を指す。 微積分を掛け算として計算できるため、線形微分方程式を調べる際に役立つ。 定義 ラプラス変換 F(s)=L[f(t)]=∫∞0f(t)e−stdt   (t≥0) 逆ラプラス変換 0) \">f(t)=limp→∞12πi∫c+ipc−ipF(s)estds   (c>0) 変換表 f(t) F(s) δ(t)={∞(x=0)0(x≠0) ※デルタ関数 1 us(t)=∫δ(t)dt=1 1s t 1s2 tnn! 1sn+1 e−at 1s+a te−at 1(s+a)2 sinωt ωs2+ω2 cosωt ss2+ω2 e−atsinωt ω(s+a)2+ω2 e−atcosωt s+a(s+a)2+ω2 性質 f(t) F(s) 線形性 af(t)+bg(t) aF(s)+bG(t) 相似性 f(at) 1aF(sa) 時間シフト f(t−a) e−asF(s) 畳み込み ∫t0f(t−τ)g(τ)dτ F(s)G(s) 微分 ddtf(t) sF(s)−f(0) n階微分 dndtnf(t) snF(s)−{sn−1f(0)+sn−2f′(0)+⋯+f(n−1)(0)} 積分 ∫t0f(t)dt 1s{F(s)+f(−1)(0)} n重積分 ∫∫…∫t0f(t)(dt)n s−nF(s)+s−nf(−1)(0)+{s−(n−1)f−2(0)+⋯+s−1f(−n)(0)} 初期値・最終値の定理 limt→+0f(t)=lims→∞sF(s) f(t) が収束するなら limt→∞f(t)=lims→0sF(s) "},"mathematics/analysis/fourier_transform.html":{"url":"mathematics/analysis/fourier_transform.html","title":"フーリエ変換","keywords":"","body":"フーリエ変換 フーリエ変換とは、時間や空間座標が変数の関数を、周波数を変数とする関数に変換する関数変換を指す。 信号に含まれる周波数成分の解析などに利用される。 変換後の関数は元の関数の「周波数領域表現」と呼ばれることがある。 定義 フーリエ変換 X(ω)=∫∞−∞x(t)e−jωtdt フーリエ逆変換 x(t)=12π∫∞−∞X(ω)ejωtdω 性質 x(t) X(ω) 線形性 ax(t)+by(t) aX(ω)+bY(ω) 相似性 x(at) 1∥a∥X(ωa) 時間シフト x(t−b) X(ω)e−jωb 周波数シフト x(t)ejat X(ω−a) 畳み込み (x∗y)(t) X(ω)Y(ω) 積 x(t)y(t) 12π(X∗Y)(ω) 時間反転 x(−t) X(−ω) 複素共役 ¯¯¯x(t) ¯¯¯¯¯X(ω) x(t)微分 ddtx(t) jωX(ω) X(ω)微分 (−jt)x(t) ddωX(ω) 積分 ∫t−∞x(τ)dτ X(ω)jω+πX(0)δ(ω) 周期関数のフーリエ変換 一般に三角関数の整数倍の和（複素数表記なら複素指数関数の複素数倍の和）で表される周期関数は次のようにフーリエ変換できる。 x(t)=∞∑n=−∞cnejnω0tcn=1T∫T/2−T/2x(t)e−jnω0τ dτ   (n=0, ±1, ±2, ⋯) パーセバルの定理（Parseval's theorem） フーリエ変換はユニタリ作用素であることを示した定理。 ユニタリ作用素とはヒルベルト空間上の自己同型写像、すなわち線形性及び（一般的、抽象的な意味での）内積とそこから定まる位相の関係を保つような全単射を指す。 より一般的には関数のL2ノルムの積分とその周波数スペクトルのL2ノルムの積分が一致することを示したプランシュレルの定理がある。 パーセバルの等式 パーセバルの定理から導き出される等式。 時間領域におけるエネルギーと周波数領域におけるエネルギーが等しくなることを示している。 ∫∞−∞|x(t)|2dt=12π∫∞−∞|X(ω)|2dω "},"mathematics/analysis/convex.html":{"url":"mathematics/analysis/convex.html","title":"凸集合・凸関数","keywords":"","body":"凸集合・凸関数 凸集合 集合D（⊆Rn）について、内包する2点同士を結ぶ 凸結合 がすべてDに含まれているとき、Dは 凸集合 であるという。 条件を数式にすると S={(1−λ)u+λv | 0≤λ≤1}   (u,v∈D) について S⊂D が成立すること。 凸関数 定義 凸集合Dにおける関数 f:D→R が領域内の任意の2点 u,v∈D について常に f((1−λ)u+λv)≤(1−λ)f(u)+λf(v)   (0≤λ≤1) が成立する時、f はD上で 凸関数（convex function） であるという。特に f((1−λ)u+λv)≤(1−λ)f(u)+λf(v)   (0λ1) であるときを 狭義（強意）の凸関数（strictly convex function） であるという。 また、−fが凸関数であるとき、fは 凹関数 であるという。 判別法 任意の x においてヘッセ行列が半正定値　⇔　凸関数 性質 その1 fが凸関数　⇔　エピグラフ epif が凸集合 エピグラフ ある関数を描画したn+1次元のグラフにおける関数より上側の領域のこと。 epif={(x,r) | x∈D,r≥f(x),r∈R}⊆Rn+1 その2 Dが開凸集合であり、その内部でfが連続微分可能であるとき、 fが凸関数　⇔　次のいずれかが成立する f(v)≥f(u)+∇f(x)T(v−u) (∇f(v)−∇f(u))T(v−u)≥0 上の性質を∇fの単調性という。 "},"mathematics/analysis/lagrange_multiplier.html":{"url":"mathematics/analysis/lagrange_multiplier.html","title":"ラグランジュ乗数法","keywords":"","body":"ラグランジュ乗数法（ラグランジュ未定乗数法）（lagrange multiplier） ラグランジュ乗数法は、複数の変数に1つ以上の等式制約条件が課されたとき、それらの変数からなる関数の停留点を求める手法である。 停留点が求まれば、条件と関数の性質に応じてそれぞれの値を検証することで極大値・極小値を得ることができるため、主に非線形計画問題の解法として用いられる。 定理 n 次元の変数 x が次の m 個の制約条件を満たすとする。 G(x)=⎛⎜ ⎜⎝g1(x1,…,xn)⋮gm(x1,…,xn)⎞⎟ ⎟⎠=0 ただし、gk(x) は C1 級関数（連続微分可能つまり微分可能で導関数も連続）である。 また、制約条件を満たす点で dim(∇gk)=dim(∂gk∂x1,⋯,∂gk∂xn)=m である（つまり ∇gi 同士は一次独立）。 ここでm個の未知の変数 λk（Lagrange乗数と呼ぶ）を導入して、 L(x,λ)≡f(x)−M∑k=1λkgk(x) のようなLagrange関数を定義したとき、 ある x について ∂L∂xk=0, ∂L∂λk=0 を満たす λ が存在する⇔　x は関数 f(x) の停留点 が成立する。 解説 2つ目の条件 ∂L∂λk=0 は結局 gk(x∗)=0 と同じであり、制約条件を満たすつまり実行可能解であるかの確認になっている。 1つ目の条件 ∂L∂xk=0 は ∇f(x∗)=∑Mk=1λk∇gk(x∗) が成立することを意味している。 左辺は関数 f(x) の勾配ベクトル、右辺は制約関数の勾配ベクトルを示しており、関数 f(x) の等高線と制約面が接していることを示している。 "},"mathematics/vector_calculus/scalar_vector_product.html":{"url":"mathematics/vector_calculus/scalar_vector_product.html","title":"内積・外積","keywords":"","body":"内積と外積 ベクトル空間においてベクトル同士の積を次のように定義したとき、それぞれを内積（スカラー積）・外積（ベクトル積）という。 なお、外積は3次元ベクトル空間でのみ定義される。 内積（inner product / scalar product） ベクトル a,b∈V を用いて a⋅b=aTb=bTa で定義される積をベクトル a,b の内積という。 ベクトル a,b∈V の成す角を θ として、a⋅b=|a||b|cosθ と表すこともできる。 結果がスカラーになることからスカラー積ともいう。 ベクトル空間における「内積」は2つのベクトルをスカラーに移すような射影一般のことを指すが、ここでの内積はその実現の1つであると言える。 外積（vector product / cross product） 3次元ベクトル空間上のベクトル (ax,ay,az),(bx,by,bz)∈V について a×b=(aybz−azby,azbx−axbz,axby−aybx) をベクトル a,b の外積という。 結果が V 上のベクトルになることからベクトル積・クロス積ともいう。 "},"mathematics/vector_calculus/triple_product.html":{"url":"mathematics/vector_calculus/triple_product.html","title":"三重積","keywords":"","body":"三重積（triple product） 3次元ベクトル空間において次のように定義されるベクトル積をそれぞれスカラー三重積・ベクトル三重積という。 スカラー三重積（scalar triple product） ベクトル a,b,c∈V に対して a⋅(b×c) をスカラー三重積という。 スカラー三重積は3つのベクトルが成す平行六面体の体積に等しい。 ベクトル三重積（vector triple product） ベクトル a,b,c∈V に対して a×(b×c) をベクトル三重積という。 ベクトル三重積は次の性質を満たす。 a×(b×c)=b(a⋅c)−c(a⋅b) "},"mathematics/vector_calculus/vector-valued_function.html":{"url":"mathematics/vector_calculus/vector-valued_function.html","title":"ベクトル値関数","keywords":"","body":"ベクトル値関数（vector-valued function） 定義 ベクトル解析の分野において、スカラーまたはベクトルをベクトルに移すような関数 f:(KorV)→V をベクトル値関数またはベクトル関数という。 連続性（continuity） 定義域 U⊂V 上でのベクトル関数の連続性は次のように定義される。 ∀t∈U(limτ→tf(τ)=f(t)) 微分 定義域 U 上の点 x0 においてベクトル関数 f(x) について limx→x0f(x)−f(x0)x−x0 が存在するとき、f(x) は x0 において微分可能であるという。 微分の性質 ベクトル空間 V の基底 ei  (i=1∼n) を用いて f(x)=∑αi(x)ei と表されるとき、以下の性質が成立する。 limx→x0f(t)=∑limx→x0αi(x)ei f(x) が連続　⇔　αi(x) がすべて連続 f(x) が連続　⇒　f′(x0)=∑α′(x)ei "},"mathematics/vector_calculus/vector_field.html":{"url":"mathematics/vector_calculus/vector_field.html","title":"ベクトル場","keywords":"","body":"ベクトル場 定義 ユークリッド空間上の各点にベクトル的な量が与えられているとき、その分布を表したものをベクトル場という。 ベクトル場はベクトル値関数 V:M→Rm  (M⊂Rm) によって表現される。 "},"mathematics/statistics/level_of_measurement.html":{"url":"mathematics/statistics/level_of_measurement.html","title":"データの尺度水準","keywords":"","body":"データの尺度水準（level of measurement） データは尺度水準と呼ばれる性質により、次の4つに分類できる。 名義尺度（nominal scale） 観測値が順序関係のない値（記号・文字列・単なる分類番号など）を元とする集合であるとき、このデータを名義尺度データ（カテゴリデータ）という。 言い換えれば、観測値同士が「等しいかどうか」以外の意味を持たないデータであり、それぞれの出現頻度だけに興味がある場合などはこれに相当する。 定義可能な代表値は最頻値のみ。 例：性別・会社名・色名など 順序尺度（ordinal scale） 観測値が順序関係のある値を元とする集合であるとき、このデータを順序尺度で観測されたデータという。 言い換えれば、観測値同士で「どちらが大きいか・等しいか」の比較だけが意味を持つデータである。 定義可能な代表値は最頻値・中央値のみ。 例：階級・嗜好（どちらが好き） 間隔尺度（interval scale） 観測値が差（間隔）の概念を持つ値を元とする集合であるとき、このデータを間隔尺度で観測されたデータという。 言い換えれば、観測値同士で「どちらがどの程度大きいか」の比較が有効であるようなデータである。 定義可能な代表値は最頻値・中央値・算術平均のみ。 例：摂氏・日付 比率（比例）尺度（ratio scale） 観測値が原点が定義された集合であるとき、このデータを比率尺度で観測されたデータという。 言い換えれば、観測値同士で「一方がもう一方の何倍であるか」の比較が有効であるようなデータである。 例：身長・収入 "},"mathematics/statistics/statistics.html":{"url":"mathematics/statistics/statistics.html","title":"統計量","keywords":"","body":"統計量（statistics） 得られた1組の標本データから目的に応じた統計学的なアルゴリズムによって取り出した値を統計量という。 順序統計量 順序尺度を持つ標本データの標本点を小さいものから順に並べて x1,x2,⋯ としたものを順序統計量という。 また xk を k 番目の順序統計量と呼ぶ。 要約統計量 データの特徴を要約（代表）して表すことを目的に取り出された数値を要約統計量という。 詳細はこちら。 検定統計量 統計学的仮説検定を行う際、検定の基準値として用いるために標本データから抽出した数値を検定統計量という。 "},"mathematics/statistics/summary_statistics.html":{"url":"mathematics/statistics/summary_statistics.html","title":"要約統計量（代表値）","keywords":"","body":"要約統計量（代表値）（summary statistics） データの特徴を要約（代表）して表すことを目的に取り出された数値を要約統計量という。 対象が標本・離散確率分布・連続確率分布のときで定義の方法が異なるため、ここでは概念だけを説明する。 名義尺度から求まる要約統計量 最頻値（mode） データの中で最も多く出現する値（出現率が高い値）を最頻値といい、xmo で表す。 順序尺度から求まる要約統計量 最小値・最大値（maximum / minimum） データの中で出現する（出現しうる）最小の値・最大の値を最小値・最大値といい、xmin,xmax で表す。 中央値（median） データを小さいものから順に並べたときの中央の値を中央値といい、xme で表す。 ヒンジ（hinge） 中央値以下のデータの中央値・中央値・中央値以上のデータの中央値をそれぞれ第1ヒンジ（上側ヒンジ）・第2ヒンジ・第3ヒンジ（下側ヒンジ）という。 第2ヒンジ・第3ヒンジは次に説明する25%点・75%点とは若干異なるので注意。 n 分位点・k パーセント点 データを小さいものから順に並べたときに全体を n 分割する点、下から k %の位置にある点の値を n 分位点、k パーセント点という。 また n 分位点の場合、下からいくつ目の分位点であるかを使って第1 n 分位点、第2 n 分位点…という。 例：25%点 ⇔ 第1四分位点（first quartile） 5数要約（five-number summary） データの特徴を次の5点で記述することを5数要約という。 最小値 第1ヒンジもしくは第1四分位点 中央値 第3ヒンジもしくは第3四分位点 最大値 これを利用した例に箱ひげ図（box-and-whisker plot）がある。 間隔尺度から求まる要約統計量 算術平均（相加平均）（arithmetic mean） 比率尺度から求まる要約統計量 幾何平均 調和平均 一般化平均 自己加重平均 打切平均 "},"mathematics/statistics/event.html":{"url":"mathematics/statistics/event.html","title":"標本空間・事象","keywords":"","body":"標本空間と事象 定義 標本空間・全事象（sample space / whole event） 偶然現象を試行したとき起こりうる結果すべての集合を標本空間または全事象といい、Ω で表す。 例 サイコロをふるとき Ω={1,2,3,4,5,6} が標本空間である 標本点（sample point） 標本空間の元、つまり試行によって起こりうる結果それぞれを標本点という。 例 サイコロをふるとき 1,2,3,4,5,6 が標本点である 事象（event） 標本空間の部分集合を事象という。 また、ただ1つの標本点からなる事象を根源事象（elementary event）といい A,B,⋯ で表す。 標本点を1つも含まない事象を空事象といい ∅ で表す。 例 サイコロをふるとき {1,2} は「1か2が出る」という事象を意味し、空事象は「生じ得ない」事象を意味する 和事象・積事象・余事象（union of events / intersection of events / complement event） 事象 A,B の和集合 A∪B・積集合 A∩B・補集合 Ac も事象となり、それぞれを和事象・積事象・余事象という。 例 サイコロをふるとき {1,2}∪{2,3}={1,2,3} は「1か2か3が出る」という事象を示す 排反事象 事象 A,B に対して A∩B=∅ が成り立つとき、事象 A,B は互いに排反である（mutually exclusive / disjoint）という。 例 サイコロをふるとき {1,2}∩{3,4}=∅ は「1か2が出て同時に3か4が出る」というありえない事象を意味するため、{1,2} と {3,4} は排反である 完全加法族 空でない集合 Ω の部分集合の族 A が次の条件を満たすとき、加法族（additive class）と呼ぶ。 Ω∈A A∈A→Ac∈A A∈A∧B∈A→A∪B∈A また3つ目の条件を Ai∈A→⋃∞i=1Ai∈A (i=1,2,⋯) に置き換えたものを完全加法族（complete additive class）または σ-加法族という。 完全加法族は有限回の合併 ∪、交叉 ∩、補演算 c について閉じており、確率を定義できる事象全体を為す族として解釈できる。 直観的には条件1は全事象を含むすなわち確率1を定義できること、条件2はある事象が起きる確率に対して起きない確率を定義できること、条件3はある事象とある事象が同時に生じる確率を定義できることを示している。 "},"mathematics/statistics/probability.html":{"url":"mathematics/statistics/probability.html","title":"確率・確率空間","keywords":"","body":"確率・確率空間 定義 可測空間（measurable space） 空でない集合 Ω とその完全加法族 A の組 (Ω,A) を可測空間という。 確率空間（probability space） 可測空間に対して、A 上で定義され P(Ω)=1 を満たす測度を確率測度（probability measure） P といい、これを加えて (Ω,A,P) としたものを確率空間という。 確率空間は、ある偶然現象について、生じうる事象の集合 Ω・その中で「数学的に確率が定義できる組み合わせ」の集合 A・各事象の生起確率 P をまとめたものである。 例：サイコロを1回振り出目を観測するときの確率空間 Ω={1,2,3,4,5,6} A={{},{1},{2},{1,2},{3},⋯,{1,2,3,4,5,6}} P(A)=1/6 （出目が均一と仮定した場合） コルモゴロフの公理 確率測度の定義は、次のようなコルモゴロフの公理の形で示すことができる。 すべての事象の生じる確率は 0∼1 の範囲になる ∀A∈A(0≤P(A)≤1) 全事象 S が生じる確率は1である P(S)=1 有限個の排反事象に関する和の法則が成立する ∀A1∈A ∀A2∈A(A1≠A2→A1∩A2=∅)→P(⋃∞i=1Ai)=∑∞i=1P(Ai) "},"mathematics/statistics/conditional_probability.html":{"url":"mathematics/statistics/conditional_probability.html","title":"条件付き確率","keywords":"","body":"条件付き確率（conditional probability） 定義 条件付き確率 確率空間 (Ω,A,P) において、事象 0)\">A,B∈A (P(B)>0) が与えられているとき、以下で定義される実数値関数は確率測度となる。 P(A|B)=P(A∩B)P(B) これを事象 B が起きたという条件下での事象 A の条件付き確率という。 基本的な性質 0\">A,B∈A,  P(A),P(B)>0 について以下が成立する。 P(A∩B)=P(A)P(B|A)=P(B)P(A|B) （乗法定理） P(A|B)=P(A)→P(B|A)=P(B) P(A∩B)≤P(B|A), P(A∩B)≤P(A|B) 全確率の定理 Ai,B∈A (i=1,2,⋯,n) について、⋃ni=1Ai=Ω, Ai∩Aj=ϕ (i≠j) が成り立ち、 0\">P(Ai)>0 であるとき以下が成り立つ。 P(B)=n∑i=1P(Ai)P(B|Ai) ベイズの定理（Bayes theorem） Ai,B∈A (i=1,2,⋯,n) について、⋃ni=1Ai=Ω, Ai∩Aj=ϕ (i≠j) が成り立ち、 0\">P(Ai), P(B)>0 であるとき以下が成り立つ。 P(Aj|B)=P(Aj)P(B|Aj)∑ni=1P(Ai)P(B|Ai)   (j=1,2,⋯,n) "},"mathematics/statistics/random_variable.html":{"url":"mathematics/statistics/random_variable.html","title":"確率変数","keywords":"","body":"確率変数（random variable） 定義 確率空間 (Ω,A,P) において、写像 X:Ω→R が任意の集合 B∈B について X−1(B)={ω | X(ω)∈B}∈A を満たすとき、X を確率変数という。 つまり偶然現象によって生じる事象それぞれに何らかの値（観測値）が紐付いているとき、その値を確率的に定まる変数として捉えたものが確率変数である。 現実の統計では、各事象に区別可能な値（数値・呼び名）を必ず割り振ることになる（というより人間が区別できるということはすでに頭の中で何かしらの形で記号化されていると言える）ため、確率変数＝観測される結果といったニュアンスで記述されることが多い。 "},"mathematics/statistics/probability_distribution.html":{"url":"mathematics/statistics/probability_distribution.html","title":"確率分布","keywords":"","body":"確率分布（probability distribution） 概要 ベルヌーイ分布（Bernoulli distribution） 確率変数x(x∈{0,1})が確率μで1の値を取るときの確率分布。 つまり二項分布のn=1のケースに相当する。 Bern(x|μ)=μx(1−μ)1−xx∈{0,1} 第1種ベータ分布（beta distribution） ベルヌーイ分布の共役事前分布である。 0, \\ \\ \\ b>0 \">Beta(μ|a,b)=xa−1(1−x)b−1∫10xa−1(1−x)b−1dxx∈[0,1],   a>0,   b>0 import numpy as np import scipy.stats import matplotlib.pyplot as plt params = [[1,1],[5,5],[3,9],[1,5]] x = np.linspace(0,1,101) for p in params: rv = scipy.stats.beta(p[0],p[1]) y = rv.pdf(x) plt.plot(x,y,label=p) plt.legend() plt.show() "},"mathematical_programming/graph_theory/intro.html":{"url":"mathematical_programming/graph_theory/intro.html","title":"グラフ","keywords":"","body":"グラフ理論 グラフ理論は頂点・辺からなるグラフの性質について考察する分野。 グラフの構成要素 頂点（vertex/node） 頂点：u,v 頂点の集合：V 頂点数：|V| 辺・枝（edge/arc） 辺：e 辺の集合：E 辺の数：|E| e=(u,v)∈E 順序対の代わりに辺の始点・終点を抽出する写像 ∂+,∂− で定義することもある グラフ全体は G=(V,E) もしくは G=(V,E;∂+,∂−) と表現する。 基本的な用語 パス（path） ある頂点から辺・頂点を辿って別の頂点へ行くための経路をパスという。 形式的には頂点と枝の交互系列 (v0,e1,v1,e2,⋯,vk) で表される。 有向グラフ上のパスが辺に設定された向きに従っているとき、これをとくに有向路（directed path）という。 ある頂点からある頂点へのパスが存在するとき、始点から終点へ到達可能（reachable）であるという。 同じ辺を2回以上通らないパスを単純な路（simple path）といい、同じ頂点を2回以上通らないパスを初等的な路（elementary path）という。 次数 グラフの頂点に結合する辺の数を次数という（ループの場合は2と換算する）。 有向グラフの場合は向きに応じて入次数・出次数とすることもある。 閉路・ループ（loop） ある頂点から出発し自分に戻ってくるようなパスを閉路・ループという。 とくに有向路からなる閉路を有向閉路という。 多重枝（parallel edge） ある2つの頂点の間に複数の辺が存在するとき、これを多重枝という。 カット（cut） グラフの頂点を真部分集合 X⊊V とその補集合 Xc=V∖X の2つのグループに分割するとき、異なるグループの点同士を結ぶ辺をカットという。 また、有向グラフのカットについてすべてのカットが一方のグループからもう一方のグループの向きに伸びているとき、これを有向カットという。 形式的に表現すると以下のようになる。  ∂+(X)∪∂−(X) {∂+(X)={e∈E | ∂+e∈E,∂−e∈V∖X}∂−(X)={e∈E | ∂+e∈V∖X,∂−e∈V} 縮約（contraction） 頂点の部分集合 W∈V について、新しい頂点 w を追加し W と V∖W のカットの W 側をすべて w に接続した上で W を削除する操作を W の縮約 という。 部分グラフ（subgraph） V′⊂V, E′⊂E と ∂+,∂− を E′ に制限した ∂+E′,∂−E′ で表されるグラフ G′(V′,E′;∂+E′,∂−E′) を部分グラフという。 頂点はそのままに辺だけをいくつか取り去ったような部分グラフを全域部分グラフ（spanning subgraph）という。 抜き出した頂点間に定義される辺がすべて含まれているような部分グラフをE′ が誘導する部分グラフ（subgraph induced by E′）という。 パスや閉路を構成する頂点・辺の集合も部分グラフの一種である。 辺の性質による分類 有向グラフ・無向グラフ（directed graph / undirected graph） 辺に方向が与えられているグラフを有向グラフ、与えられていないグラフを無向グラフという。 重み付きグラフ・ネットワーク（network） 辺にコストが与えられているグラフを重み付きグラフ・ネットワークという。 単純グラフ（simple graph） 閉路・多重枝を含まないグラフを単純グラフという。 形状による分類 完全グラフ すべての二頂点間に辺が存在するグラフを完全グラフという。 連結グラフ 無向グラフのうちすべての二頂点間でパスが存在するグラフを連結グラフという。 木（tree） グラフのうち連結かつ閉路を持たないグラフを木という。 また、有向グラフからなる木を有向木といい、有向木に根となる頂点（その他のすべての頂点へ有向路を持つ頂点）が存在する場合とくに根付き木（rooted tree）という。 木において辺が1つだけ接続されている頂点を葉（leaf）という。 単に閉路を含まないようなグラフは木の集合によって表されるグラフであり、これを森（forest）という。 また、あるグラフの全域部分グラフが木である場合、全域木（spanning tree）と呼ぶことがある。 ある連結グラフが木であるかの判定には |V|−1=|E| を満たすかを調べれば良い。 2部グラフ（bipartite graph） 頂点を2つのグループに分けたとき、グループ内の頂点同士の間に辺が存在しないグラフを2部グラフという。 平面グラフ（planar graph） 平面上に枝を交差させることなく描画できるグラフを平面グラフという。 双対グラフ（dual graph） 平面グラフ G=(V,E) に対して次の操作を行うことで得られるグラフ G∗=(V∗,E∗) を双対グラフという。 G の辺 e で分割された平面の各領域に頂点 v∗k を1つずつ置き、その集合を V∗ とする G の辺 e の右側の領域にある頂点 v∗i から左側の領域にある頂点 v∗j へ辺を追加し、その集合を E∗ とする 双対グラフは明らかに平面グラフである。 双対グラフは次の性質を満たす。 平面グラフ G=(V,E) について C⊆E が閉路（有向閉路）の枝集合である⇔　C は双対グラフ G∗=(V∗,E∗) 上の極小なカット（極小な有向カット）と対応する 有向非巡回グラフ（Directed Acyclic Graph：DAG） 有向グラフのうち閉路を持たないグラフを有向非巡回グラフ（DAG）という。 DAGは次のような性質を持つ。 頂点の集合が半順序関係を持つ トポロジカルソートが行える トポロジカルソート 順序関係の早い方から小さい値をつけて行く作業をトポロジカルソートという。 この作業によって順序が確定しない頂点同士にも順序が与えられるため、半順序関係を満たすような全順序関係の1つを求める作業であるともいえる。 "},"mathematical_programming/graph_theory/flow.html":{"url":"mathematical_programming/graph_theory/flow.html","title":"フロー","keywords":"","body":"フロー（flow） 定義 ネットワークに何らかのもの（車・情報・水・製品など）を流すことを考えるとき、この流れをフローという。 フローは有向辺に沿って流れ、頂点で分岐・合流するものとして考える。 以後、各辺の流量を与える関数を φ:E→R と書くことにする。 容量制約（flow bound constraint） 一般的に、フローを考えるときそのネットワークの辺にはコストとして容量制約を設ける。 すなわち、ある辺の容量制約を与える関数を u:E→R とすれば、 0≤φ(ek)≤u(ek) が常に成立することが問題への制約条件となる。 この条件を満たすようなフローを実行可能流（feasible flow）または可能流という。 とくにすべての頂点の供給量が 0 であるような可能流を循環流（circulation flow）という。 流量保存則（mass balance constraint） フローが供給点と需要点以外で出現・消失することはありえないので、各頂点の供給量・流入量・需要量・流出量の収支は一致するはずである。 これを流量保存則といい、次のように表す。  ∀v∈V(∑e∈∂+vφ(e)−∑e∈∂−vφ(e)=b(v)) ∑v∈Vb(v)=0 0\">b(vk)>0 は供給点、b(vk)0 は需要点、b(vk)=0 は中継点であることを示している。 フロー分解定理（flow decomposition theorem） フローに関して次のような定理を記述できる。 有向グラフ G=(V,E) 上の任意の非負のフローを φ とする⇒　有向閉路 Qk 上のフローと 0\">∂φ(v)>0 である頂点から ∂φ(v)0 である頂点への有向路 Pk 上のフローに分解できる このように任意の非負のフロー φ をいくつかの有向閉路上のフローと有向路上のフローに分けることをフローの同符号分解（flow equisignum decomposition）という。 "},"mathematical_programming/graph_theory/matroid.html":{"url":"mathematical_programming/graph_theory/matroid.html","title":"マトロイド","keywords":"","body":"マトロイド（matroid） 参考：http://www.ieice-hbkb.org/files/12/12gun_02hen_05.pdf マトロイドはベクトル空間におけるベクトル集合の一次独立・従属といった概念の組み合わせ論的な側面を抽象化した系である。 定義 有限集合 E とその部分集合族 I⊂2E の組 M=(E,I) が ∅∈I A⊂B∈I⇒A∈I A,B∈I, |A||B| ⇒ ∃b∈B∖A (A∪{b}∈I) を満たすとき、これをマトロイドといい、E を台集合（ground set）、I を独立集合族という。 また独立集合族の元 A∈I を独立集合（independent set）という。 条件1は空集合を含むことを示している。 条件2は I に含まれる集合の冪集合も I に含まれることを示している。 例えば {1,2,3}∈I なら {∅,{1},{2},{3},{1,2},{2,3},{1,3},{1,2,3}}⊂I である。 条件3は I から要素数の異なる2つの元を選び出すと、要素数の大きい方にしか含まれていない元（要素）のどれかを選んで要素数の小さい方に追加してできる集合も I に含まれていることを示している。 例えば {{1},{1,2,3}}⊂I なら {1,2},{1,3} のどちらかが I に含まれていなければならない。 また、I に選ばれなかった部分集合 A∈2E∖I を従属集合という。 基（base） 独立集合族 I の中で包含関係で極大であるものを基といい、基の集合 B を基族という。 上記の条件2より、ある I のすべての基の要素数は一致するのは明らかである。 基の要素数 n をマトロイド M の階数（rank）という。 マトロイド M の基族 B={B1,⋯,Bn} がわかれば、各基の冪集合の和集合を取ることで独立集合族を I=⋃ni=12Bi のように表せる。 この意味でマトロイドの「基」と呼んでいる。 例えばマトロイド M=(E,I) が E={1,2,3}, I={{1},{2},{3},{1,2},{2,3},{1,3}} であるとき、基族は {{1,2},{2,3},{1,3}} であり、階数は 2 である。 基族に対する定理 マトロイドの定義に従えば、基族であるための必要十分条件は次の2つの条件が成立することである。 B≠∅ A,B∈B, b∈A∖B ⇒ ∃e∈B∖A ((A∖{b})∪{e}∈B) マトロイドの定義を変形していけば導ける。 階数関数 任意の部分集合 X⊂E に対してマトロイドの階数関数 ρ:eE→Z を次のように定義する。 ρ(X)=max{|I| | I⊂X∧I∈I}=max{|I| | I∈2X∧I∈I} この関数は次のような性質を満たす。 ρ(∅)=0 ∀X⊂E (ρ(X)≤|X|) X⊂Y⇒ρ(X)≤ρ(Y) ∀X,Y⊂E (ρ(X)+ρ(Y)≥ρ(X∩Y)+ρ(X∪Y)) 特に4は劣モジュラ性（submodularity）と呼ばれる性質であり、マトロイドに関する効率的なアルゴリズムの存在に深く関与している。 サーキット（circuit） 従属集合のうち包含関係で極小のものをサーキットといい、C で表す。 サーキットは次の性質を満たす。 ∅∉C A,B∈C, A⊂B ⇒ A=B A,B∈C, j∈A∩B ⇒ ∃C∈C (C⊂(A∪B)∖{j}) 閉包関数（closure function） 任意の部分集合 X⊂E に対して cl(X)={j | ρ(X)=ρ(X∪{j})} と定義される関数を閉包関数という。 つまり、ある部分集合に追加しても階数が変わらないような要素の集合を示す関数である。 閉包関数は次の性質を満たす。 ∀B∈B (cl(B)=E) ∀I∈I ∀j∈cl(I)∖I (I∪{j}∈2E∖I) 基本サーキット（fundamental circuit） 閉包関数の性質2で示した従属集合 I∪{j} はただ1つのサーキットを含む（サーキットの性質3より）。 このサーキットを基本サーキットといい、C(I|j) と表す。 すなわち C(I|j)={i | (I∪{j})∖{i}∈I} (I∈I, j∈cl(I)∖I) である。 双対マトロイド（dual matroid） マトロイド M=(E,I) の基族 B に対して B∗={E∖B | B∈B} を定義すると、B∗ も基族の性質を満たす。 これを基族とするマトロイド M∗=(E,⋃nB∗=B∗2B∗) を双対マトロイドという。 元のマトロイドの階数関数と双対マトロイドの階数関数の関係は次のように表される。 ρ∗(X)=|X|+ρ(E∖X)−ρ(E) 双対マトロイドにおけるサーキット C∗ を M のコサーキット（cocircuit）という。 任意のサーキット C と任意のコサーキット C∗ に対して |C∩C∗|≠1 となる。 また、定義から明らかなようにコサーキットはすべての基と空でない交わりを持っている。 任意の基 B∈B とその要素 b∈B に対して、C∗∩B={b} となるコサーキットが一意に存在する。 このコサーキットを B と b に関する基本コサーキットといい、C∗(B|b) と表す。 すなわち、 C∗(B|b)={e | (B∖{b})∪{e}∈B} (b∈B∈B) である。 例 例1 台集合：E={1,2,3,4} 独立集合：I={ ∅,{1},{2},{3},{1,2},{1,3},{2,3} } 従属集合：E∖I= { {4},{1,4},{2,4},{3,4},    {1,2,3},{1,2,4},{1,3,4},{2,3,4},{1,2,3,4} } 基：B={ {1,2},{1,3},{2,3} } 階数関数 {X∈2E | ρ(X)=0}={ ∅,{4} } {X∈2E | ρ(X)=1}={ {1},{2},{3},{1,4},{2,4},{3,4} } {X∈2E | ρ(X)=2}={ {1,2},{1,3},{2,3},{1,2,3},{1,2,4},{1,3,4},{2,3,4},{1,2,3,4} } サーキット：C={ {1,2,3},{4} } 基本サーキットの例 C({∅}|1)={1} C({1}|4)={4} C({1,2}|3)={1,2,3} C({1,2}|4)={4} 双対マトロイドの基族：B∗={ {1,4},{2,4},{3,4} } コサーキット：C∗={ {1,2},{1,3},{2,3} } 基本コサーキットの例 C∗({1,2,3}|3)={3} C∗({4}|4)={4} 例2 台集合：E={1,2,3,4} 独立集合：I={ ∅,{1},{2},{3},{4},{1,3},{1,4},{2,3},{2,4} } 従属集合：E∖I= { {1,2},{3,4},{1,2,3},{1,2,4},   {1,3,4},{2,3,4},{1,2,3,4} } 基：B={ {1,3},{1,4},{2,3},{2,4} } 階数関数 {X∈2E | ρ(X)=0}={ ∅ } {X∈2E | ρ(X)=1}={ {1,2},{3,4} } {X∈2E | ρ(X)=2}={ {1,3},{1,4},{2,3},{2,4},{1,2,3},{1,2,4},{1,3,4},{2,3,4},{1,2,3,4} } サーキット：C={ {1,2},{3,4} } 基本サーキットの例 C∗({∅}|1)={1} C∗({1,3}|2)={1,2} C∗({1,3}|4)={3,4} 双対マトロイドの基族：B∗={ {1,2},{3,4} } コサーキット：C∗={ {1,3},{1,4},{2,3},{2,4} } 基本コサーキットの例 C∗({1,3}|1)={1,2} C∗({1,3}|3)={3,4} C∗({2,3}|2)={1,2} C∗({2,3}|3)={3,4} "},"mathematical_programming/graph_theory/graph_matroid.html":{"url":"mathematical_programming/graph_theory/graph_matroid.html","title":"グラフとマトロイド","keywords":"","body":"グラフとマトロイド グラフとマトロイドの関係について言及する。 グラフ的マトロイド（graphic matroid） 無向グラフ G=(V,E) を考える。 枝集合の部分集合のうち閉路を含まないものの集合を I⊂2E とすると、M(G)=(E,I) はマトロイドになり、これをグラフ的マトロイドという。 例 V={A,B,C,D} E={1,2,3,4} graph LR V1((A)) ---|\"( 2 )\"| V2((C)) V2 ---|\"( 4 )\"| V4((D)) V1 ---|\"( 1 )\"| V3((B)) V3 ---|\"( 3 )\"| V2 基族：B={ {1,2,4},{1,3,4},{2,3,4} } 全域木に相当する サーキット：C={ {1,2,3} } 閉路に相当する 基本サーキットの例 C({1,2,4}|3)={1,2,3} C({1,3,4}|2)={1,2,3} C({1,2}|3)={1,2,3} 双対マトロイドの基族：B∗={ {1},{2},{3}} } コサーキット：C∗={ {1,2},{1,3},{2,3},{4} } カットセットに相当する （書きかけ） 横断マトロイド（transversal matroid） 2部グラフ G=(V1,V2;E) を考える。 一方の点集合 V1 のうちマッチングの端点になり得るもの全体を I⊂2V1 とすると、M(G)=(V1,I) はマトロイドになり、これを横断マトロイドという。 "},"mathematical_programming/graph_theory/minimum_spanning_tree_problem.html":{"url":"mathematical_programming/graph_theory/minimum_spanning_tree_problem.html","title":"最小木問題","keywords":"","body":"最小木問題（minimum spanning tree problem） 問題 連結な無向グラフ G=(V,E) と各辺の重み w:E→R があるとき、枝の重みが最小となる全域木を求める問題を最小木問題という。 また、このときの全域木を最小木と呼ぶ。 全域木の性質 G の全域木 T=(V,F) について、以下は同値な条件である。 T=(V,F) は木である 全域木の定義 T=(V,F) は閉路を含まないが、F に属さない辺 e∈E∖F を1本加えるとただ1つの閉路を持つ この閉路を基本閉路（fundamental cycle）といい、その辺集合を C(T|e) と表す T=(V,F) は連結であるが、任意の辺を1本取り除くと連結でなくなる 連結でなくなった2つの木の頂点同士を結ぶような辺の集合を基本カット（fundamental cut）といい C∗(T|e) と表す（取り除いた辺も含まれる） これを利用すれば次のような操作で別の全域木を得ることができる。 基本閉路の任意の辺 e′∈C(T|e) に対し、F∪{e}∖{e′} の誘導する部分グラフも全域木である 基本カットの任意の辺 e′∈C∗(T|e) に対し、F∖{e}∪{e′} が誘導する部分グラフも全域木である 閉路最適性条件 基本閉路に注目したときの最適性条件は次のように与えられる。 連結グラフ G=(V,E) 上の全域木 T が最小木である⇔　任意の辺 ∀e∈E∖F, ∀a′∈C(T|e) (w(a)≥w(a′)) すなわち、どの基本閉路を追加しても総コストがこれ以上小さくならないことが最適性条件である。 カット最適性条件 基本カットに注目したときの最適性条件は次のように与えられる。 連結グラフ G=(V,E) 上の全域木 T が最小木である⇔　∀e∈F, ∀e′∈C∗(T|e) (w(e)≤w(e′)) すなわち、どの辺を削除して基本カットの1本につなぎ替えるにしても総コストがこれ以上小さくならないことが最適性条件である。 最小木アルゴリズム 最小木問題を解くアルゴリズムとしてはPrim法とKruskal法が有名。 "},"mathematical_programming/graph_theory/single_source_shortest_path_problem.html":{"url":"mathematical_programming/graph_theory/single_source_shortest_path_problem.html","title":"単一始点最短経路問題","keywords":"","body":"単一始点最短経路問題（single source shortest path problem） 定義 有向グラフ G=(V,E) と各枝の長さ l:E→R と始点 s∈V が定まったもとで、s から到達可能な各頂点への最短路とその長さを、もし負閉路が存在して無限に小さな経路が存在するときはその負閉路の1つを出力する問題。 最短路長に関する三角不等式 有向グラフ G=(V,E) において、s から各頂点 v∈V までのある有向路長（有向路が存在しない場所も長さ +∞ の有向路として考える）を d(v) とする。 このとき以下の定理が成立する。 すべての頂点について d(v) が始点 s からの最短路長である⇔　∀e∈E (d(∂−e)≤d(∂+e)+l(e)) この式は最短路長に関する三角不等式と呼ばれる。 この定理をある有向路 Pv に限って適用すれば、次の系を得る。 ただし、頂点 v までの最短路長を d∗(v) とする。 ある有向路が始点 s から終点 v までの最短路である⇔　∀e∈E(Pv) (d∗(∂−e)=d∗(∂+e)+l(e)) すなわち、その有効路に含まれるすべての辺で三角不等式が等号で成り立てば、有向路は最短路であることを示している。 この定理を始点から再帰的に適用していくことで問題を解くことができる。 解法 単一始点最短経路問題の解法としてダイクストラ法とベルマンフォード法がある。 これらの詳細はアルゴリズムの項目で解説する。 "},"mathematical_programming/graph_theory/maximum_flow_problem.html":{"url":"mathematical_programming/graph_theory/maximum_flow_problem.html","title":"最大流問題","keywords":"","body":"最大流問題（maximum flow problem） フロー（流量）の最大化を目的とした問題について言及する。 定義 有向グラフ G=(V,E) と各辺の正の容量 u:E→R++ と供給点（source）s∈V ・需要点（sink）t∈V が与えられたとき、流量最大の可能流を求める問題を最大流問題もしくは最大フロー問題という。 最小カット（minimum cut） グラフを始点側と終点側に分割する、すなわち s∈X, t∉X を満たす頂点の部分集合を X⊂V としたとき、∂(X) を s-tカット という。 s-tカットの容量を κu(X)=∑e∈∂+(X)u(e) としたとき、これが最小であるカットを最小カットという。 流量保存則と容量制約より任意のs-tカットの容量は始点からの供給量以上でなければならなず、最小カットはグラフ上のボトルネックを示しているため、最小カットの容量を調べれば最大流量と一致する。 定理の証明 流量保存則より ∂φ(s)=∂φ(s)+∑v∈X∖{s}∂φ(s)=∑v∈V∂φ(v)=∑e∈∂+(X)φ(e)−∑e∈∂−(X)φ(e) すなわち、任意のs-tカットの容量と s からの供給量 ∂φ(s) の間で ∂φ(s)≤κu(X) が成り立つ。 次に任意のフロー φ に対して補助ネットワーク（auxiliary network）（あるいは残余ネットワーク（residual network））を次のように定義する。 0\\} \\\\ e^r = (\\partial^- e, \\partial^+ e)\\end{cases} \\end{eqnarray} \"> Nφ=(Gφ=(V,Eφ),uφ) ⎧⎪⎨⎪⎩Eφ=EFφ∪EBφEFφ{e∈E | φ(e)u(e)}, EBφ{er | e∈E,φ(e)>0}er=(∂−e,∂+e) これは、現在のフローについて容量制約に余裕がある辺（流量を追加できる辺）とフローの存在する辺（流量を削ることができる辺）を考えたものである（結局グラフ上のすべての辺が AFφ と ABφ のどちらかに属する）。 また、補助ネットワークから次のような残余容量（residual capacity） uφ:Eφ→R を定義する。 uφ(e)={u(e)−φ(e)(e∈EFφ)φ(er)(e∈EBφ) ここで現在のフローに補助ネットワーク上のあるフロー ψ を追加して得られるフロー φ⊕ψ は次のように表される。 (φ⊕ψ)(e)=⎧⎪⎨⎪⎩φ(e)+ψ(e)−ψ(er)(e∈EFφ,er∈EBφ)φ(e)+ψ(e)(e∈EFφ,er∉EBφ)φ(e)−ψ(er)(a∉EFφ,er∈EBφ) ここで、ψ が補助ネットワーク上の s から t への有向路であるとき、ψ を増加路（augmenting path）という。 ここで最大流の最適性条件は次のように表される。 可能流 φ が最大流⇔　補助ネットワーク Nφ 上に増加路が存在しない⇔　容量制約を等式で満たす辺（制約容量に余裕がない辺）が1つは存在する⇔　最小カットが容量制約を等式で満たす 最大流アルゴリズム 最大流問題には様々なアルゴリズムが存在するが、大きく2通りに分類できる。 補助ネットワーク上で増加路を探索し、可能流の流量を増加させていく方法（増加路法） 流量保存則を緩和し各頂点に流量が留まることを許したフローを用いて辺ごとにフローを更新し、流量保存則を満たすフローを見つける方法（プリフロー・プッシュ法） 増加路法（augmenting path method） 基本的な手順は以下のようになる。 φ(e):=0(∀∈E) とする 補助ネットワーク Nφ=(Gφ=(V,Eφ),uφ) を計算し、増加路 P を探す 増加路が見つからなければ終了する 増加路の残余容量の和 ε=min{uφ(e) | e∈Eφ(P)} を求め、φ:=φ⊕(ϵ⋅χP) と更新する 2~4を繰り返す 増加路はどれを選択してもよく、増加路の選択が異なれば得られる最大流も異なる場合がある。 問題はどのように増加路を探索するかであり、この探索方法によってさらにいくつかのアルゴリズムに分類される。 最大容量増加路法 手順2において常に増加路の残余容量の和 ε が最大になるように増加路を選択する手法。 このような増加路の探索はボトルネック最短路問題に帰着するため弱多項式時間アルゴリズムとなる。 辺の容量の最大値を U=max{u(e) | e∈E} とすれば、時間計算量について以下の定理が成り立つ。 すべての辺の容量が正数　⇒　最大容量増加路法の繰り返し回数は O(mlog(nU)) プリフロー・プッシュ法（preflow-push method） プリフロー・プッシュ法では各頂点について次のような残存量（excess/deficit）を定義する。 fφ(v)=∑e∈∂−vφ(e)−∑e∈∂+vφ(e) s,t 以外の頂点の残存量が非負であるフローをプリフローと呼ぶ。 また、残存量が正である点を活動頂点・活性点（active vertex）という。 プリフロー φ に対して d:V→Z+ が補助ネットワークの各辺 e∈Eφ で d(∂+e)≤d(∂−e)+1 を満たし、d(s)=n であるときフローの距離ラベル（distance label） という。 また、この式を等式で満たす辺を可能辺（admissible arc / eligible arc）という 基本的な手順は以下のようになる。 φ(e):=u(e) (∀e∈∂+s) , φ(e):=0 (∀e∈E∖∂+s) , d(s):=n , d(v):=0 (∀v∈V∖{s}) とする 活性点 v を選択 活性点がなければ終了 v を始点とする可能辺 a∈Eφ を探す 可能辺が存在すれば、e∈EFφ のときは φ(e):=φ(e)+min{fφ(v),uφ(e)} と更新し、e∈EBφ のときは φ(ar):=φ(ar)−min{fφ(v),uφ(e)} と更新する 可能編が存在しなければ d(v):=min{f(∂−e) | e∈Eφ,e∈∂+v}+1 と更新する 2~6を繰り返す "},"mathematical_programming/graph_theory/bipartite_matching.html":{"url":"mathematical_programming/graph_theory/bipartite_matching.html","title":"2部グラフのマッチング問題","keywords":"","body":"2部グラフのマッチング問題 定義 2部グラフ G=(V1,V2;E) が与えられたとき、要素数の最大のマッチングを求める問題を2部グラフのマッチング問題という。 2部グラフのマッチング問題は下図のように始点 s と終点 t を付け加え、すべての辺の容量を1としたグラフ ~G の最大流問題に帰着できる。 graph LR; subgraph V1 a1((a1)) a2((a2)) a3((a*)) end subgraph V2 b1((b1)) b2((b2)) b3((b*)) end a1 --> b1 a1 --> b2 a2 --> b2 a3 --> b3 s --> a1 s --> a2 s --> a3 b1 --> t b2 --> t b3 --> t Dinitzの増加路法を利用することで、最悪時間計算量は O(√nm) になる。 ケーニヒの定理（Kőnig theorem） 最大マッチング問題の双対問題である最小頂点被覆問題を利用した方法。 頂点被覆（vertex cover） 部分集合 W⊂V が頂点被覆であるとは頂点の ∀e∈E (∂+e∈W∨∂−e∈W) を満たすこと、すなわちすべての辺が W 中の頂点のどれかとつながっていることをいう。 任意のマッチング M⊂E と任意の頂点被覆 W⊂V の間には |M|≤|W| の関係が成立する。 ケーニヒの定理によると次の性質が成立する。 2部グラフにおける最大マッチングの辺数は最小頂点被覆の頂点数に等しくなる "},"mathematical_programming/graph_theory/graph_expression.html":{"url":"mathematical_programming/graph_theory/graph_expression.html","title":"プログラムにおけるグラフ表現","keywords":"","body":"プログラムにおけるグラフ表現 プログラムにおいてグラフ構造を表現する方法について言及する。 手法としては主に次の2種類に分類される。どちらにも長所・短所があるため、ケースバイケースで使い分ける。 隣接行列 |V|×|V|の二次元配列に辺の情報を格納する手法。 頂点i->jの辺の有無（0/1）もしくはコストをテーブルの値として格納する。 重み付きグラフでは辺が存在しない箇所をコスト無限（INF）として処理する。 隣接リスト 構造体などのリストに辺の情報を格納する手法。 構造体のフィールドは自由に設定できるため、方向・コスト以外の情報を持たせることも可能。 比較 隣接行列 隣接リスト メモリ使用量 O(V2) O(E) アクセス時間 O(1) O(logn) 多重辺・ループの表現 ✖ 〇 実装の複雑さ 単純 複雑 "},"mathematical_programming/linear/intro.html":{"url":"mathematical_programming/linear/intro.html","title":"概要","keywords":"","body":"線形計画問題（Linear Programming Problem） 定義 制約付き最適化問題のうち、f(x),gi(x),hj(x) のすべてが1次式である場合、この最適化問題を線形計画問題（LP問題）という。 線形計画問題は行列を用いて次のように表現できる。 minimize: cTxs.t. ⎧⎪ ⎪⎨⎪ ⎪⎩Ax=aBx≤bA∈Rm×n, B∈Rl×n, a∈Rm, b∈Rl, c∈Rn, x∈Rn 制約付き最適化問題（constrained optimization） minimize: f(x)s.t. ⎧⎪ ⎪ ⎪⎨⎪ ⎪ ⎪⎩gi(x)=0   (i=1,…,m)hj(x)≤0   (j=1,…,l)f:Rn→R, gi:Rn→R, hi:Rn→R 標準形 先ほどの式において xi は自由変数であるが、正負がはっきりしないと解く手順の中で場合分けが必要になってしまう。そこで xi=x′1−x′2   (x′1,x′2≥0) のように未知変数を1つ増やすことですべての未知変数が正であるものとして扱えるようになる。 また、不等式制約についても Ajixi≤ai⇔Ajixi+x′1=ai のように未知変数を1つ増やすことで等式制約に変換できる。 このとき追加した未知変数を特に スラック変数 と呼ぶ。 以上を踏まえて新たに A,B,a,b,c,x,l,m,n を置き直すと、 minimize: cTxs.t. ⎧⎪ ⎪⎨⎪ ⎪⎩Ax=bxi≥0A∈Rm×n, b∈Rm, c∈Rn, x∈Rn となる。 これを線形計画問題の標準形という。 解法（m≥n のとき） 制約条件が過分に設定されている場合（m≥n）、行列 A の右に b を結合した行列（拡大係数行列）を行に関して基本変形し、 左上側のn×nの小行列が単位行列 n 行目より後の行が 0 ベクトル を満たせば、最も右側の列ベクトルが条件を満たす唯一の解となる。 満たさない場合は解が存在しない。 解法（mn のとき） 制約条件が不足している場合（mn）、解は領域として存在しその中から最適な点を選択しなければならない。 そのため、単体法などの手法を用いることになる。 用語の整理 最適解（optimal solution） 目的関数を最小にする実行可能解を 最適解 という。 実行可能解・実行可能領域（feasible region） 制約条件を満足するような x を 実行可能解（feasible solution） といい、すべての実行可能解の集合 S={x∈Rn|Ax=b,x≥0} を実行可能領域という。 基底行列・基底変数（basis matrix / basic variable） 等式制約の係数行列 A から m=rank(A) 本の線形独立な列ベクトルを1組選んだとき、それらを並べて作る正則行列を B∈Rm×m とおいて基底行列といい、それに対応する m 個の変数 xi を基底変数という。 逆に選ばれなかった n−m 個の変数 xi を非基底変数（nonbasic variable）という。 Ax=b[BN][xBxN]=b 基底解（basic solution） 上の式で非基底変数がすべて0であると仮定すると、 Ax=b[BN][xB0]=bx=[xBxN]=[B−1b0] のように解が求まる。 このように m=rank(A) 個の基底変数を選び、非基底変数を0として得た解を基底解と呼ぶ。 実行可能解かつ基底解であるものを特に実行可能基底解と呼ぶ。 実行可能基底解については次の2つの定理が知られている。 実行可能解が存在する　⇒　実行可能基底解が存在する最適解が存在する　⇒　実行可能基底解の中に最適解が存在する よって、実行可能基底解を順に調べれば最適解が得られる。 n 個の変数から m 個の基底変数を選ぶ作業に相当するため、実行可能基底解の数は高々  nCm 個である。 退化（degenerate） 基底解を得たとき、非基底変数だけでなく基底変数の中にも0の値をとるものがあるとき、退化しているという。 逆に基底変数がすべて非零であるとき（ 0, x_N = 0\">xB>0,xN=0）、非退化（non-degenerate）であるという。 基底形式（basic form） x を基底解、つまり x=[xBxN]=[B−1b0] とする。 B が正則行列であることを利用して問題を xN の一次式として書き直すと minimize: cTBB−1b+(cTN−cTBB−1N)xNs.t. {xB=B−1b−B−1NxNxB≥0,   xN≥0 のようになる。 この式を基底形式といい、¯cTN=cTN−cTBB−1N を相対費用係数という。 単体乗数（simplex multiplier） 基底解 x を得たとき、 cTx=cT[B−1b0]=cTBB−1b=(B−1)TcBb が成り立つ。 このときの (B−1)TcB を単体乗数という。 "},"mathematical_programming/linear/dual_problem.html":{"url":"mathematical_programming/linear/dual_problem.html","title":"双対問題","keywords":"","body":"双対問題（dual problem） 定義 標準形の線形計画問題を主問題として minimize: bTys.t. ATy≤c もしくは maximize: bTys.t. {ATy+z=cz≥0 で表される問題を双対問題という。 また、このときの変数 y,z は双対変数という。 主問題と双対問題の間には次のような関連性がある。 弱双対定理 ¯x と ¯y がそれぞれ主問題と双対問題の実行可能解であるならば cT¯x≥bT¯y が成立する。 証明 cTx=(ATy+z)Tx=yTAx+zTx=yTb+zTx=bTy+zTx 実行可能なら z≥0 となるため cT¯x≥bT¯y 双対定理 主問題が実行可能解を持ち最適値 f をとる　⇔　双対問題が実行可能解を持ち最適値 f をとる 主問題の最適解に対して、双対問題の最適解はそれに対応する単体乗数 (B−1)TcBb となる 証明 主問題の最適解 x∗ は弱双対定理を満たす最小の値であるはずなので、 cTx∗=max{bTy} 右辺は双対問題の最適解に他ならないため、 cTx∗=bTy∗ が成立することがわかる。 この式を基底解と非基底解に分割して考えると、 cTBxB+cTNxN=bTycTBB−1b=bTyy=(B−1)TcBb となる（∗ は省略）。 まとめ 上記の定理の他に主問題・双対問題の性質を加えまとめると以下のようになる。 主問題・双対問題がともに実行可能解を持つならそれは各々の最適解であり、その最適値は一致する 双対問題の最適解は主問題の最適解に対応する単体乗数 主問題が実行可能で非有界　⇔　双対問題は実行不可能 主問題が実行不可能　⇔　双対問題は実行可能だが非有界 "},"mathematical_programming/linear/simplex_method.html":{"url":"mathematical_programming/linear/simplex_method.html","title":"シンプレックス法","keywords":"","body":"単体法（シンプレックス法：simplex method） 概要 線形計画問題は 実行可能基底解を1つ見つける 「見つけた実行可能基底解より目的関数値が小さくなる実行可能基底解を探す」を繰り返す というアルゴリズムによって最適解を求めることができる。 シンプレックス法は2番の手順を効率よく実現した解法である。 原理 理論を追いやすくするため、記号の置き換えは最小限に留めて解説する。 次のような線形計画問題について考える。 minimize: cTBxB+cTNxNs.t. {BxB+NxN=bxB,xN≥0 このとき双対問題は minimize: bTys.t. ⎧⎨⎩BTy+zB=cBNTy+zN=cNzB,zN≥0 のように表される。 この問題について、なんらかの方法で実行可能基底解 x∗=[xBxN]=[B−1b0]≥0 が1つ得られているものとする。 最適解であるかの検証 まず、現在の解が最適解であるかを確認する。 x∗が最適解であると仮定すれば、双対定理より cTx∗=bTy が成立するため、 y=(BT)−1cB,  zB=0,  zN=cN−NT(BT)−1cB となる。 もし zN≱0 ならば、双対問題が実行不可能な解を持っていることになるため双対定理が満たされず、x∗ が最適解であるという仮定は成り立たない。 逆に 0\">zN>0 ならば、双対問題も同じ評価値の実行可能解を持ち、双対定理を満たすことから x∗ は最適解であることがわかるためここで終了する。 もし 0\">zN>0 かつ (zN)q=0 となる要素があれば、同じ最適値を持つ基底解が複数存在することになる。 (xN)q を基底変数に取り込めば別の最適基底解が得られる。 この作業を繰り返して得られるすべての最適基底解が囲む線分・平面・超平面が最適解となる。 このときの zN を相対費用係数といい、zN≥0 を最適性基準という。 基底変数に取り込む非基底変数を選択 最適解でなかった場合、zN の負の要素の中から値が最小である (zN)q を基底変数に取り込むことにする（負の要素ならどれを選んでも良いが、問題が退化している場合は後述するように添え字が最小のものを選ぶことで巡回対策とする）。 (zN)q=min{(zN)k | (zN)k0, 0≤k≤n−m} この q に合わせて問題を基底形式で表現する。 minimize: cTBB−1b+(zN)qxqs.t. xB=B−1b−B−1Nqxq ただし Nq は xq に対応する N の列ベクトルを指す。 問題が有界であるかの検証 もし −B−1Nq≥0 であれば、ある (xB)k と xq をともに大きくすることで制約条件を満たしながら評価値を無限に小さくできる。 この場合は解が有界でないという結論が得られるためここで終了する。 基底変数の入れ替え (−B−1N)kq0 となる要素がある場合、制約条件のもとで xk を小さく、xq を大きくしていけば評価値は小さくなるはずである。x≥0 の制約条件を考慮すると、結局は1つの基底変数 xp を外し（xp:α→0）、かわりに非基底変数 xq を基底変数に加えればよいことになる（xq:0→β）。 制約条件 xB=B−1b−B−1Nqxq を考慮すると、xq が取りうる最大値βは β=(B−1b)p(B−1N)pq=min(−B−1N)iq0(B−1b)i(B−1N)iq となる（一意に p が定まらない場合どれを選んでも良いが、問題が退化している場合は後述するように添え字が最小のものを選ぶことで巡回対策とする）。 以上から新しい基底変数 x∗B と非基底変数 x∗N が求まり、評価値がより小さい実行可能基底解が得られる。 シンプレックス表 基底変数 (xB)1⋯(xB)m (xN)1⋯(xN)n−m 等式制約の定数 (xB)1(xB)2⋮(xB)m I(単位行列) B−1N B−1b 0    ⋯    0 (zN)1⋯(zN)n−m −ω ※ xk の並び順を自由に変更してよい（基底変数・非基底変数の列を入れ替えてもよい） 原理の1ステップを上記のような表にまとめたものをシンプレックス表・シンプレックスタブローと呼ぶ。 このような形にまとめることで、基底変数の入れ替えの作業が (−B−1N)kq をピボットとした掃き出しに置き換えられるため、計算をある程度単純化できる。 手順 (zN)q=min{(zN)k | (zN)k0, 0≤k≤n−m} を選ぶ 0\">(zN)q>0 なら最適解なので終了 列ベクトル B−1Nq に注目する B−1Nq≤0 なら解が有界でないため終了 0} \\frac{(B^{-1}b)_ i}{(B^{-1}N)_ {iq}}\">(B−1b)p(B−1N)pq=min(B−1N)iq>0(B−1b)i(B−1N)iq を選び、それをピボットとした掃き出しを行う Blandの巡回対策 問題が退化している場合、p,q を任意に選択すると同じ最適値を取る基底変数を巡回してしまうことがある。 この対策として、q の選択と、(B−1b)k(B−1N)kq が同じ値を取るものが複数あるときの p の選択では「添字が最小のものを選択する」というルールを定めればよいことが知られており、これをBlandの巡回対策という。 "},"mathematical_programming/linear/two_phase_method.html":{"url":"mathematical_programming/linear/two_phase_method.html","title":"2段階法","keywords":"","body":"2段階法（two phase method） シンプレックス法では最初に実行可能基底解が1つ求まっている状態からアルゴリズムを開始したが、問題によっては最初の実行可能基底解を得ること自体が困難である。 そこで、初期解を求めてからシンプレックス法を適用するのが2段階法である。 手順 bi≥0 となるよう制約条件の符号を調整する シンプレックス表を書き、基底形式に A の各列の和 di を用いて u=−d1x1−d2x2−⋯−dnxn+u0 としたものを目的関数と見てシンプレックス法の掃き出しを行う u0 はなんでもよいが u0=b1+b2+⋯+bm とすることが多い −u の行のベクトルが 0 になれば初期の実行可能基底解が得られている状態になるので w を目的関数と見てシンプレックス法の掃き出しを行う −u の行のベクトルが 0 にならなければ問題は実行不可能 原理 標準形の線形計画問題を考える。 ただし、bi≥0 になるよう制約条件の符号を調整してあるものとする。 minimize: cTxs.t. {Ax=bxi≥0 ここですべての要素が非負である人為変数（artificial variable） v を導入して minimize: cTxs.t. ⎧⎨⎩Ax+v=bxi≥0vi≥0 とする。 ここで A′=[AI]、x′T=[xTvT]、u=v1+v2+⋯+vm とすれば x,v を変数とする線形計画問題になる。 minimize: us.t. {A′x′=bx′i≥0 ここで xT0=[0,0,⋯,0]、vT0=[b1,b2,⋯,bm]、x′0T=[xT0vT0] とすれば、x′0 は明らかにこの問題の実行基底解である。 上記を初期解としてシンプレックス法を用いてこの問題の最適解を求めれば v=0、xi のいくつかが基底となる、元の問題に対する実行可能基底解が得られる。 逆に v=0 となる最適解が存在しなければ元の問題が実行不可能であることがわかる。 人為変数は一度基底変数から外れれば再び基底変数に選ばれることはないはずなので、シンプレックス表から省くことができる。 また、初期解の基底形式を求めれば u=cxx+cvv として zTN=cTx−B−1NcTv=B−1N⎡⎢ ⎢⎣1⋮1⎤⎥ ⎥⎦ となるので、目的関数は B−1N=A の i 列目の要素の和 di を取って u=−d1x1−d2x2−⋯−dnxn+u0 と記述できる。 u0 はなんでも良いが、b1+b2+⋯+bm としておけば最適解が u=0 になるため、定数項を u0=b1+b2+⋯+bm としておくことが多い。 "},"mathematical_programming/linear/post-optimization.html":{"url":"mathematical_programming/linear/post-optimization.html","title":"感度解析と再最適化","keywords":"","body":"感度解析と再最適化 minimize: cTBxB+cTNxNs.t. {BxB+NxN=bxB,xN≥0 ある線形計画問題の最適解が求まっているとする。 ここで、目的関数や制約条件が変化したときに最適解がどのように変化するかを調べることを感度解析（sensitivity analysis）という。 また、目的関数や制約条件が変化した問題の最適解をもとの問題の最適解から効率よく求める方法が知られており、これを再最適化（post-optimization）という。 最適解の表現 求まっている最適解における最適基底行列を B∗、最適非基底行列を N∗、最適変数を x∗=[x∗B0]、最適値を w∗ とする。 このとき次の条件を満たしているはずである。 x∗B=B∗−1b≥0,   w∗=c∗BTx∗B,   zN∗=cN∗−(B∗−1N∗)TcB∗≥0 目的関数の係数が変化した場合の再最適化 目的関数が cTx→(c+Δc)Tx と変化したとする。 このとき、新しい最適性基準 ^zN は ^zN∗=(cN∗+ΔcN∗)−(B∗−1N∗)T(cB∗+ΔcB∗)=zN∗+ΔcN∗−(B∗−1N∗)TΔcB∗ となり、新しい最適値 ^w は ^w=(cB∗+ΔcB∗)TxB∗=w∗+ΔcTB∗xB∗ となる。 よって次の結論を得る。 ΔcN∗−(B∗−1N∗)TΔcB∗≥0 なら最適性条件は満たされるため新しい最適値 ^w=w∗+ΔcTB∗xB∗ を得る 新しい最適性条件が満たされないなら単体法を適用して再最適化を行う 制約条件の定数項が変化した場合の再最適化 制約条件の定数項が b→b+Δb と変化したとする。 このとき、最適性基準は影響を受けず、新しい最適基底変数 ^xB∗ は ^xB∗=B∗−1(b+Δb)=xB∗+B∗−1Δb となり、新しい最適値 ^w は ^w=cTB∗B∗−1(b+Δb)=w∗+cTB∗B∗−1Δb となる。 よって次の結論を得る。 新しい最適基底変数について ^xB∗≥0 なら実行可能基底解であるため、^w=w∗+cTB∗B∗−1Δb が最適値になる 新しい最適基底変数が実行不可能なら双対単体法を適用して最最適化を実行する "},"mathematical_programming/linear/program.html":{"url":"mathematical_programming/linear/program.html","title":"線形計画問題を解くプログラム","keywords":"","body":"線形計画問題を解くプログラム Python いくつかライブラリが存在するが、LP問題に限ればPuLPが良さそう。 サンプル1 minimize:2x1+3x2s.t.⎧⎨⎩4x1+x2≥133x1+2x2≥16x1+2x2≥8x1≥0,   x2≥0 Python 3.6.1, PuLP 1.6.5 import pulp problem = pulp.LpProblem('sample', pulp.LpMinimize) x1 = pulp.LpVariable(name='x1', lowBound=0) x2 = pulp.LpVariable(name='x2', lowBound=0) problem += 2*x1 + 3*x2 problem += 4*x1 + x2 >= 13 problem += 3*x1 + 2*x2 >= 16 problem += x1 + 2*x2 >= 8 status = problem.solve() print(\"Status :\", pulp.LpStatus[status]) print() print(problem) print(\"Result\") print(\"cost :\", problem.objective.value()) for v in problem.variables(): print(v.name, v.value()) サンプル2 minimize:−4x1−5x2−2x3−8x4s.t.{2x1+2x2+x3+3x4≥5x1,x2,x3,x4∈{0,1} import pulp problem = pulp.LpProblem('sample', pulp.LpMaximize) x1 = pulp.LpVariable(name='x1', lowBound=0, upBound=1, cat=pulp.LpInteger) x2 = pulp.LpVariable(name='x2', lowBound=0, upBound=1, cat=pulp.LpInteger) x3 = pulp.LpVariable(name='x3', lowBound=0, upBound=1, cat=pulp.LpInteger) x4 = pulp.LpVariable(name='x4', lowBound=0, upBound=1, cat=pulp.LpInteger) problem += 4*x1+5*x2+2*x3+8*x4 problem += 2*x1 + 2*x2 + x3 + 3*x4 "},"mathematical_programming/nonlinear/unconstrained.html":{"url":"mathematical_programming/nonlinear/unconstrained.html","title":"無制約最小化問題","keywords":"","body":"無制約最小化問題 次の問題について考える。 minimize  f(x)   (x∈Rn)s.t. x∈D⊆Rn,   f:D→R 最適性条件 f(x) が x∗ の近傍で2回連続微分可能であるとき、次のことが成り立つ。 ∇f(x∗)=0 かつ ∇2f(x∗) が半正定値行列　⇔　x∗ は局所的最小解である。 また f(x) が凸関数であるとき x∗ は大域的最小解となる。 "},"mathematical_programming/nonlinear/equality_constrained.html":{"url":"mathematical_programming/nonlinear/equality_constrained.html","title":"等式制約付き最小化問題","keywords":"","body":"等式制約付き最小化問題 次の問題について考える。 minimize f(x)s.t. ⎧⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎨⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎩G(x)=⎛⎜ ⎜⎝g1(x1,…,xn)⋮gm(x1,…,xn)⎞⎟ ⎟⎠=0x∈D⊆Rn,   f:D→R,   gi,hi:D→R 最適性条件 x∗ で f,g は1回微分可能であるとする。 1次導関数に対する条件 x∗ が局所的最小解　⇒　x∗ は停留点（∂∂xif(x∗)=0となる点） ラグランジュ乗数法より、停留点は次の条件を満たす。 L(x,λ)≡f(x)−∑Mk=1λkgk(x) として ∂L∂xk=0, ∂L∂λk=0 これが局所的最小解であるための1次導関数に対する条件となる。 ただし逆は成立しない（停留点には極大点や鞍点などが含まれるため）。 2次導関数に対する十分条件 x∗ と λ∗ がKKT条件を満たし 0))\">∀y∈CF(x∗) ((y=0)∨(yT∇2xxL(x∗,λ∗)y>0)) を満たす⇒　x∗ は局所的最小解である 解法 実行可能領域 D において f(x)が 下に凸でない場合、有界でないために解が存在しなかったり、極小点でない境界上の点が解になったりするため、必ずしも局所的最小解が解になるとは限らない。 そのため、事前に関数の凸性を調べるなどの操作が必要になる。 局所的最小解の求め方 局所的最小解の候補となる停留点はラグランジュ乗数法を用いて導ける。 導き出された停留点についてヘッセ行列が正定値であるかを調べ、極小点であるか判定する。 "},"mathematical_programming/nonlinear/constrained.html":{"url":"mathematical_programming/nonlinear/constrained.html","title":"一般の制約付き最小化問題","keywords":"","body":"一般の制約付き最小化問題 次の問題について考える。 minimize f(x)s.t. ⎧⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎨⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎩G(x)=⎛⎜ ⎜⎝g1(x1,…,xn)⋮gl(x1,…,xn)⎞⎟ ⎟⎠≤0H(x)=⎛⎜ ⎜⎝h1(x1,…,xn)⋮hm(x1,…,xn)⎞⎟ ⎟⎠=0x∈D⊆Rn,   f:D→R,   gi,hi:D→R 有効制約式 不等式制約条件について、gi(x′)=0 であるとき、この制約式を x′ での有効制約式（active constraint）という。 以降、x′ の下での有効制約式を示すインデックスを i∈E(x′) と表記する。 最適性条件 x∗ において f,g は連続1階微分可能かつ2階微分可能であるとする。 1次導関数に対する条件 概要 1次導関数に対する条件は大まかに言えば次の形で示される。 x∗ が局所的最小解である⇒　（制約想定を満たす　→　x∗ についてKKT条件を満たすKKT乗数 (λ,μ) が存在する）が成立する つまり、制約想定が満たされる問題でのみKKT条件を最適性条件として利用することができる。 制約想定（constraint qualification） 厳密な制約想定はAbadieの制約想定と呼ばれる。 これを示すための前提知識は複雑なのでここでは省略する。 一般的にはAbadieの制約想定の十分条件であるものを用いる。 1次独立の制約想定（LICQ） ∇hi(x∗)  (i=1,⋯,m) と ∇gj(x∗)  (j∈E(x∗)) は一次独立 Slaterの制約想定 gj は凸関数であり、gi(^x)0  (j=1,⋯,l) となる ^x∈Rn が存在する MF（Mangasarian-Fromovitz）の制約想定 ∇hi(x∗)  (i=1,⋯,m) が一次独立で ∇hi(x∗)Ty=0  (i=1,⋯,m), ∇gj(x∗)Ty0  (j∈E(x∗)) を満たす y∈Rn が存在する それぞれの関係は「LICQ　⇒　MF　⇒　Abadie」、「Slater　⇒　MF」である。 なお、MFの制約想定を不等式制約のみの問題に制限したものをCottleの制約想定という。 Cottleの制約想定 ⟨∇gj(x∗),y⟩0  (j∈E(x∗)) を満たす y∈Rn が存在する KKT条件（Karush-Kuhn-Tucker condition） 次の条件をKKT条件という。 ⎧⎪⎨⎪⎩1:∇f(x∗)+∑mi=1λi∇hi(x∗)+∑lj=1μj∇gj(x∗)=02:h(x∗)=03:gj(x∗)≤0,  μj≥0,  μjgj(x∗)=0  (j=1,⋯,l) ラグランジュ関数 L(x,λ,μ)=f(x)+m∑i=1λihi(x)+l∑j=1μjgj(x) を用いれば次のように書き直すこともできる。 ⎧⎨⎩1:∇xL(x∗,λ,μ)=02:∇λL(x∗,λ,μ)=03:gj(x∗)≤0,  μj≥0,  μjgj(x∗)=0  (j=1,⋯,l) 条件1は目的関数 f(x) の等高線と制約条件の等高線が接していることを示している。 直感的に言えば、曲面を組み合わせて作った地形の上にボールを転がすとき、重力 −∇f(x) と曲面から受ける抗力 −λi∇hi(x),−μj∇gj(x) の和が釣り合う点が最も低い場所（局所的最小解）であることを示している。 条件2は等式制約条件を満たすことを示している。 ボールの例で言えば、曲面の上にレールが敷かれており、ボールはそのレールの上だけを転がることができる、ということを示している。 条件3は gj(x)=0 もしくは μj=0 のどちらかを満たすことを示しており、相補性条件と呼ばれる。 これは条件1にて、有効制約式は ∇gj(x) を考慮し、有効制約式でないものは μj=0 とすることで ∇gj(x) を考慮しないようにすることを示している。 ボールの例で言えば、ボールが最も低い場所にいるときに接していない曲面から受ける抗力は無視する、ということを示している。 また、関数の凸性を考慮すれば次の定理が成立する。 f,gi が凸関数で hi が準凸関数、かつ (x∗,λ∗,μ∗) がKKT条件を満たす⇒　x∗ は大域的最小解である このとき制約想定は不要である。 2次導関数に対する必要条件 x∗ が局所的最小解かつ x∗ でLICQが成立する⇒　∀y∈C(x∗) (yT∇2xxL(x∗,λ∗,μ∗)y≥0) 2次導関数に対する十分条件 (x∗,λ∗,μ∗) がKKT条件を満たし ∀y∈C(x∗) (yT∇2xxL(x∗,λ∗,μ∗)y≥0) を満たし、かつ 0 \\ \\ (j = 1,\\cdots,l)\">μ∗j−gj(x∗)>0  (j=1,⋯,l) を満たす⇒　x∗ は狭義の局所的最小解である ただし、 C(x)={y | ⟨∇hi(x),y⟩=0  (i=1,⋯,m) ∧ ⟨∇gj(x),y⟩=0  (j∈E(x))} である。 "},"dynamics/abstract/system_of_measurement.html":{"url":"dynamics/abstract/system_of_measurement.html","title":"単位系","keywords":"","body":"単位系（system of measurement） ここでは物理単位を表す組立単位系について言及する。 国際単位系（International System of Units : SI） 参考：https://www.nmij.jp/library/units/si/R8/SI8J.pdf 1875年に17カ国が締結したメートル条約により国際度量衡局（BIPM）が創設され、1889年にSI基本単位が定義され、1983年にメートルの定義が見直されたのを最後に現在の定義が完成した。 SI基本単位 量 単位 定義 長さ m（メートル） 1秒の299,792,458分の1の時間に光が真空中を伝わる行程の長さ 質量 kg（キログラム） 国際キログラム原器の質量 時間 s（秒） セシウム133の原子の基底状態の二つの超微細構造準位の間の遷移に対応する放射の周期の9,192,631,770倍の継続時間（補足：温度0Kの下で静止した状態） 電流 A（アンペア） 真空中に1メートルの間隔で平行に配置された無限に小さい円形断面積を有する無限に長い二本の直線状導体のそれぞれを流れ、これらの導体の長さ1メートルにつき2×10−7ニュートンの力を及ぼし合う一定の電流 熱力学温度 K（ケルビン） 水の三重点の熱力学温度の1/273.16 物質量 mol（モル） 0.012キログラムの炭素12の中に存在する原子の数（補足：炭素12の原子は結合しておらず、静止しており、基底状態にある） 光度 cd（カンデラ） 周波数540×1012ヘルツの単色放射を放出し、所定の方向におけるその放射強度が1/683ワット毎ステラジアンである光源の、その方向における光度 質量の定義だけが原器に依存したものとなっている。 原器自体も表面への不純物の吸着で1年に1μgほどの汚染を被るため、1990年に原器を特定の方法で洗浄した直後の重量を指すことを明示した。 SI接頭語 接頭語 乗数 接頭語 乗数 da（デカ） 101 d（デシ） 10−1 h（ヘクト） 102 c（センチ） 10−2 k（キロ） 103 m（ミリ） 10−3 M（メガ） 106 μ（マイクロ） 10−6 G（ギガ） 109 n（ナノ） 10−9 T（テラ） 1012 p（ピコ） 10−12 P（ペタ） 1015 f（フェムト） 10−15 E（エクサ） 1018 a（アト） 10−18 Z（ゼタ） 1021 z（セプト） 10−21 Y（ヨタ） 1024 y（ヨクト） 10−24 メートル法 国際単位系の前身である、18世紀のフランス革命に起源を持つ単位系。 長さとしてメートル、面積としてアール、体積としてステール（1立法メートル）とリットル（1立法デシメートル）、重さとしてキログラム（1リットルの水の重さ）を定めた。 CGS単位系 メートル法から派生してできた単位系。 センチメートル、グラム、秒を基本単位としており、物理学における量をこの3つの組立単位として表現しようとした（実際にはSI基本単位における電流の定義が不足しているため不十分だった）。 MKS単位系 メートル法から派生してできた単位系。 メートル、キログラム、秒を基本単位とした力学的な量のみを取り扱う単位系で、主に工学分野で用いられた。 MKSA単位系 MKS単位系にアンペアの定義を追加したもの。 これにより電磁気学の取り扱いが可能になった。 MTS単位系 メートル、トン、秒を基本単位とした単位系。 20世紀にソ連で利用されたが、あまりメジャーにはならなかった。 重力単位系 質量の代わりにその地域における重力を基本単位とする単位系。 SI単位系では、力は質量・長さ・時間から間接的に定義されるものとして扱われるが、日常生活では重量を基準にしたほうがわかりやすいこともあり、現在も利用されることがある。 単位記号は、質量の単位記号の後にwかfを付け足したものになる。 例：重量キログラム・・・ 1 kgf≃9.8 N≃9.8 kg⋅m/s2 "},"dynamics/materials/intro.html":{"url":"dynamics/materials/intro.html","title":"概要","keywords":"","body":"材料力学 機械や構造物に負荷が加わったときの変形・破壊について考える学問。 材料力学における仮定 一般的な材料力学ではモデルを簡易化するため次のような仮定を行う。 材料が均質（homogeneous）である 全体に渡って欠陥がなく均一な組織から構成されている 局所的な力学的性質に差がない 等方性材料（isotropic material）である 組織や繊維の配向などによる力学的性質の差がない 対義語は異方性材料（anisotropic material） 外力による変形量は物体の寸法より十分小さい 外力と変形の間で重ね合わせの原理（principle of superposition）が成立する 現実にこれらの仮定は満たされないが、これらの仮定を適切に用いれば十分な精度で物体の性質を記述できる。 基本用語 荷重（load） 機械や構造物の部材に加わる外力を総じて荷重と呼ぶ。 荷重はその性質によって次のように分類することがある。 作用する範囲 集中荷重（concentrated load） 分布荷重（distributed load） 経時的に見たとき 静荷重（static load） 変動荷重（dynamic load） 繰り返し変動荷重（repeated load） 変動荷重との違いは短期間で急激に変化するか長期間に渡って繰り返すか 梁（beam） 細い棒状の構造物を梁と呼ぶ。 梁は構造物の基本単位として様々な場所で現れるため、梁の変形・働く応力について調べることは材料力学・構造力学の基本となる。 梁の支持（support） 梁の支持の方法では次の2種類が基本となる。 単純支持（simple support）・回転支持（hinged support） 上下方向のみ支え、回転は拘束しない 固定支持（fixed support） 剛体壁に固定し上下方向と回転を拘束する "},"dynamics/materials/stress.html":{"url":"dynamics/materials/stress.html","title":"応力・ひずみ","keywords":"","body":"応力（stress） 物体が外力を受けて変形しているとき、物体の内部には外力に釣り合う内力（internal force）が生じているものと考えられる。 この内力が外力と釣り合うことができなければ物体は破壊されると考えて良い。 このときの単位面積あたりの内力の大きさを応力といい、[N/mm2] 、[MPa] などの単位で表す（数値が大きくなることが多いため）。 応力は次の2種類に分類される。 垂直応力（normal stress） 物体上にある仮想断面（作用面）を定義するとき、作用面の垂直方向に働く力を軸力、応力を垂直応力という。 せん断応力（shearing stress） 物体上にある仮想断面（作用面）を定義するとき、作用面と平行な方向に働く力をせん断力、応力をせん断応力という。 曲げ応力（bending stress） 長さ l の梁の一端を固定支持し、反対側にせん断方向の外力によって生じるモーメントを曲げモーメント（bending moment）といい、これと対応して生じる応力を曲げ応力という。 曲げ応力は不均一な垂直応力と捉えることができ、またせん断力に付随して生じるものであるため、ほかの2つと密接な関係がある。 ひずみ（strain） 材料力学では物体の変形を一般化して考えるため、変形量を変形前の長さで割ったものを指標とする。 これをひずみという。 ひずみは次の2種類に大別される。 垂直ひずみ（normal strain） 長さ l0 幅 d0 の物体に軸力が作用して長さ l 幅 d に変形したとき、ε=l−l0l0 で表される値を垂直ひずみまたは縦ひずみ（longitudinal strain）といい、ε′=d−d0d0 で表される値を横ひずみ（lateral strain）という。 ポアソン比（Poisson's ratio） 垂直ひずみと横ひずみの比は材料に固有であることが知られており、ν=−ε′ε をポアソン比と呼ぶ。 せん断ひずみ（shearing strain） 高さ l の物体にせん断力が作用して下図のように平行四辺形に変形したとき、上面の横方向の変位を λs として γ=λsl=tanϕ≃ϕ で表される値をせん断ひずみという。 "},"dynamics/materials/deformation_property.html":{"url":"dynamics/materials/deformation_property.html","title":"変形特性","keywords":"","body":"変形特性（deformation property） ある材料に加えた荷重と変形の関係を変形特性という。 応力-ひずみ線図（stress-strain diagram） 材料の変形特性を断面積や長さについて正規化して記述した図。 グラフと材料の変形特性の関係は次のように説明できる。 比例限度（proportional limit）までは除荷すると変形が完全に元に戻る（弾性変形） 応力とひずみが比例関係になる 弾性限度（elastic limit）に達すると変形が残るようになる（塑性変形） 上降伏点（upper yield stress）を超えると応力が減少し応力一定（下降伏点（lower yield stress）・降伏応力）のままひずみが増加する区間がある 一度降伏点を超える応力を加えると再び応力に応じてひずみが増減するようになるが、常に図中の Ap で表される塑性ひずみ（plastic strain）・永久ひずみ（permanent strain）が残るようになる（これの減少加工硬化（work hardening）・ひずみ硬化（strain hardening）という） 降伏点を超えた後に荷重を加えることを再負荷（reloading）という さらに負荷を加えると極限強さ（ultimate strength）に達する 極限強さを超えると材料が部分的に細くなり応力を小さくしてもひずみが大きくなり（材料が伸び）、最終的に千切れる グラフ上ではあくまで部材に加える力を標準状態の面積で割ったものを応力とするが、細くなった部分は面積が小さくなるため局所的な応力は増加している（これを真応力と呼んで区別する） なお、非鉄金属や非金属などの材料のように降伏点を持たないものもある。 降伏点がない例 降伏点がある例 （出典：https://ja.wikipedia.org/wiki/%E5%BF%9C%E5%8A%9B-%E3%81%B2%E3%81%9A%E3%81%BF%E6%9B%B2%E7%B7%9A） フックの法則（Hooke's law） 弾性変形領域では応力とひずみの間で比例関係が成立する。 これをフックの法則という。 このときの比例定数をヤング率（Young's modulus）・縦弾性係数（modulus of longitudinal elasticity）という。 ヤング率は応力と同じ次元を持つ。 またせん断変形に関してもフックの法則が成立する。 このときの比例定数をせん断弾性係数（modulus of shearing elasticity）・横弾性係数（modulus of transverse elasticity）という。 弾性定数・材料定数（elastic constants / material constants） ヤング率 E 、せん断弾性係数 G 、ポアソン比 ν をまとめて弾性定数・材料定数といい、材料固有の値として扱う。 "},"dynamics/materials/beam_elastic_stress_analysis.html":{"url":"dynamics/materials/beam_elastic_stress_analysis.html","title":"単純な梁の弾性応力解析","keywords":"","body":"単純な梁の弾性応力解析 支持されている梁に荷重を加えたとき、変形量が微小であるものとして、梁の内部に働く応力について考える。 片持ち梁（集中荷重） 一方の端を固定支持した長さ l の梁の反対側の端に W の集中荷重を加える。 まず全体の釣り合いの式を考える。 {RA−W=0MA−Wl=0 次に位置 x の仮想断面における釣り合いの式を考える。 切断法では断面の左右どちらかに着目して釣り合いの式を考えればその断面における応力が求まることが知られているため、左側についてだけ考える。 {RA−F=0MA−Fx+M=0 これらを解くと {F=WM=−W(l−x) を得る。 これに基づいてSFD、BMDを描くと以下のようになる。 片持ち梁（等分布荷重） 長さ l の片持ち梁全体に等分布荷重 W0 を加える（なお分布荷重の値は単位長さあたりの大きさを表す）。 まず全体の釣り合いの式を考える。 {RA−∫l0W0dξ=0MA−∫l0ξ⋅W0dξ=0 次に位置 x の仮想断面における釣り合いの式を考える。 {RA−∫x0W0dξ−F=0MA−∫x0ξ⋅W0dξ−Fx+M=0 これらを解くと ⎧⎨⎩RA=W0l2M=−W02(l−x)2 を得る。 これに基づいてSFD、BMDを描くと以下のようになる。 両端支持梁（集中荷重） 長さ l の両端支持梁の一端から a の位置に集中荷重 W を加える。 まず全体の釣り合いの式を考える。 {RA+RB−W=0−0⋅RA+Wa−RBl=0 次に位置 x の仮想断面における釣り合いの式を考える。 x が W を超えているかによって場合分けが必要になる。 xa のとき {RA−F=0−0⋅RA+Fx−M=0 a\">x>a のとき {RA−W−F=0−0⋅RA+Wa+Fx−M=0 これらを解くと a) \\end{cases}\\\\ M = \\begin{cases}\\frac{l-a}{l}Wx & (x a) \\end{cases} \\end{cases}\">⎧⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎨⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎩RA=l−alWRB=alWF={l−alW(xa)−alW(x>a)M={l−alWx(xa)l−xlaW(x>a) を得る。 これに基づいてSFD、BMDを描くと以下のようになる。 両端支持梁（分布荷重） 長さ l の両端支持梁へ分布荷重 W0 を加える。 まず全体の釣り合いの式を考える。 {RA+RB−∫l0W0dξ=0−0⋅RA+∫l0ξ⋅W0dξ−RBl=0 次に位置 x の仮想断面における釣り合いの式を考える。 {RA−∫x0W0dξ−F=0−0⋅RA+∫x0ξ⋅W0dξ+Fx−M=0 これを解くと ⎧⎨⎩F=W02(l−2x)M=W02(l−x)x を得る。 ソースコード import matplotlib.pyplot as plt import numpy as np xs = np.linspace(0, 1, 100) sfs = list(map(lambda x: 1, xs)) bms = -1 * (1 - xs) plt.plot(xs, sfs, label='SFD') plt.plot(xs, bms, label='BMD') plt.title('cantilever / concentrated load (l=1,W=1)') plt.xlabel('span') plt.ylabel('shearing stress/bending stress') plt.legend() plt.show() import matplotlib.pyplot as plt import numpy as np xs = np.linspace(0, 1, 100) sfs = list(map(lambda x: 1/2, xs)) bms = -1/2 * np.power(1 - xs, 2) plt.plot(xs, sfs, label='SFD') plt.plot(xs, bms, label='BMD') plt.title('cantilever / uniformly-distributed load (l=1,W0=1)') plt.xlabel('span') plt.ylabel('shearing stress/bending stress') plt.legend() plt.show() import matplotlib.pyplot as plt import numpy as np l = 1 a = 0.7 w = 1 xs = np.linspace(0, l, 100) def sf_func(x): if x import matplotlib.pyplot as plt import numpy as np l = 1 w0 = 1 xs = np.linspace(0, l, 100) sfs = w0*(l-2*xs)/2 bms = w0*(l-xs)*xs/2 plt.plot(xs, sfs, label='SFD') plt.plot(xs, bms, label='BMD') plt.title('both end supported beam / uniformly-distributed load (l=1,W0=1)') plt.xlabel('span') plt.ylabel('shearing stress/bending stress') plt.legend() plt.show() "},"dynamics/fluid/glossary.html":{"url":"dynamics/fluid/glossary.html","title":"用語","keywords":"","body":"用語 連続体 流体・弾性体などを巨視的に捉え、内部の分子などは無視でき、内部が均一で滑らかであると仮定したものを連続体という。 流体粒子・流体要素（fuild particle / fluid element） 流体が微小な流体塊から成り立っている連続体であるとしたとき、この流体塊を流体粒子・流体要素という。 分子の平均的な振る舞いをそのまま適用できる範囲で（つまり流体分子よりは十分大きなスケールで）、連続体をなるべく小さく区切ったものといえる。 平均自由行程（mean free path） 流体中の分子が、他の分子とぶつかった後で再び他の分子とぶつかるまでの間に進む距離の平均値を平均自由行程という。 平均自由行程は分子間力と分子の密度に依存し、粘性・熱伝導・拡散などを考える際に役立つ。 クヌーセン数（Knudsen number） 分子の平均自由行程 λ と流れの代表寸法 L を用いて Kn=λL で表される無次元数をクヌーセン数という。 クヌーセン数は流体を連続体と見なしてよいかの指標として用いられる。 クヌーセン数が小さくなるほど分子運動に対する流れ場のスケールが大きいことになるため、1より十分に小さい値を取る場合は流体を連続体と見なす。 標準大気圧（normal atmospheric pressure） 101,325 [Pa]。 海水面における標準的な大気圧を由来とする。 流線と流管（stream line / stream tube） 流れ場のある瞬間において、接線がその点における流体粒子の速度ベクトルとなるように引いた曲線を流線という。 流線は次のような性質を満たす。 滑らかで連続な流れ場が一意に与えられているとき流線は交差しない ※流線が交差するということはある点において複数の接線が存在する⇒複数の流れ場が与えられている また、流れ場に1つの閉曲線を考えたとき、その閉曲線を通過する流線の集まりを壁面とする管を仮定できる。 この管を流管という。 体積力（body force） 重力など、流体粒子の質量に応じて作用する外力を質量力・体積力という。 "},"dynamics/fluid/intro.html":{"url":"dynamics/fluid/intro.html","title":"概要","keywords":"","body":"流体力学の概要 流体のモデル化 流体力学での流体のモデル化の方法は大まかに次のように分類される。 非圧縮性流体 粘性流体 ニュートン流体 非ニュートン流体 非粘性流体（理想流体）->オイラーの運動方程式 圧縮性流体 "},"dynamics/fluid/ideal_fluid.html":{"url":"dynamics/fluid/ideal_fluid.html","title":"理想流体","keywords":"","body":"理想流体 理想流体（非圧縮性非粘性流体）の流れの記述方法について言及する。 オイラーの運動方程式（Euler's equation of motion） 非粘性流体の流れ場のある流体粒子に注目する。 流体粒子は剛体と見なしてよいため、ニュートンの運動の第二法則を適用できる。 Ma=F 流体の密度 ρ 、流体粒子の微小体積 ΔV 、速度ベクトル v 、体積力のベクトル f を用いれば、 この方程式をオイラーの運動方程式という。 ベルヌーイの定理（Bernoulli's theorem） 理想流体の定常流れ 連続の式 すべての流れについて成立する。 "},"numerical_analysis/finite_element_method/1-dimention.html":{"url":"numerical_analysis/finite_element_method/1-dimention.html","title":"1次元の重み付き残差法","keywords":"","body":"１次元の重み付き残差法 次の微分方程式を数値的に解くことを考える。 d2udx2−λ=0   (0≤x≤L)u|x=0=0,   dudx|x=L=0(1) ここで u|x=0=0 のように u の値が分かっているような境界条件をディリクレ（Dirichlet）境界条件という。 また dudx|x=L=0 のように dudx の値が分かっているような境界条件をノイマン（Neumann）境界条件という。 概要 近似解を u′(x) とすると、微分方程式を完全には満たさないため R(x)=d2u′dx2−λ のように残差 R(x) が生じる。 この残差をすべての点で0に近づければよいが、そのままでは逐次的な操作となるため難しい。 そこで重み関数 u∗(x) を用いて重み付き残差平均 ∫u∗(x)R(x)dx を最小化しようというのが重み付き残差法である。 重み関数の選び方として選点法・モーメント法・最小二乗法・ガラーキン法などが考案された。 ここでは今日よく利用されるガラーキン法によって例題を解く。 重み付き残差法では上記の式そのものを解くのではなく、弱形式から弱解を求めることで近似解を得る。 こうすることで、近似解の導出が連立方程式を解く作業に置き換わるため、線形代数の知識を利用して（つまりコンピュータに解かせることができる形で）近似解を求めることができるようになる。 弱形式（Weak Formulation）の導出 式(1)の両辺に任意の重み関数 u∗(x) をかけた上で領域内で積分すると ∫L0u∗(x)(d2udx2−λ)dx=0 これを部分積分すると −∫L0(du∗dxdudx+u∗λ)dx+[u∗dudx]L0=0 ここで境界条件 dudx|x=L=0を代入、またディリクレ境界条件が課せられた境界上（今回は x=0）において u∗(x)=0 とすると（理由は後述） ∫L0(du∗dxdudx+u∗λ)dx=0(2) となる。 このとき式(2)は式(1)の 弱形式 であるといい、 『任意の u∗(x) について式(2)が成立する ⇒ 式(1)が成立する』 を満たす。 近似解の離散化 0≤x≤L においてN個の小区間に分割したときの u(x) の折れ線近似解を ~u(x) とすると弱形式全体は ∫L0(du∗dxdudx+u∗λ)dx≃N∑k=1[∫xk+1xk(du∗dxd~ukdx+~ukλ)dx] と近似できる。 折れ線近似として ~uk(x)=ak+bkx の関数形を仮定し、各区分点における ~u(x) の値を ~u1,~u2,…,~un+1 とすると (~uk~uk+1)=[1xk1xk+1](akbk) となるから、逆行列を求めて ak,bk を消去すると ~uk(x)=[1x](akbk)=[xk+1−xxk+1−xkx−xkxk+1−xk](~uk~uk+1)d~udx=[ddx(xk+1−xxk+1−xk)ddx(x−xkxk+1−xk)](~uk~uk+1)=[−1xk+1−xk1xk+1−xk](~uk~uk+1)(3)(4) これで区分点の値を用いて小区間における近似解とその1階微分を表現できた。 ここからは式を以下のようにまとめる。 lk=xk+1−xkNTk=[xk+1−xlkx−xklk]LTk=[−1lk1lk]~Uk=(~uk~uk+1)U∗k=(u∗ku∗k+1) 重み関数の離散化 u(x) の離散化はできたので、次に u∗(x) を離散化する。 ここではガラーキン法を用いることとしたため、u(x) と同じ関数形を仮定して u∗k(x)=a∗k+b∗kx とする。 すると u(x) の離散化の手順をそのまま適用できるため u∗k(x)=NTkU∗kdu∗kdx=LTkU∗k となる。 弱形式の離散化 以上をまとめると、小区間において成立すべき一次方程式は ∫xk+1xk(du∗dxd~ukdx+~ukλ)dx=∫xk+1xk(LTkU∗kLTk~Uk+NTkU∗kλ)=(U∗k)T[LkLTk~Uk∫xk+1xkdx+λ∫xk+1xkNkdx]=(U∗k)T[1lk[1−1−11]~Uk+12lk(11)] これを対象領域で連立させると ∑Nk=1[∫xk+1xk(du∗dxd~ukdx+~ukλ)dx]=[u∗1u∗2…u∗n+1](A~u+B) ただし A=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣1/l1−1/l10…00−1/l11/l1+1/l2−1/l2…000−1/l21/l2+1/l3…00⋮⋮⋮⋱⋮⋮000…1/ln−1+1/ln−1/ln000…−1/ln1/ln⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦B=⎛⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜⎝λl1/2λ(l1+l2)/2λ(l2+l3)/2⋮λ(ln−1+ln)/2λln/2⎞⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟⎠~u=⎛⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜⎝~u1~u2~u3⋮~un~un+1⎞⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟⎠ ここで u∗1,u∗2,…,u∗n+1 は任意関数であるべきなので A~u+B=0 を ~u について調べればよい。 しかし、このままではAが逆行列を持たないため計算できない（これは問題の制約条件が不足していることと対応している）。 そこで「ディリクレ境界条件が課された境界上では u∗(x)=0 とする」という条件を再利用する。 式の1行目に着目すると u∗(~u1l1−~u2l1+λl12)=0 ここで ~u1l1−~u2l1+λl12=0 を満たす必要がない代わりに、 u∗1=0 を満たすようにする。 A′=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣100…00−1/l11/l1+1/l2−1/l2…000−1/l21/l2+1/l3…00⋮⋮⋮⋱⋮⋮000…1/ln−1+1/ln−1/ln000…−1/ln1/ln⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦B′=⎛⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜⎝0λ(l1+l2)/2λ(l2+l3)/2⋮λ(ln−1+ln)/2λln/2⎞⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟⎠ と置けば ~u=−A′−1B′ より近似解 ~u が求まる。 "},"numerical_analysis/finite_element_method/laplaces_equation.html":{"url":"numerical_analysis/finite_element_method/laplaces_equation.html","title":"2次元の重み付き残差法（ラプラス方程式）","keywords":"","body":"2次元の重み付き残差法（ラプラス方程式） 曲線 Γ に囲まれた領域 Ω におけるラプラス方程式の近似解を求める。 ∂2ϕ∂x2+∂2ϕ∂y2=0   (x,y)∈Ω∂ϕ∂n|(x,y)∈Γ1=^q(x,y),   ϕ|(x,y)∈Γ2=^ϕ(x,y)Γ=Γ1∪Γ2,   Γ1∩Γ2=∅ ただし、^q(x,y),^ϕ(x,y) は既知とする。 概要 1次元のときと同じようにガラーキン法を用いる。 今回は2次元のため、領域を三角形の小領域に分割し、小領域内での解を平面に近似する。 弱形式の導出 任意関数 ϕ∗(x,y) を用いて ∫∫Ωϕ∗(∂2ϕ∂x2+∂2ϕ∂y2)dxdy=0 ここでガウスの発散定理を用いる。 閉曲線 Γ で囲まれる2次元領域 Ω において F(x,y),G(s,y) が連続かつその1階偏導関数も連続なら ∫∫Ω(∂2ϕ∂x2+∂2ϕ∂y2)dxdy=∫Γ(Fnx+Gny)dΓ ただし ∫ΓdΓ は反時計回りに取る。 直感的には『領域全体でのポテンシャルの増減 = 領域境界における流入出の和』を示す式である。 ∫∫Ω[∂∂x(ϕ∗∂ϕ∂x)+∂∂y(ϕ∗∂ϕ∂y)]dxdy=0 ∫Γϕ∗(∂ϕ∂xnx+∂ϕ∂yny)dΓ=0 ∂ϕ∂n=∂ϕ∂xnx+∂ϕ∂yny を用いて ∫Γϕ∗∂ϕ∂ndΓ−∫∫Ω(∂ϕ∗∂x∂ϕ∂x+∂ϕ∗∂y∂ϕ∂y)dxdy=0 ∫Γ1ϕ∗∂ϕ∂ndΓ+∫Γ2ϕ∗∂ϕ∂ndΓ−∫∫Ω(∂ϕ∗∂x∂ϕ∂x+∂ϕ∗∂y∂ϕ∂y)dxdy=0 ノイマン境界条件を利用して ∫Γ1ϕ∗^qdΓ+∫Γ2ϕ∗∂ϕ∂ndΓ−∫∫Ω(∂ϕ∗∂x∂ϕ∂x+∂ϕ∗∂y∂ϕ∂y)dxdy=0 ここでディリクレ境界条件が課せられた境界上ではϕ∗=0と仮定する。 ∫Γ1ϕ∗^qdΓ−∫∫Ω(∂ϕ∗∂x∂ϕ∂x+∂ϕ∗∂y∂ϕ∂y)dxdy=0 これが弱形式となる。 弱形式の離散化 近似解を~ϕ(x,y)とすると、これが満たすべき方程式は ∫∫Ω(∂ϕ∗∂x∂~ϕ∂x+∂ϕ∗∂y∂~ϕ∂y)dxdy−∫Γ1ϕ∗^qdΓ=0~ϕ=^ϕ(x,y)   (Γ2上) である。 "},"numerical_analysis/finite_element_method/examples.html":{"url":"numerical_analysis/finite_element_method/examples.html","title":"数値計算例","keywords":"","body":"有限要素法の数値計算例 1次元 d2udx2−λ=0   (0≤x≤L)u|x=0=a,   dudx|x=L=b(1) ※式を展開して解いていったときの結論と一致が確認できていないので import numpy as np import matplotlib.pyplot as plt l = 10 lam = -2 a = 5 b = -5 n = 100 #小区間を100個 ps = np.linspace(0, l, n+1) #区分点は101個 #各小区間の長さ lens = [] for i in range(n): lens.append(ps[i+1]-ps[i]) A = np.zeros((n+1,n+1)) B = np.zeros((n+1,1)) for i in range(n): val = 1 / lens[i] A[i][i] += val A[i][i+1] += -val A[i+1][i] += -val A[i+1][i+1] += val val2 = lam * lens[i] / 2 B[i][0] += val2 + b B[i+1][0] += val2 - b A[0] = np.zeros((1,n+1)) A[0][0] = 1 B[0][0] = -a res = -np.linalg.solve(A,B) plt.plot(ps, res) plt.show() "},"control/abstract/intro.html":{"url":"control/abstract/intro.html","title":"概要","keywords":"","body":"制御理論 制御理論は制御工学の一分野で、対象を数理モデルで表し数学を応用することで望む制御を設計する学問。 制御理論の歴史 1800年代後半 制御の理論的研究が始まった 1950年代末 現代制御理論の芽生え 1960年ごろ 古典制御理論が体系化された 近年 現代制御理論が体系化された 古典制御と現代制御 制御理論では様々な理論が提唱されているが、主だったものとして古典制御理論・現代制御理論がある。 両者の概要を以下に示す。 古典制御 現代制御 基礎となる概念 伝達関数 状態方程式 制御対象 主に１入力１出力時不変線形 多入力多出力時変・時不変線形・非線形 注目する変数 入力変数（特にその周波数）・出力変数 システム内部の状態変数 設計 定常偏差・減衰係数・ゲイン余裕・位相余裕などが満足できる値になるまで試行錯誤的にパラメーターを探す 目的（評価）関数を定め最適化手法に基づいてパラメーターを求める "},"control/abstract/linear_system.html":{"url":"control/abstract/linear_system.html","title":"線形システム","keywords":"","body":"線形システム（Linear System） 定義 入力 u(t) と出力 y(t) の関係が次式で表せるとき、このシステムを線形システム（線形ダイナミカルシステム）という。 n∑k=0andky(t)dtn=m∑k=0bndku(t)dtn 線形システムは解析・設計が比較的容易かつ、現実の多くの事象に適用できるため制御理論の基礎となる。 補足 定義式は「入力 u1(t), u2(t) に対して y1(t), y2(t) の応答が得られる ⇒ αu1(t)+βu2(t) の入力を与えると αy1(t)+βy2(t) の応答が得られる」という線形性を満たす。 線形化 上記の形式で表現できないような非線形システム（式に指数関数を含むものなど）は伝達関数・状態方程式の数学的な分析が困難になる。 そこでシステムの動作が想定される範囲をテイラー展開などで線形微分方程式に近似してから制御設計を行う手法がよく用いられる。これを線形化という。 "},"control/classical/transfer_function1.html":{"url":"control/classical/transfer_function1.html","title":"伝達関数1","keywords":"","body":"伝達関数1（transfer function） 伝達関数表現 線形システムを微分方程式のまま計算すると、システムの結合が連立微分方程式で表現されることになり扱いづらい。 そこでラプラス変換を用いて t の微分 ⇔ s の掛け算となるような媒介変数表示にすると次のような利点がある。 システムの特性をひとつの伝達関数 G(s) として表現できるようになる。 システムの直列結合を伝達関数の積として表現できるようになる。 システムの並列結合を伝達関数の和として表現できるようになる。 例 線形システムA、Bを直列に結合してみる。 ⎧⎪ ⎪⎨⎪ ⎪⎩a2d2y1(t)dt2+a1dy1(t)dt+a0y1=b1du1(t)dt+b0u0(t)c2d2y2(t)dt2+c1dy2(t)dt+c0y2=d1dy1(t)dt+d0y1(t) このままでは扱いづらい。 そこで y1(t)、y2(t)、u(t) を全ての初期値を0としてラプラス変換する。 Y1(s)=L[y1(t)]Y2(s)=L[y2(t)]U(s)=L[u(t)] これを利用して書き直すと (a2s2+a1s+a0)Y1(s)=(b1s+b0)U(s)(c2s2+c1s+c0)Y2(s)=(d1s+d0)Y1(s) さらに Y1(s) を消してひとつの式にまとめると Y2(s)=d1s+d0c2s2+c1s+c0⋅b1s+b0a2s2+a1s+a0U(s) 簡潔に記述できた。 上の式において GA(s)=b1s+b0a2s2+a1s+a0GB(s)=d1s+d0c2s2+c1s+c0 はそれぞれA、Bのシステムの入出力比を表しているといえる。 つまり GA(s)、GB(s) はA、Bのシステムの特性を表現する関数になっている。 これを伝達関数と呼ぶ。 "},"control/classical/transfer_function2.html":{"url":"control/classical/transfer_function2.html","title":"伝達関数2","keywords":"","body":"伝達関数2（transfer function） 伝達関数とブロック線図 ブロック線図のパターンと伝達関数の演算の対応表を示す。 （出典：http://ysserve.wakasato.jp/Lecture/ControlMecha1/node10.html） むだ時間（dead time）を含む系 入力に対する応答に一定のラグ（むだ時間）を含む系は伝達関数表現と相性が悪い。 というのも、このケースでは伝達関数が指数関数となってしまうため。 例 y(t)=u(t−L) は信号の伝達を L だけ遅延させるシステム。 これをラプラス変換すると Y(s)=e−sLU(s)G(s)=e−sL となる。 パデー近似（Pade approximation） むだ時間を無視できない場合、次のような有理関数への近似を行うことがある。 e−sL≃1−Ls/21+Ls/2e−sL≃1−Ls/2+(Ls)2/121+Ls/2+(Ls)2/12 "},"control/classical/transfer_function3.html":{"url":"control/classical/transfer_function3.html","title":"伝達関数3","keywords":"","body":"伝達関数3（transfer function） proper／strictly proper／improperな伝達関数 次のような線形システムについて考える。 n∑k=0andky(t)dtn=m∑k=0bndku(t)dtn このシステムの伝達関数を計算すると G(s)=N(s)D(s)=bmsm+bm−1sm−1+ … +b0sn+an−1sn−1+ … +a0 となる。 プロパー（proper） 伝達関数の分母の次数が分子の次数以上のとき（n≥m）、ある時刻tにおける出力 y(t) は過去から現在までの入力のみに依存することになる。 このとき、このシステムの伝達関数はプロパー（proper）であるという。 厳密にプロパー（strictly proper） 特に m\">n>m のとき、伝達関数は厳密にプロパー（strictly proper）であるという。 インプロパー（improper） 逆に伝達関数の分子の次数が分母の次数より高いとき（nm）、ある時刻 t における入力は過去から現在までの出力に依存すると言える。 しかし、現実におけるシステムでは現在の入力に依存して現在の出力が決まるため、このような制御器は実現できない。 このとき、伝達関数はインプロパー（improper）／非プロパーであるという。 "},"control/classical/impulse_step_response.html":{"url":"control/classical/impulse_step_response.html","title":"インパルス応答とステップ応答","keywords":"","body":"インパルス・ステップ応答 インパルス応答 システムの初期状態が0のときに入力を単位インパルス関数としたときのシステムの出力をインパルス応答という。 単位インパルス関数（デルタ関数）とは ∫∞−∞δ(t)dt=1,  δ(t)|t≠0=0 を満たす関数。 面積1の三角形を用いた定義として limε→0δε(t) δε(t)={1/ε0tε0else などがある。 伝達関数 G(s) のシステムのインパルス応答は y(t)=L−1[G(s)] によって得られる。 任意の入力 u(t) に対する応答 y(t) はインパルス応答 g(t) の畳み込み積分で表現できる。 直観的には、インパルス信号に重み関数をかけて重ね合わせて入力を作ると線形性によりインパルス応答に重み関数をかけて重ね合わせたものが応答になる、という理解になる。 y(t)=L−1[G(s)u(s)]=∫t0g(t−τ)u(τ)dτ ステップ応答 システムの初期状態が0のときに入力を単位ステップ関数としたときのシステムの出力をステップ応答という。 単位ステップ関数とは 0 \\\\ 0 & tus(t)={1t>00t0 を満たす関数。 伝達関数 G(s) のシステムのステップ応答は y(t)=L−1[G(s)1s] によって得られる。 "},"control/classical/transient_response.html":{"url":"control/classical/transient_response.html","title":"過渡応答","keywords":"","body":"過渡応答（transient response） 高次システムの性質を調べる際には、すべての応答を代表させてステップ応答を評価することが多い。 その理由としては 実験しやすい 制御対象をモデル化するのに十分な情報を持っている 実際の制御系においても目標値がステップ状に変化するケースが多い などがあげられる。 このようにシステムの性質を評価する目的で得たステップ応答を過渡応答と呼ぶ。 過渡応答の特性値 過渡応答の評価は次のような特性値を基に行われる。 立ち上り時間（rise time）Tr 定常値の10%->90%になるまでに要する時間。 遅れ時間（遅延時間）（delay time）Td 定常値の50%に達するまでの時間。 整定時間（settling time）Ts 応答が定常値の±2%（±5%,±1%とすることもある）の範囲に収まるまでの時間。 オーバーシュート（最大行き過ぎ量）（overshoot）Amax 応答のピーク値と定常値の差の最大値。 行き過ぎ時間（peak time）Tp 最初の行き過ぎに達するまでの時間。 減衰比（decay ratio） 最初の行き過ぎ量と次の行き過ぎ量の比。 （出典：http://www1.gifu-u.ac.jp/~kawalab/content/seminar/Control/Property2.html） "},"control/classical/first_order_system.html":{"url":"control/classical/first_order_system.html","title":"1次系の応答","keywords":"","body":"1次系の応答 1次系（first order system） 伝達関数が 0,K>0) \">G(s)=KTs+1   (T>0,K>0) の形で与えられるシステムは1次系と呼ばれる。 インパルス応答 1次系のインパルス応答は次のようになる。 y(t)=L−1[G(s)]=KTe−t/T ステップ応答 1次系のステップ応答は次のようになる（インパルス応答を積分して求めた）。 y(t)=∫t0KTe−τ/Tdτ=K(1−e−t/T) 以上からステップ応答の定常値・初期速度は次のようになる。 limt→∞y(t)=K,   dydt|t=0=KT パラメーターの意味 ゲイン K 定常状態でのゲイン（定常値が入力信号のK倍になる） 時定数 T 収束の速さ 出力が初期速度のまま進めばT秒後に定常値に到達する 時刻t=Tにおいて定常値の63.2%になる インパルス応答（Python） Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(1, 5): K = 1 #ゲイン T = 0.2 * i #時定数 t = np.arange(0, 3, 0.001) tf = matlab.tf([K], [T, 1]) y_out, t_out = matlab.impulse(tf, t) plt.plot(t_out, y_out, label='T = ' + '%.2f'%T) plt.title('Impulse response: $G(s)=\\\\frac{1}{Ts+1}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() ステップ応答（Python） Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(1, 5): K = 1 #ゲイン T = 0.2 * i #時定数 t = np.arange(0, 3, 0.001) tf = matlab.tf([K], [T, 1]) y_out, t_out = matlab.step(tf, t) plt.plot(t_out, y_out, label='T = ' + '%.2f'%T) plt.title('Step response: $G(s)=\\\\frac{1}{Ts+1}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() "},"control/classical/second_order_system.html":{"url":"control/classical/second_order_system.html","title":"2次系の応答","keywords":"","body":"2次系の応答 2次系（second order system） 伝達関数が 0,a_1>0,a_2>0) \">G(s)=b0s2+a1s+a2   (b0>0,a1>0,a2>0) の形で与えられるシステムは2次系と呼ばれる。 上記の式は解析のしやすさを考えて次のような形で表すことが多い。 0,\\zeta>0,\\omega_n>0) \">G(s)=Kω2ns2+2ζωns+ω2n   (K>0,ζ>0,ωn>0) インパルス応答 2次系のインパルス応答は次のようになる。 y(t)=L−1[G(s)]=Kωn√1−ζ2e−ζωntsin(ωdt) ステップ応答 2次系のステップ応答は次のようになる（部分分数分解を用いて求めた）。 ωd=ωn√1−ζ2 と置いて y(t)=L−1[G(s)1s]=L−1[Ks−K(s+2ζωn)s2+2ζωns+ω2n]=L−1[Ks−K(s+ζωn)(s+ζωn)2+ω2d−Kζ√1−ζ2√1−ζ2ωn(s+ζωn)2+ω2d]=K{1−e−ζωnt√1−ζ2sin(ωdt+θ)} (θ=tan−1√1−ζ2ζ) パラメーターの意味 後に示すグラフを見ればわかるように、各パラメーターは応答に次のような影響を与える。 ゲイン K 定常状態でのゲイン（定常値が入力信号のK倍になる） 減衰係数 ζ 振動減衰（damping）の特性を定める ζ1：不足制動（under damping） ζ=1：臨界制動（critical damping） 1\">ζ>1：過制動（over damping） 自然角周波数 ωn 速応性を定める 実際は ωd=ωn√1−ζ2 が振動の周波数になる インパルス応答（Python） Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(2, 7): K = 1 #ゲイン zeta = 0.2 * i #時定数 omega_n = 10 t = np.arange(0, 2, 0.001) tf = matlab.tf([K*omega_n**2], [1, 2*zeta*omega_n, omega_n**2]) y_out, t_out = matlab.impulse(tf, t) plt.plot(t_out, y_out, label='$\\\\zeta$ = ' + '%.2f'%zeta) plt.title('Impulse response: $G(s)=\\\\frac{100}{s^2+20\\\\zeta s+100}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(3, 7): K = 1 #ゲイン zeta = 0.4 #時定数 omega_n = 2 * i t = np.arange(0, 2, 0.001) tf = matlab.tf([K*omega_n**2], [1, 2*zeta*omega_n, omega_n**2]) y_out, t_out = matlab.impulse(tf, t) plt.plot(t_out, y_out, label='$\\\\omega_n$ = ' + '%.2f'%omega_n) plt.title('Impulse response: $G(s)=\\\\frac{\\\\omega_n}{s^2+0.8\\\\omega_n s+\\\\omega_n^2}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() ステップ応答（Python） Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(2, 7): K = 1 #ゲイン zeta = 0.2 * i #時定数 omega_n = 10 t = np.arange(0, 2, 0.001) tf = matlab.tf([K*omega_n**2], [1, 2*zeta*omega_n, omega_n**2]) y_out, t_out = matlab.step(tf, t) plt.plot(t_out, y_out, label='$\\\\zeta$ = ' + '%.2f'%zeta) plt.title('Step response: $G(s)=\\\\frac{100}{s^2+20\\\\zeta s+100}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt for i in range(3, 7): K = 1 #ゲイン zeta = 0.4 #時定数 omega_n = 2 * i t = np.arange(0, 2, 0.001) tf = matlab.tf([K*omega_n**2], [1, 2*zeta*omega_n, omega_n**2]) y_out, t_out = matlab.step(tf, t) plt.plot(t_out, y_out, label='$\\\\omega_n$ = ' + '%.2f'%omega_n) plt.title('Step response: $G(s)=\\\\frac{\\\\omega_n}{s^2+0.8\\\\omega_n s+\\\\omega_n^2}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() "},"control/classical/pole_zero.html":{"url":"control/classical/pole_zero.html","title":"極・零点と過渡応答","keywords":"","body":"極・零点と過渡応答 復習：伝達関数の定義 G(s)=N(s)D(s)=bmsm+bm−1sm−1+ … +b0sn+an−1sn−1+ … +a0 極（pole）・零点（zero） D(s)=0 を満たす根（解）を極という。 N(s)=0 を満たす根（解）を零点という。 極・零点と過渡応答の関係 一般的な高次システムとして、伝達関数 G(s)、実極 −σi(i=1∼M)と複素数共役極 −αi±jωi(i=1∼N) を持つシステムを考える。 なお簡単のためすべての極は互いに異なるものとする。 このシステムのステップ応答のラプラス変換を部分分数分解すると次のようになる。 y(s)=A0s+M∑i=1Ais+σi+N∑i=1Bi(s+αi)2+ω2i これを逆ラプラス変換すると以下のようになる。 y(t)=A0+M∑i=1Aie−σit+N∑i=1Biωie−αitsinωit 極の影響 上記の式から、高次システムの過渡応答は各極に対応するインパルス応答の重ね合わせによって表現できることがわかる。 第1項は極（s=0）に対応するインパルス応答。 これが定常値となる。 第2項・第3項は G(s) の各極（s=−σi,−αi±jωi）に対応するインパルス応答。 これが過渡応答を形成する。 極とインパルス応答の対応イメージを以下に示す。 （出典：http://ysserve.wakasato.jp/Lecture/ControlMecha1/node16.html） 代表極・代表特性根（dominant pole） 過渡応答に最も影響を与える極のことを代表極・代表特性根という。 たとえば上記の式では σi,αi が 0 に近いほど e−σt,e−αt の収束が遅くなることが分かる。 つまり Ai,Bi に大きな差がない場合、応答はこれらの遅いモードが支配的になるはずであり、最も 0 に近い σi もしくは αi が代表極となる。 零点の影響 零点は極と共に上記の式の Ai,Bi に影響を与える。 （bmsm+bm−1sm−1+ … +b0sn+an−1sn−1+ … +a0 の部分分数分解の過程を追わなければならないため定性的な評価は面倒） 零点の影響により、逆ぶれ（定常値と逆の方向にふれること）を生じたり、実極しか存在しないにもかかわらずオーバーシュートが生じたりする。 "},"control/classical/stability.html":{"url":"control/classical/stability.html","title":"線形システムの安定性","keywords":"","body":"線形システムの安定性 安定性 線形システムに有界な大きさの任意の入力（|u(t)|∞）を加えたとき、出力も有界（|y(t)|∞）となるとき、システムは 安定（stable） であるという。 逆に出力が無限に発散しうるとき、システムは 不安定（unstable） であるという。 極と安定性　 線形システムの場合 「ステップ応答が安定⇔システムが安定」 であることが知られている。 極・零点と過渡応答で述べた通り、過渡応答はG(s)の各極（s=−σi,−αi±jωi）を用いて次式で表される。 y(t)=A0+M∑i=1Aie−σit+N∑i=1Biωie−αitsinωit ここで 0\">−σi,−αi>0であれば第2項・第3項がt→∞のとき0に収束しないため、不安定となる。逆に 0\">−σi,−αi>0でない限りステップ応答は有限な値に収束するはずである。 よって 全ての極の実部が負　⇔　システムが安定 が成り立つ。 安定性の判別 上記のように全ての極を調べればシステムの安定性が判別できるが、指数関数が絡むため面倒である。 そこで、ラウス・フルビッツらは比較的簡単に安定性を判別する手法を考案した。両者の手法は手順こそ異なるものの本質的には同じ数学的性質に依存している。 フルビッツの安定判別法 極は伝達関数の分母をとって D(s)=ansn+an−1sn−1+⋯+a1s+a0=0 であるとする。 ここで、各係数を用いて以下のようなn×n正方行列を作る。 ⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣an−1an−3an−5⋯⋯⋯0anan−2an−4⋯⋯⋯⋮0an−1an−3an−4⋯⋯⋮0anan−2an−4⋯⋯⋮⋮⋮⋮⋮⋱⋮⋮⋮⋯⋯⋯⋯⋱⋮0⋯⋯⋯⋯a2a0⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦ 左上をn−1として、下に行くと添え字を+1、右に行くと添え字を-2して、相当するaiがない箇所は0とした行列である。 この行列の左上側を起点とした1×1, 2×2, ⋯, n×nの小行列式Hiを導く。 H1=∣∣an1∣∣, H2=∣∣∣an1an−3anan−2∣∣∣, H3=∣∣ ∣ ∣∣an1an−3an−5anan−2an−40an−1an−3∣∣ ∣ ∣∣, ⋯ このとき 0\">ai>0 かつ 0\">Hi>0　⇒　全ての極の実部は負である が成り立つ。 "},"control/classical/feedback.html":{"url":"control/classical/feedback.html","title":"フィードバック制御系の特性","keywords":"","body":"フィードバック制御系の特性 フィードバック制御系はフィードフォワード制御系と比較して次のような特性を持つ。 制御対象のパラメーターの変動の影響を受けづらい 入力の変動時の速応性が改善される 外乱に強くなる 定常特性が改善される 一巡伝達関数が含む 1/s の積分器の数によって定常偏差の特性が定まる 1/s の積分器を1つ以上含めば定常位置偏差は0となり、外乱に対する定常偏差も0となる 周波数成分 s=0 に対して感度関数が0になるため 伝達関数 制御対象が1次系、制御機が定数ゲインの制御システムを例にとる。 　 P(s)=Aτs+1,   K(s)=K 上記のシステムのフィードフォワード系とフィードバック系の伝達関数はそれぞれ次のようになる。 Gf(s)=AKτs+1Gb(s)=AKτs+1+AK 感度特性 下の図を見てわかるように、フィードフォワード制御系では制御対象のパラメーターの変動・誤差（ここでは A:5→7）がそのまま現れてしまう。 一方、フィードバック制御系ではゲインを大きくするほど変動の影響が大幅に減少し速応性が改善される。 制御対象の伝達関数がP(s)→~P(s)のように変化したとき、系全体の伝達関数がT(s)→~T(s)と変化したとすると、双方の変動率には T(s)−~T(s)~T(s)=11+P(s)K(s)⋅P(s)−~P(s)~P(s) のような関係がある。この比率を感度関数（sensitivity function）と呼ぶ。 外乱に対する感度特性 P(s) への入力に d(s) の外乱が混ざるとする。このとき外乱が出力に与える変化量 yd(t) はフィードフォワード系・フィードバック系でそれぞれ yd(s)=P(s)d(s)yd(s)=P(s)1+P(s)K(s)d(s) となるため、先ほどの条件下では limt→∞yd(t)=5d(s)limt→∞yd(t)=0.05d(s) となる。 ここから、フィードバック系は外乱に対しても強くなることが確認できる。 目標値に対する定常特性 フィードバック系の制御量と目標値の偏差について考える。 追従偏差を e(t)=r(t)−y(t) とすると、閉ループを一巡したときの伝達関数（一巡伝達関数 ・ 開ループ伝達関数）は P(s)K(s) であるため、 e(s)=11+P(s)K(s)r(s) となる。 以下で確認できるように、位置・速度・加速度のいずれにおいてもゲインを高くするほど偏差は小さくなる。 ステップ入力 r(s)=1のステップ入力の定常偏差（steady-state error）を入出力比で考えると es=lims→0s11+P(s)K(s)1s=11+lims→0P(s)K(s) となる。ステップ入力の定常偏差を特に定常位置偏差（steady-state position error）、Kp=lims→0P(s)K(s) を位置偏差定数（position error constant）と呼ぶ。 ランプ入力 r(s)=tのランプ入力の定常偏差は es=lims→0s11+P(s)K(s)1s2=lims→01sP(s)K(s) となる。ランプ入力の定常偏差を特に定常速度偏差（steady-state velocity error）、Kv=lims→0sP(s)K(s) を速度偏差定数（velocity error constant）と呼ぶ。 一定加速度入力 r(s)=t22の一定加速度入力の定常偏差は es=lims→01s2P(s)K(s) となる。一定加速度入力の定常偏差を特に定常加速度偏差（steady-state acceleration error）、Ka=lims→0s2P(s)K(s) を加速度偏差定数（acceleration error constant）と呼ぶ。 制御系の型と定常偏差 上記からわかるように、一巡伝達関数 P(s)K(s) に 1/s の積分器がいくつ含まれてるかによって定常位置偏差・定常速度偏差・定常加速度偏差の特性が決まる。 1/sl の積分器を含む制御系を l 型の制御系と呼ぶ。 型 r(t)=1 r(t)=t r(t)=t2/2 0型 11+Kp ∞ ∞ 1型 0 1Kv ∞ 2型 0 0 1Ka 特に定常位置偏差に注目すると1つ以上の 1/s の積分器を持つ制御系では定常偏差0が実現されることがわかる。 これは周波数成分 s=0 に対して一巡伝達関数が無限のゲインを持つ（P(0)K(0)=∞）ことで感度関数が0になるため、と解釈できる。 外乱に対する定常偏差 P(s) への入力に d(s) の外乱が混ざるとする。このとき外乱が出力に与える変化量 yd(t) は yd(s)=P(s)1+P(s)K(s)d(s) となる。ここで外乱がステップ入力であるとすると、 limt→∞yd(t)=limx→0sy(s)=P(0)1+P(0)K(0) となるため、外乱による定常偏差を0とするためには P(0)=0 または K(0)=∞ である必要がある。 プロパーな制御対象が P(0)=0 を満たすことはないため、実質的に K(s) が 1/s の積分器を持つことが外乱に対する定常偏差を0にする条件となる。 グラフのソースコード Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt import numpy as np t = np.arange(0, 6, 0.001) #A=5 tf_p = matlab.tf([5], [1, 1]) #制御対象（τ=1） #フィードフォワード tf_k1 = matlab.tf([0.2], [1]) #制御器（ゲイン:0.2） forward = tf_k1 * tf_p #フィードバック tf_k2 = matlab.tf([20], [1]) #制御器（ゲイン:20） back = matlab.feedback(tf_k2*tf_p, 1, -1) y_out, t_out = matlab.step(forward, t) plt.plot(t_out, y_out, c='orange', label='feed-forward(K=0.2, A=5)') y_out, t_out = matlab.step(back, t) plt.plot(t_out, y_out, c='blue', label='feed-back(K=20, A=5)') #---------- #A=7 tf_p = matlab.tf([7], [1, 1]) #制御対象（τ=1） #フィードフォワード tf_k1 = matlab.tf([0.2], [1]) #制御器（ゲイン:0.2） forward = tf_k1 * tf_p #フィードバック tf_k2 = matlab.tf([20], [1]) #制御器（ゲイン:20） back = matlab.feedback(tf_k2*tf_p, 1, -1) y_out, t_out = matlab.step(forward, t) plt.plot(t_out, y_out, c='orange', linestyle=':', label='feed-forward(K=0.2, A=7)') y_out, t_out = matlab.step(back, t) plt.plot(t_out, y_out, c='blue', linestyle=':', label='feed-back(K=20, A=7)') plt.title('Step response: $P(s)=\\\\frac{A}{s+1}$') plt.xlabel('Time [s]') plt.ylabel('Output') plt.legend() plt.show() "},"control/classical/root_locus.html":{"url":"control/classical/root_locus.html","title":"根軌跡","keywords":"","body":"根軌跡（root locus） 根軌跡はフィードバック制御系においてゲインKを変えたとき極がどのように変化するかを示した図である。 ゲインに対してシステムの安定性がどのように変化するかを一望できる図として制御設計において重要視される要素のひとつとなっている。 定義 定数ゲイン（ゲイン：K）の直結フィードバック制御系について、伝達関数が次のように規格化されているとする。 G(s)=(s−z1)(s−z2)⋯(s−zm)(s−p1)(s−p2)⋯(s−pn) このときの閉ループの伝達関数は KG(s)1+KG(s)=KN(s)D(s)+KN(s) となり、その極は次の特性方程式 1+KG(s)=D(s)+KN(s)=0 を満たす。 ここでKを0→∞のように変化させたとき、極は複素数平面上を動くはずである。このときの極の軌跡を根軌跡と呼ぶ。根軌跡を示すグラフではG(s)の極を×、零点を○で示し、Kが増大する方向に矢印をつけるのが慣例となっている。 根軌跡の性質 根軌跡は開ループ伝達関数G(s)の極 pi(1≤i≤n) から出発し、そのうちm本の軌跡の終端はG(s)の零点 zi(1≤i≤m) であり、残りの n−m 本の軌跡は無限遠点に発散する 無限遠点に至る根軌跡の漸近線の角度は 180∘+360∘ln−m （lは任意の整数）となる つまり実数軸の負の方向を基準に一周を n−m 分割するような漸近線が描かれる 実軸上の点の右側に、重複度も考慮して実極と実零点が合計奇数個あればその点は根軌跡上の点である 根軌跡が実軸状から分岐・合流する点は dds1G(s)=0 を満たす 複素極 pj から根軌跡が出発する角度は 180∘−∑i≠j∠(pj−pi)+∑mi=1∠(pj−zi) 、複素零点 zj へ根軌跡が終端する角度は 180∘+∑ni=1∠(zj−pi)−∑i≠j∠(zj−zi) となる グラフのソースコード Python 3.6.1, matplotlib 2.0.1, control 0.7.0 from control import matlab import matplotlib.pyplot as plt tf = matlab.tf([1], [1, 2, 0]) #制御対象 matlab.rlocus(tf) plt.title('Root locus: $G(s)=\\\\frac{1}{s(s+2)}$') plt.show() from control import matlab import matplotlib.pyplot as plt tf = matlab.tf([1], [1, 6, 8, 0]) #制御対象 matlab.rlocus(tf) plt.title('Root locus: $G(s)=\\\\frac{1}{s(s+2)(s+4)}$') plt.show() from control import matlab import matplotlib.pyplot as plt tf = matlab.tf([1], [1, 4, 6, 4]) #制御対象 matlab.rlocus(tf) plt.title('Root locus: $G(s)=\\\\frac{1}{(s+2)(s^2+2s+2)}$') plt.show() "},"control/classical/frequency_response.html":{"url":"control/classical/frequency_response.html","title":"周波数応答","keywords":"","body":"周波数応答（frequency response） 周波数特性 安定な線形システムに一定周波数の正弦波を加え続けると、定常状態の出力も同じ周波数の正弦波になることが知られている。 このとき、出力の振幅と位相は入力と伝達関数 G(s) に依存して変化する。 特に入力の周波数に対する変化の特性を周波数特性と呼ぶ。 伝達関数と周波数特性 伝達関数 G(s)=N(s)/D(s) の安定な線形システムに一定周波数の正弦波 u(t)=ejωt=cosωt+jsinωt を加えたときの出力 y(t) について考えると、 Y(s)=G(s)L[u(t)]Y(s)=G(s)1s−jω G(s) の極 piを用いて右辺を部分分数分解すると Y(s)=K0s−jω+n∑i=1Kis−piy(t)=K0ejωt+n∑i=1Kiepit 安定なシステムであることから Re[pi]0 (i=1∼n) を満たすため、 t→∞ のとき、第二項は無視できる y(t)≃K0u(t) また部分分数分解の係数の性質より K0=lims→jω(s−jω)G(s)=G(jω) であることを利用すると y(t)=G(jω)u(t)=|G(jω)| ej(ωt+ϕ) が得られる。（ただし ϕ=∠G(jω) ） 周波数伝達関数 上記の式より次のことがわかる。 出力の振幅は入力の振幅の |G(jω)| 倍になる（これをゲインと呼ぶ） 出力の位相は入力の位相より ϕ だけ進んだものになる（これを位相差と呼ぶ） このようにシステムの周波数特性は s=jω とした伝達関数から得られる。 この伝達関数を特に周波数伝達関数と呼ぶ。 "},"control/classical/vector_locus.html":{"url":"control/classical/vector_locus.html","title":"ベクトル軌跡","keywords":"","body":"ベクトル軌跡（vector locus） 周波数伝達関数 G(jω) について、ω を 0→∞ と変化させたとき、ベクトル G(jω) の先端を複素平面上にプロットしたものをベクトル軌跡という。 "},"control/classical/bode_diagram.html":{"url":"control/classical/bode_diagram.html","title":"ボード線図","keywords":"","body":"ボード線図（Bode diagram） システムの周波数特性について考えるとき、入力周波数とゲイン・位相の関係をグラフで表現したものをボード線図と呼ぶ。 一般的に、横軸に各周波数の対数、縦軸にゲインのデシベル値もしくは位相を置く。 デシベル 電圧・音圧：20log10V ボード線図には次のような利点がある。 広い周波数帯域を1つの図で扱える 複雑な伝達関数の周波数特性もボード線図の和として表現できる 折れ線近似が容易なため、周波数特性の概略が簡単に精度良く得られる ボード線図の性質 あるシステムがある周波数 ω∗ において伝達関数 G(jω∗)=∏ni=1Gi(jω∗) を持つとき、 G(jω∗)=G1(jω∗)⋅G2(jω∗)⋯Gn(jω∗)=r1ejθ1⋅r2ejθ2⋯rnejθn=(r1r2⋯rn)ej(θ1+θ2+⋯+θn) より 20log10|G(jω)|=n∑i=120log10|Gi(jω)|∠G(jω)=n∑i=1∠Gi(jω) となる。 この式から、伝達関数の乗算（システムの直列結合）はボード線図の和算に相当することがわかる。そのため、基本的な伝達関数のボード線図上の形状がわかっていれば、複雑な伝達関数のボード線図も容易に書くことができる。 1次系のシステムのボード線図 G(s)=11+jωT Python 3.6.1, numpy 1.12.0, matplotlib 2.0.1, control 0.7.0 import numpy as np from control import matlab import matplotlib.pyplot as plt #plotしたい周波数のリスト（指定しなければ自動で適当な範囲を描画してくれる） omegas = np.logspace(-2, 2, 100) for t in [0.1, 1, 10, 100]: tf = matlab.tf([1], [t, 1]) #制御対象 matlab.bode(tf, omegas) sp_gain = plt.subplot(211) sp_gain.set_ylim(-40, 20) plt.legend(('T=0.1', 'T=1', 'T=10', 'T=100')) plt.suptitle('Bode diagrams: $G(s)=\\\\frac{1}{1+j\\\\omega T}$') plt.show() 2次系のシステムのボード線図 G(s)=ω2ns2+2ζωns+ω2n import numpy as np from control import matlab import matplotlib.pyplot as plt #plotしたい周波数のリスト（指定しなければ自動で適当な範囲を描画してくれる） omegas = np.logspace(-2, 2, 100) for z in [0.1, 0.3, 0.5, 0.7, 0.9]: tf = matlab.tf([1], [1, 2*z, 1]) #制御対象 matlab.bode(tf, omegas) sp_gain = plt.subplot(211) sp_gain.set_ylim(-40, 20) sp_phase = plt.subplot(212) sp_phase.set_xlabel('$\\\\omega/\\\\omega_n$') plt.legend(('$\\\\zeta$=0.1', '$\\\\zeta$=0.3', '$\\\\zeta$=0.5', '$\\\\zeta$=0.7', '$\\\\zeta$=0.9')) plt.suptitle('Bode diagrams: $G(s)=\\\\frac{\\\\omega_n^2}{s^2+2\\\\zeta \\\\omega_n s + \\omega_n^2}$') plt.show() "},"control/classical/stability_of_feedback.html":{"url":"control/classical/stability_of_feedback.html","title":"フィードバック制御系の内部安定性","keywords":"","body":"フィードバック制御系の内部安定性 図のようなフィードバック制御系について考える。 プロパー性に関する議論を省略するため、P(s)=NP(s)DP(s) は厳密にプロパー、K(s)=NK(S)DK(S) はプロパーであると仮定する。 内部安定性（internal stability） 入力 r,d と出力 u,y の間で記述される次の4つの伝達関数すべてが安定であるかどうかを内部安定性と呼ぶ。 ⎧⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎨⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪⎩Gur(s)=K(s)1+P(s)K(s)=DP(s)NK(s)ϕ(s)Gud(s)=−P(s)K(s)1+P(s)K(s)=−NP(s)NK(s)ϕ(s)Gyr(s)=P(s)K(s)1+P(s)K(s)=NP(s)NK(s)ϕ(s)Gyd(s)=P(s)1+P(s)K(s)=NP(s)DK(s)ϕ(s)ϕ(s)=DP(s)DK(S)+NP(s)NK(s) またこのときの ϕ(s) を特性多項式（characteristic polynominal）と呼ぶ。 4つの伝達関数の分母は同じであるため、内部安定性に関して次の定理が成り立つ。 フィードバック制御系が内部安定である⇔　特性多項式 ϕ(s)=0 のすべての根の実部が負 解説 以前述べたようにフィードバック制御系の r から y への伝達関数は Gyr(s) となる。 ここで P(s)=1s−1, K(s)=s−1s のシステムについて考えると、 Gyr(s)=1s+1 となり、一見安定であるかのように見える。しかし、y の初期値 y0 を考慮すると y(s)=1s+1r(s)+s(s+1)(s−1)y0 となり、第二項に不安定極が残り y0≠0 の場合は発散してしまうことがわかる。 全体の伝達関数が安定になったのは DP(s)=s−1 の不安定極と NK=s−1 の零点が相殺されたためと解釈できる。 フィードバック制御系の安定性を考える際はこの不安定な極零相殺（unstable pole-zero cancellation）に注意しなければならないため、上記の特性多項式を用いた評価が必要になる。 追記 python-controlでは極零相殺されたときも発散しなかった。 とりあえず根軌跡を描画したとき、ぬるぽが発生するのでその辺が指標になりそう。 matlab本家なら多分ちゃんと対応してる。 "},"control/classical/nyquist_diagram.html":{"url":"control/classical/nyquist_diagram.html","title":"ナイキストの安定判別法","keywords":"","body":"ナイキストの安定判別法（Nyquist） フィードバック制御系の安定性で述べた通り、フィードバック制御系の内部安定性の判別には特性多項式の根を調べれば良い。 しかし特性多項式が高次である場合は、ラウス＝フルビッツの安定判別法の適用にさえ非常に手間がかかる。 そこで、特性多項式を直接計算するのではなく、開ループ伝達関数の周波数応答に基いて図的に安定性を判別する方法として考案されたのがナイキストの安定判別法である。 ナイキストの安定判別法は、実測可能なフィードフォワード制御系の周波数伝達関数 P(jω)K(jω) のベクトル軌跡からフィードバック制御系の安定性を判別できる点で優れている。 また、むだ時間を含む系にも適用できることが知られている。 手順 開ループ伝達関数（一巡伝達関数）P(s)K(s) の極の中で実部が正であるものの個数を調べ、これを Π とする。 開ループ伝達関数のベクトル軌跡 P(jω)K(jω) を各周波数 ω=0∼∞ の範囲で描く。さらにこれを実軸に関して上下対象に描き、ナイキスト軌跡 Γ を得る。 ナイキスト軌跡 Γ が点 (−1,0) の周りを時計方向にまわる回数（反時計方向は負として数える）を調べ、これを N とする。 閉ループ系の不安定な極の数は Z=N+Π となる。したがって、Z=0 であればフィードバック制御系は安定、Z≠0 であれば不安定である。 また、開ループ伝達関数が安定（ Π=0 ）であることがわかっているとき、N=0 かの検証だけになるため、次のように手順を簡略化できる。 開ループ伝達関数 P(s)K(s) の極の実部がすべて負であることを確認する。 開ループ伝達関数のベクトル軌跡 P(jω)K(jω) を各周波数 ω=0∼∞ の範囲で描く。 ω=0→∞ と辿ったとき、ベクトル軌跡が点 (−1,0) を常に左に見て動くならフィードバック制御系は安定、右に見て動くなら不安定である。 解説 P(s)=DP(s)NP(s),   K(s)=DK(s)NK(s) とする。一巡伝達関数 P(jω)K(jω) を用いて、 w=1+P(s)K(s)=NP(s)NK(s)+DP(s)DK(s)NP(s)NK(s)=(s−r1)(s−r2)⋯(s−rn)(s−p1)(s−p2)⋯(s−pn) よって w は系全体の極 ri と、開ループ系の極 pi によって表されることがわかる。 w の偏角について考えると、 ∠w=n∑i=1∠(s−ri)−n∑i=1∠(s−pi) である。 ここで複素平面上を 原点 → +∞j → +∞ → −∞j → 原点 と辿る閉曲線 C を考える。 ある極 q が不安定極である場合、q の実部は正であるため閉曲線 C の内側に存在するはずである。 s が閉曲線 C を辿りながら一周したとき、もし q が閉曲線 C の内側にあれば ∠(s−q) の総変化量は −360∘ となり、閉曲線 C の外側にあれば ∠(s−q) の総変化量は 0∘ となる。 よって右辺は −360∘×Z+360∘×Π とわかる。 また同じく s が閉曲線 C を辿りながら一周したときの w−1=P(s)K(s) の軌跡は、 原点 → ∞j のとき P(s)K(s)   (ω=0∼+∞) のベクトル軌跡と一致 +∞j → +∞ → −∞j のとき P(∞)K(∞)=0 （プロパー性より） −∞j → 原点 のとき P(s)K(s)   (ω=−∞∼0) のベクトル軌跡と一致 つまり P(s)K(s)   (ω=0∼+∞) のベクトル軌跡と実軸について対象な軌跡 となるため、上記のようなナイキスト軌跡に一致することがわかる。 よって左辺は ∠w の総変化量 =−360∘×N である（虚部が負の範囲は ∠w の総変化量の計算の際に相殺される）。 以上より −N=−Z+ΠZ=N+Π が得られ、閉ループ系の不安定極の個数 Z が計算できる。 "},"control/classical/gain_phase_margin.html":{"url":"control/classical/gain_phase_margin.html","title":"ゲイン余裕・位相余裕","keywords":"","body":"ゲイン余裕・位相余裕 開ループ伝達関数が安定であるときのナイキストの安定判別法では、ベクトル軌跡が点 (−1,0) を左右どちらに見ながら動くかを調べることで安定性を判別した。 同様にベクトル軌跡を見れば安定限界までの余裕を評価することもできる。 ω=0→∞ のとき、原点周りのベクトル軌跡は下の図のような軌跡を描く。 （From : http://cmorito.blogspot.jp/2012/05/blog-post_24.html） 用語 ゲイン交差周波数（gain crossover frequency） 点 G は |P(jωgc)K(jωgc)|=1 になるような各周波数 ωgc と対応しており、ωgc をゲイン交差周波数という。 位相交差周波数（phase crossover frequency） 点 P は ∠P(jωpc)K(jωpc)=−180∘ となるような角周波数 ωpc と対応しており、ωpc を位相交差周波数という。 ゲイン余裕（gain margin） 位相交差周波数において開ループ伝達関数のゲインを何倍にすればシステムが不安定になるかをゲイン余裕という。 一般的にデシベル値で表現される。 GM=1|OP|=−20log|OP|   [dB] 位相余裕（phase margin） ゲイン交差周波数において開ループ伝達関数の位相がどれだけ遅れるとシステムが不安定になるかを位相余裕という。 PM=∠GOP "},"control/modern/state_space_equation.html":{"url":"control/modern/state_space_equation.html","title":"状態方程式","keywords":"","body":"状態方程式（State-space Equation） 定義 システムを入力・出力・内部状態を表現する状態変数の関係で記述した連立方程式を状態方程式という。 なお、熱力学における気体の状態方程式とはまったく別物である。 一般に m 入力 r 出力の n 次元システムの状態方程式は ˙x=f(x,u)y=g(x,u) と表される。ただし x, y, u はそれぞれ n, m, r 次元のベクトル、˙x はベクトル x の微分である。 線形システムの場合、関数 f, g は行列演算によって表現できる。 ˙x=Ax+Buy=Cx+Du ただし A, B, C, D はそれぞれ n×n, n×m, r×n, r×m の定数行列である。 一般的なシステムでは入出力の間に何らかの動特性があることがほとんどのため、入出力直達項は考慮されないことが多い。そこで現代制御理論においては D=0 とした線形状態方程式を考えるのが一般的である。 ˙x=Ax+Buy=Cx 時変システムの状態方程式 時刻 t に依存してシステムの特性が変化するようなシステムを時変システムという。 一般的な時変システム ˙x=f(x,u,t)y=g(x,t) 線形時変システム ˙x=A(t)x+B(t)uy=C(t)x 状態方程式と伝達関数 伝達関数は入出力の関係だけに注目している一方、状態方程式は n 次の状態変数を考慮する。 そのため伝達関数表現が同じになるような異なる状態方程式が存在する。 言い換えると伝達関数は状態方程式を縮小した概念である。 また、伝達関数は主に1入力1出力について論じられる一方、状態方程式では m 入力 r 出力を扱う。 平衡点 f(x,0)=0 を満たす点をシステムの平衡点という。 線形システムの原点はその定義から、平衡点の1つである。 "},"control/modern/transition_matrix.html":{"url":"control/modern/transition_matrix.html","title":"状態方程式の解・遷移行列","keywords":"","body":"状態方程式の解 状態方程式 ˙x=Ax+Bu の解について考える。 a,b をスカラとしたとき、˙x=ax+bu の解は eat を用いて次のように表されることが知られている。 x(t)=ea(t−t0)x(t0)+∫tt0ea(t−τ)bu(τ)dτ また、eat はテイラー展開を利用して次のように表される。 eat=a+at+a2t22!+a3t33!+⋯ ここで a を行列に拡張することを考えて eAt=A+At+A2t22!+A3t33!+⋯ と定義すると、次のような演算について eat と同じ形で表されることが確認できる。  d(eAt)dt=AeAt=eAtA eA(t1+t2)=eAt1eAt2 (eAt)−1=e−At eAt|t=0=I ただし、e(A+B)t=eAteBt は AB=BA のときにしか成立しないなど、すべての演算が同じ形になるわけではない。 また、3つ目に示す通り A の正則・非正則にかかわらず eAt は正則になる。 上記の変形を用いれば ˙x=Ax+B の解は eat の場合と同じ形で表される。 x(t)=eA(t−t0)x(t0)+∫tt0eA(t−τ)Bu(τ)dτ これが状態方程式の解となる。 遷移行列（state-transition matrix） 上記の式で入力を u=0 とすれば、時刻 t における状態変数は初期状態 x(t0) を用いて次のように表される。 x(t)=eA(t−t0)x(t0) このときの係数 eA(t−t0) を遷移行列という。 要素の計算 遷移行列の要素は定義の式 eAt=A+At+A2t22!+A3t33!+⋯ から計算できるほか、ラプラス変換を用いても計算できる。 t0=0 として、eAt の性質から d(eAt)dt=AeAt 両辺をラプラス変換すると sL[eAt]−eA⋅0=AL[eAt]sL[eAt]−I=AL[eAt]eAt=L−1[(sI−A)−1] となり、これを計算すれば遷移行列の要素が求まる。 ただし、L−1[M] は行列 M の各要素を逆ラプラス変換した行列に等しい。 "},"control/modern/controllability_observability.html":{"url":"control/modern/controllability_observability.html","title":"可制御性・可観測性","keywords":"","body":"可制御性・可観測性 定義 可到達性（reachability）・可制御性（controllability） 有限時間で原点から任意の状態に移すような入力が存在するとき、システムは可到達であるという。 有限時間で任意の状態から原点に移すような入力が存在するとき、システムは可制御であるという。 その性質から「可到達 ⇒ 可制御」。 特に連続システムの場合は「可到達 = 可制御」。 可観測性（obserbability）・可再生性（detectability） 十分に時間が経過すれば、初期時刻から現在までの入出力データから初期状態を推定できるとき、システムは可観測であるという。 十分に時間が経過すれば、初期時刻から現在までの入出力データから現在の状態を推定できるとき、システムは可再生であるという。 その性質から「可観測 ⇒ 可再生」。 特に連続システムの場合は「可観測 = 可制御」。 直観的には 可到達：うまくコントロールすると任意の状態に持っていける 可制御：うまくコントロールすると原点に戻せる（少なくとも暴走は止められる） 可観測：入出力を観測すれば状態がわかる 可再生：入出力を観測すれば現在の状態だけはわかる 判別 次のような連続時間システムについて考える。 ˙x=Ax+Buy=Cx 可制御性 MC=[BAB⋯An−1B] がフルランク（ rank(MC)=n ）⇔　システムは可制御 可観測性 MO=⎡⎢ ⎢ ⎢ ⎢⎣CCA⋮CAn−1⎤⎥ ⎥ ⎥ ⎥⎦ がフルランク（ rank(MO)=n ）⇔　システムは可観測 "},"control/modern/canonical_form.html":{"url":"control/modern/canonical_form.html","title":"可制御正準形・可観測正準形","keywords":"","body":"可制御正準形・可観測正準形 状態方程式の同値変換（conversion to equivalent model） 任意の状態方程式が与えられているとする。 ˙x=Ax+Buy=Cx このとき、任意の正則行列 T を用いて ¯x=Tx と置くと、先程の状態方程式は ˙¯x=TAT−1¯x+TBuy=CT−1¯x となり、¯A=TAT−1, ¯B=TB, ¯C=CT−1 をパラメーターとする同値な状態方程式に変換することができる。これを同値変換という。 また、同値なシステムの伝達関数は一致する。 1入力1出力システムの可制御正準形（controllable canonical form） 1入力1出力の n 次元の状態変数を持つ可制御なシステムは T=(MCT1)−1T1=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣α1α2⋯αn−11α2α3⋯10⋮⋮⋱⋮⋮αn−11⋯0010⋯00⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦det(sI−A)=sn+αn−1sn−1+⋯+α1s+α0 を用いて次のようなパラメーターを持つシステムに同値変換できる。 ¯A=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣010⋯0001⋯0⋮⋮⋮⋱⋮000⋯1−α0−α1−α2⋯−αn−1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦¯B=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣00⋮01⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦¯C=CMC これを1入力1出力システムの可制御正準形という。 1入力1出力システムの可観測正準形（observable canonical form） 1入力1出力の n 次元の状態変数を持つ可観測なシステムは T=T1MOT1=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣α1α2⋯αn−11α2α3⋯10⋮⋮⋱⋮⋮αn−11⋯0010⋯00⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦det(sI−A)=sn+αn−1sn−1+⋯+α1s+α0 を用いて次のようなパラメーターを持つシステムに同値変換できる。 ¯A=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣00⋯0−α010⋯0−α101⋱⋮−α2⋮⋱⋱0⋮0⋯01−αn−1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦¯C=[00⋯01]¯B=T1MOB これを1入力1出力システムの可観測正準形という。 多入力システムの可制御正準形（controllable canonical form） 多入力システムに関しても可制御正準形を定義できる。 B=[b1b2⋯bm] であるとき、変換行列 T は次のようにして求められる。 MC=[b1b2⋯Ajbi⋯An−1bm] の左側から順に一次独立なベクトルをなるべく多く選び、そのうち bi の積で表されているものの数を μi とする つまり μi=min{j | Ajbi∈span[MC]} これを可制御性指数と呼ぶ ∑mi=0μi=n S=[b1Ab1⋯Aμ1−1b1b2⋯Aμ2−1b2⋯Aμm−1bm] とする S−1 の第 ∑ij=1μj 行目を ^s=1 とする T を次のように定義する T=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣^s1^s1A⋮^s1Aμ1−1^s2⋮^smAμm−1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦ この同値変換によって得られる新しいパラメーターは (¯A,¯B,¯C) は次のような形になる。 ¯A=⎡⎢ ⎢ ⎢⎣¯A11⋯¯A1m⋮⋱⋮¯Am1⋯¯Amm⎤⎥ ⎥ ⎥⎦¯B=⎡⎢ ⎢⎣¯B1⋮¯Bm⎤⎥ ⎥⎦¯Aii=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣010⋯0001⋯⋮⋮⋮⋮⋱000⋯01∗⋯⋯⋯∗⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦   (μi×μi)¯Aij=⎡⎢ ⎢ ⎢ ⎢⎣0⋯⋯0⋮⋯⋯⋮0⋯⋯0∗⋯⋯∗⎤⎥ ⎥ ⎥ ⎥⎦   (μi×μj,i≠j)¯Bi=⎡⎢ ⎢ ⎢ ⎢⎣0⋯⋯⋯⋯⋯0⋮⋯⋯⋯⋯⋯⋮0⋯⋯⋯⋯⋯00⋯01∗⋯∗⎤⎥ ⎥ ⎥ ⎥⎦   (μi×m,中央はi列目)¯C=⎡⎢ ⎢⎣∗⋯∗⋮⋯⋮∗⋯∗⎤⎥ ⎥⎦ "},"control/modern/canonical_decomposition.html":{"url":"control/modern/canonical_decomposition.html","title":"正準分解","keywords":"","body":"正準分解（canonical decomposition） ある任意のシステムが与えられたとき、可制御性と可観測性の概念に基づいていくつかのサブシステムに分割する事ができ、これをカルマンの正準分解という。 定理 ˙x=Ax+Buy=Cx は適当な同値変換を用いて ˙¯x=F¯x+Guy=H¯xF=⎡⎢ ⎢ ⎢ ⎢⎣FaaFabFacFad0Fbb0Fbd00FccFcd000Fdd⎤⎥ ⎥ ⎥ ⎥⎦G=⎡⎢ ⎢ ⎢ ⎢⎣GaGb00⎤⎥ ⎥ ⎥ ⎥⎦H=[0Hb0Hd] に変換できる。 解説 参考：http://ogyahogya.hatenablog.com/entry/2015/10/18/%E5%8F%AF%E5%88%B6%E5%BE%A1%E6%80%A7%E3%83%BB%E5%8F%AF%E8%A6%B3%E6%B8%AC%E6%80%A7 概要 システム内部の状態変数 x が取りうる値全体の集合（状態空間）を χ とおく。 可制御性行列 MC・可観測性行列 MO を利用すると、可制御空間 χC と不可観測空間 χ¯O は χC=ImMCχ¯O=KerMO であり、かつそれぞれが A について不変な部分空間であることが証明できる。 ここで部分空間 χa,χb,χc,χd を次のように定義する。 χa=χC∩χ¯OχC=χa⊕χbχ¯O=χa⊕χcRn=χa⊕χb⊕χc⊕χd それぞれの基底を Ξa,Ξb,Ξc,Ξd とすると AΞa=ΞaFaaAΞb=ΞaFab+ΞbFbbAΞc=ΞaFac+ΞcFccAΞd=ΞaFad+ΞbFbd+ΞcFcd+ΞdFdd と表されることがわかる。 ここで T−1=[ΞaΞbΞcΞd] なる同値変換によって上記の形に変換することができる。 χC=ImMC であることの証明 状態方程式の解より x(t)=eA(t−t0)x(t0)+∫tt0eA(t−τ)Bu(τ)dτ である。 まず χC⊂ImMC を示す。可制御性の条件を「時刻 0 から適当な有限時刻 T で x を原点に移すような入力 u(t) が存在する」と考えると 0=eATx(0)+∫T0eA(T−τ)Bu(τ)dτx(0)=−∫T0eAτBu(τ)dτ が満たされるはずである。 右辺をテイラー展開して x(0)=−∫T0(I+A(−τ)+A2(−τ)22!+⋯)Bu(τ)dτ さらにケーリー・ハミルトンの定理を用いれば An,An+1,⋯ は A0∼An−1 の一次多項式として表せるため x(0)=[BAB⋯An−1B]⎛⎜ ⎜ ⎜ ⎜⎝∗∗⋮∗⎞⎟ ⎟ ⎟ ⎟⎠∈ImMC となり χC⊂ImMC が示された。 次に χC⊃ImMC を示す。 （書いてる途中） 手順まとめ 可制御性行列 MC と可観測性行列 MO を求める 可制御空間 χC=ImMC・不可観測空間 χ¯O=KerMO を求める 部分空間 χa,χb,χc,χd の基底 Ξa,Ξb,Ξc,Ξd を求める（以下の条件を満たすなら選び方は任意） χa=χC∩χ¯O χC=χa⊕χb χ¯O=χa⊕χc Rn=χa⊕χb⊕χc⊕χd T−1=[ΞaΞbΞcΞd] を変換行列としてシステムを同値変換する "},"control/modern/transfer_function_matrix.html":{"url":"control/modern/transfer_function_matrix.html","title":"伝達関数行列と実現問題","keywords":"","body":"伝達関数行列（transfer function matrix） 定義 ˙x=Ax+Buy=Cx をラプラス変換すると sX(s)=AX(s)+bU(s)Y(s)=cX(s) となるため、入力と出力の関係を直接表した式 Y(s)=G(s)U(s)G(s)=C(sI−A)−1B が得られる。 このときの G(s) を伝達関数行列と呼ぶ。 性質 互いに同値なシステムに対する伝達関数行列はすべて等しい。 G(s) に変換行列 T に関する同値変換を施すと ¯G(s)=CT−1(sTT−1−TAT−1)−1TB=C(sI−A)−1B=G(s) となり、変換前後で一致する。 また、カルマンの正準分解を用いれば、G(s) は可制御可観測なサブシステムの係数によってのみ表現されることがわかる。 G(s)=Hb(sI−Fbb)−1Gb 実現問題 ある伝達関数行列 G(s) が与えられたとき、それを実現する状態方程式を求める問題を実現問題という。 実現可能性 伝達関数行列の各要素が次のよう表されているとする。 gij=Nij(s)Dij(s) Nij(s), Dij(s) が s の多項式で表されるとき（有理関数であるとき）、次の定理が成立する。 伝達関数行列の各要素が有理関数かつ厳密にプロパーである⇔　それを実現する状態方程式が存在する 最小実現 実現問題の解において、状態変数の次数が最小のものを最小実現という。 最小実現にも状態変数の取り方が異なる同値な表現が複数存在する。 条件 最小実現について次の定理が成立する。 状態方程式が可制御可観測　⇔　実現問題の最小実現である これは後述するハンケル行列の同値変換を考えることで証明できる。 最小実現の次数 伝達関数行列の各要素の分母 Dij(s) の最小公倍多項式 γ(s) の次数を ν とする。 ここで次のようにマルコフパラメータを定義する。 Jk=CAkB eAt のラプラス変換を考慮すると、マルコフパラメータは次の性質を満たす。 G(s)=∞∑i=1Ji−1s−i またマルコフパラメータを用いて次のようにハンケル行列を定義する。 Hl=⎡⎢ ⎢ ⎢ ⎢ ⎢⎣J0J1⋯Jl−1J1J2⋯Jl⋮⋮⋱⋮Jl−1Jl⋯J2l−2⎤⎥ ⎥ ⎥ ⎥ ⎥⎦=⎡⎢ ⎢ ⎢ ⎢⎣CCA⋮CAk−1⎤⎥ ⎥ ⎥ ⎥⎦[BAB⋯Ak−1B]=MCMO γ(s) の次数 ν によるハンケル行列の階数 rankHν をマクミラン次数という。 最小実現　⇔　状態方程式が可制御可観測　⇔　rankMCMO=n 、であるからマクミラン次数について次の定理が成立する。 最小実現における状態変数の次元数　＝　マクミラン次数 Mooreのアルゴリズム 最小実現を求めるアルゴリズムにMooreのアルゴリズムがある。 最小公倍多項式 γ(s) の次数 ν と aν=1 で正規化した係数 a0,⋯,aν−1 を求める G(s)=Gν−1sν−1+⋯+G0γ(s) の形に変形する Jk=lims→∞Gk(s) G0(s)=sG(s) Gk(s)=s{Gk−1(s)−Jk−1} 可制御な実現を求める ~A=[OI(ν−1)m−a0Im−a1Im ⋯ −aν−1Im] ~B=[OIm] ~C=[G0⋯Gν−1] (~A,~B,~C) が可観測なら終了 カルマンの正準分解を利用して可制御可観測なサブシステムを求める "},"control/modern/lyapunov_stability_theory.html":{"url":"control/modern/lyapunov_stability_theory.html","title":"リアプノフの安定性理論","keywords":"","body":"リアプノフの安定性理論（Lyapunov stability theory） 定義 一般の非線形自立システム ˙x=f(x) について考える。 ここでシステムは原点を平衡点が原点である、つまり f(0)=0 を仮定する。 システムの平衡点が f(xs)=0 であるなら、状態変数を x−xs で定義しなおすことで f′(0)=0 のように変換できるので、f(0)=0 と仮定しても一般性を失わない。 このシステムの安定性を次のように定義する。 安定 任意に与えられた 0\">ε>0 に対して適当な 0\">δ(ε)>0 が存在し、初期点が ||x(0)||δ を満たすとき、すべての時刻 t≥0 において ||x(t)||ε を満たすならば、原点 0 は安定であるという。 つまり初期値が有界であるとき、零入力を加え続けると状態変数も有界になる（発散しない）。 漸近安定 原点が安定かつ limx→∞||x(t)||→0 ならば、原点 0 は漸近安定であるという。 確認方法 適当なリアプノフ候補関数 V(x) を定義する。 この関数が平衡点を含むある領域 Ω で正定（もしくは準正定）であり、システムの軌道に沿っての時間微分 ˙V(x)=dV(x(t))dt=(∂V(x)∂x)Tf(x) が準負定であるとき、この関数をリアプノフ関数という。 リアプノフの安定性は次の定理から確認できる。 リアプノフ関数 V(x) が存在する　⇒　平衡点で安定である また 領域 Ω で ˙V(x) が負定関数⇔　任意の x(0)≠0 に対するシステムの解 x(t) が t≥0 において恒等的には ˙V(x(t))=0 とならない⇒　平衡点で漸近安定である 線形システムに対するリアプノフの安定性 リアプノフの安定性理論を線形システムに適用すると次の定理が得られる。 システムの原点が漸近安定である⇔　任意の正定行列 Q に対して ATP+PA=−Q となる正定行列 P が唯一存在する⇔　det(sI−A)=0 のすべての根の実部が負 最後の条件はフルビッツの安定判別法を用いて調べることができる。 また、対 (A,C) が可観測であるなら次の定理が成立する。 A が漸近安定行列（すなわち ˙x=Ax が漸近安定）である⇔　ATP+PA=−CTC を満たす P が正定 "},"control/modern/pole_placement.html":{"url":"control/modern/pole_placement.html","title":"極配置","keywords":"","body":"極配置 状態フィードバックを返すことによってシステムの極を任意に設定することを極配置という。 極配置可能性 定数ゲインによる状態フィードバック u=Kx+v によって極配置を行う場合、つぎの定理が成り立つ。 対 (A,B) が可制御　⇔　任意の極配置が可能 可制御正準形と同値変換によって固有値（極）が保存されることを利用すれば証明できる。 手順 状態フィードバックを返すことで状態方程式は {˙x=(A+BK)x+Bvy=Cx となる。 このときの極は det[sI−(A+BK)]=0 を満たす s である。 "},"control/modern/observer.html":{"url":"control/modern/observer.html","title":"オブザーバ","keywords":"","body":"オブザーバ（observer） 概要 極配置で導入した状態フィードバックは状態変数が観測できることを前提にしている。 しかし、システムによってはすべての状態変数がセンサーなどで計測できないことがある。 そこでオブザーバーと呼ばれるシステムを並行して動作させ、状態変数の推定値 w を得ることで状態フィードバックを行う。 状態オブザーバーの基本形は次のような形で表される。 {˙z=Fz+Gy+Huw=Wz+Vy 十分な時間が経過したとき、実際の状態変数 x とオブザーバの出力 w の推定誤差 ||x−w|| が0に収束するように各パラメーターを選ぶ。 一般にこのようなパラメーターは複数存在する。 同一次元状態オブザーバ 線形システム {˙x=Ax+Buy=Cx と状態変数と同じ次元数を持つ状態オブザーバを同一次元状態オブザーバという。 同一次元状態オブザーバはもとのシステムのパラメーターを用いて次のように定義する。 {˙z=Az+Bu+G(y−Cz)w=z ここで次の定理が成立する。 対 (A,C) が可制御　⇒　(A−GC) の固有値を任意に配置できる よって推定誤差を任意の速さで0に収束させうる。 最小次元状態オブザーバ 推定したい状態変数 x の次元は n 、システムから得られる出力は r 次元なので、状態オブザーバが推定すべき状態の次元は (n−r) 以上である。 状態オブザーバの次元数が最小 (n−r) であるものを最小次元状態オブザーバという。 まず T が n×n の正則行列になるように適当な D を選択する。 T=[CD] T を用いた同値変換を行い、C,D に対応する部分を添字 1,2 で表わせば ¯x=Tx=[¯x1¯x2]¯A=TAT−1=[¯A11¯A12¯A21¯A22]¯B=TB=[¯B1¯B2]¯C=CT−1=[Ir0] となる。 ここで ¯x2 の同一次元状態オブザーバは次のようになる。 {˙~z=¯A22~z+¯A21y+¯B2u+~G[(˙y−¯A11y−¯B1u)−¯A12~z]¯w2=~z ˙y を除くために z=~z−~Gy とすれば ˙~z=[¯A22−~G¯A12]z+[¯A22~G+¯A21−~G(¯A12~G+¯A11)]y+[¯B2−~G¯B1]uw=T−1[y¯w2]=T−1[0In−r]z+T−1[Ir~G]y 対 (A,C) が可観測なら (¯A22,¯A12) も可観測となるため、同一次元オブザーバの解説の通り、[¯A22−~G¯A12] の固有値を任意に設定するような ~G が存在する。 "},"computer_science/signal/intro.html":{"url":"computer_science/signal/intro.html","title":"概要","keywords":"","body":"信号処理 概要 目的 項目 雑音除去 雑音を取り除いて元の信号のみを取り出す 等化 歪んだ信号を元の信号に戻す 予測 過去の信号を使って未来の信号の値を予測する データ圧縮 信号の冗長な成分を取り除いてコンパクトに表現する システム同定 観測した信号からシステムの数学モデルを作成する スペクトル推定 信号がどの周波数成分をどれくらい含むかを解析する 信号の分類 時間\\振幅 連続 離散 連続 アナログ信号 多値信号 離散 サンプル値信号 ディジタル信号 偶信号／奇信号 偶信号（even signal） f(−t)=f(t),  x−n=xn 奇信号（odd signal） f(−t)=−f(t),  x−n=−xn 周期信号（periodic signal） 基本周期（fundamental period） f(t)=f(t+T),  xn=xn+N を満たす最小の T,  N 基本周波数（fundamental frequency） 1/T,  1/N A/D処理 処理 標本化（sampling） アナログ信号->サンプル値信号 量子化（quantization） サンプル値信号->ディジタル信号 エネルギー（energy） E=∫∞−∞|x(t)|2dtE=∞∑n=−∞|xn| E∞ を満たす信号は有限エネルギー信号（finite energy signal）と呼ばれる。 パーセバルの等式も参照。 平均パワー（average power） 単位時間あたりのエネルギーは平均パワーと呼ばれる。 P=limT→∞1T∫T/2−T/2|x(t)|2dtP=limN→∞12N+1N∑n=−N|xn|2 内積（inner product） 信号値 x の複素共役を ¯x と表現することにすると、信号の内積は次のように定義される。 ⟨x,y⟩=∫∞−∞x(t)¯y(t)dt⟨x,y⟩=∞∑n=−∞xn¯yn ノルム（norm） 信号のノルムは次のように定義される。 ||x||=√⟨x,x⟩ 相互相関関数（cross correlation function） yτ=y(t−τ)rxy(τ)=⟨x,yτ⟩=∫∞−∞x(t)¯y(t−τ)dt ここで相互相関関数は 0≤|rxy(τ)|≤∥x∥ ∥y∥ を満たす。 また 0=rxy(τ) なら x と yτ は直交しており、|rxy(τ)|=∥x∥ ∥y∥ なら相似であると言える。 "},"computer_science/signal/continuous_time_fourier.html":{"url":"computer_science/signal/continuous_time_fourier.html","title":"連続時間信号のフーリエ解析","keywords":"","body":"連続時間信号のフーリエ解析 解析でよく用いる連続時間正規直交信号（orthonormal signal） fn(t)={1(n=0)√2cos(nω0t)(n=1,2,⋯)gn(t)=√2sin(nω0t)   (n=1,2,⋯) ここで f0(t),f1(t),f2(t),⋯,g1(t),g2(t),⋯ は1周期のノルムが1であり互いに直交するため正規直交系であると言える。 検証 fn(t),gn(t) の定義域を1周期分に限ったものを f′n(t),g′n(t)  (0≤t≤2πnω0) とすると ∥f′n∥=nω02π∫2π/nω00∥f′n(τ)∥ dτ=nω02π∫2π/nω002cos2(nω0τ) dτ=nω02π∫2π/nω00(cos(2nω0τ)+1)dτ=nω02π{[12nω0sin(2nω0τ)]2π/nω00+[τ]2π/nω00}=1 ∥g′n∥=nω02π∫2π/nω00∥g′n(τ)∥ dτ=nω02π∫2π/nω002sin2(nω0τ) dτ=nω02π∫2π/nω00(1−cos(2nω0τ))dτ=nω02π{[τ]2π/nω00−[12nω0sin(2nω0τ)]2π/nω00}=1 rf′ng′n=nω02π∫2π/nω002sin(nω0τ)cos(nω0τ) dτ=nω02π∫2π/nω00sin(2nω0τ) dτ=nω02π[−12nω0cos(2nω0τ)]2π/nω00=0 "},"computer_science/signal/discrete_time_fourier.html":{"url":"computer_science/signal/discrete_time_fourier.html","title":"離散時間信号のフーリエ解析","keywords":"","body":"離散時間信号のフーリエ解析 離散フーリエ変換（Discrete Fourier Transform : DFT） サンプル数 N の信号に対してDFTとIDFTは次のように定義される。 Xk=N−1∑n=0xne−2πjnk/Nxn=1NN−1∑n=0Xke2πjnk/N Xk：k 次高調波の周波数スペクトル |Xk|：k 次高調波の振幅スペクトル ∠Xk：k 次高調波の位相スペクトル |Xk|2：k 次高調波のエネルギースペクトル サンプリング周波数を T としたとき、0∼N は時間 NT に相当する。 すなわち基本周波数は 1/NT 、k 次高調波の周波数は k/NT になる。 基本波の角周波数は 2π/NT 、k 次高調波の角周波数は 2kπ/NT である。 ピリオドグラム（periodgram） 信号にはある程度のノイズが含まれていることが想定されるため、確率的な扱いをしたいケースがある。 ピリオドグラムは角周波数 Ω ごとにエネルギースペクトルの平均を計算し、ノイズの影響を減らしたものである。 P(Ω)=1N∣∣ ∣∣N−1∑n=0xne−jnΩT∣∣ ∣∣2 離散フーリエ変換の行列表現 W=e−2πj/N とするとDFTは次のように表される。 ⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣X0X1X2⋮XN−1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣W0W0W0⋯W0W0W1W2⋯W(N−1)W0W2W4⋯W2(N−1)⋮⋮⋮⋱⋮W0WN−1W2(N−1)⋯W(N−1)2⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣x0x1x2⋮xN−1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦ これを X=Ax と見れば、A は AAH=AHA=I を満たすため、逆フーリエ変換は次のように表される。 x=1NAHX "},"computer_science/algorithm/execution_cost.html":{"url":"computer_science/algorithm/execution_cost.html","title":"アルゴリズムのコスト","keywords":"","body":"アルゴリズムのコスト 漸近記法（asymptotic notation） Big-Θ 記法 ある関数 f(n) に対して関数 g(n) が次の性質を満たすとき、f(n)=Θ(g(n)) であると記述する。 0, c_2 > 0, n_0 > 0 \\ ^\\forall n \\geq n_0 \\ (0 \\leq c_1 g(n) \\leq f(n) \\leq c_2 g(n))\">∃c1>0,c2>0,n0>0 ∀n≥n0 (0≤c1g(n)≤f(n)≤c2g(n)) Big-O 記法 オーダー記法とも。 ある関数 f(n) に対して関数 g(n) が次の性質を満たすとき、f(n)=O(g(n)) であると記述する。 0, n_0 > 0 \\ ^\\forall n \\geq n_0 \\ (0 \\leq f(n) \\leq c g(n))\">∃c>0,n0>0 ∀n≥n0 (0≤f(n)≤cg(n)) Little-o 記法 ある関数 f(n) に対して関数 g(n) が次の性質を満たすとき、f(n)=o(g(n)) であると記述する。 0, n_0 > 0 \\ ^\\forall n \\geq n_0 \\ (0 \\leq f(n) ∃c>0,n0>0 ∀n≥n0 (0≤f(n)cg(n)) Big-Ω 記法 ある関数 f(n) に対して関数 g(n) が次の性質を満たすとき、f(n)=Ω(g(n)) であると記述する。 0, n_0 > 0 \\ ^\\forall n \\geq n_0 \\ (0 \\leq c g(n) \\leq f(n))\">∃c>0,n0>0 ∀n≥n0 (0≤cg(n)≤f(n)) Little-ω 記法 ある関数 f(n) に対して関数 g(n) が次の性質を満たすとき、f(n)=ω(g(n)) であると記述する。 0, n_0 > 0 \\ ^\\forall n \\geq n_0 \\ (0 \\leq c g(n) ∃c>0,n0>0 ∀n≥n0 (0≤cg(n)f(n)) オーダー記法と実行時間 アルゴリズムの実行時間は入力の大きさ（ソートなら対象の要素数、文字列の置換なら文字数、など）をnとしたオーダー記法によって表現することが多い。 例えば全ての要素に対して3重のループを回すような処理は「O(n3) の処理」と言える。 競技プログラミングではざっくり次のようなイメージを持っておくとよいらしい。 O(g(n)) 106=1,000,000 余裕をもって間に合う 107=10,000,000 おそらく間に合う 108=100,000,000 非常にシンプルな処理でない限り厳しい 問題のクラス 計算複雑性理論（computational complexity theory）では、アルゴリズムや問題はその複雑さに応じたクラスに分類される。 ※ 以下の議論ではyes/noで解を出せる判定問題に帰着させて考える。 ソートアルゴリズムも「ソート済みのリストは存在するか？」という問題の解がyesであることの根拠（具体的なソート済みのリスト）を提示する問題として考えれば判定問題の一種と見なせる。 クラスP 決定性チューリングマシン（つまりifによる探索の分岐が発生しない解法）によって多項式時間（polyminal time）で解が求まる判定問題のクラスをクラスPという。 つまり「根拠の列挙及び判定のすべてが多項式時間でできる」判定問題のクラス。 クラスNP 非決定性チューリングマシンによって多項式時間で解が求まる判定問題のクラスをクラスNPという。 これは、ある根拠の候補が得られたときその候補を判定する問題がクラスPであるような問題、と言い換えても同値である。 クラスPはクラスNPの中の特殊なケースとして考えられる。 つまり「根拠1つの判定は多項式時間でできる」判定問題のクラス。 NP完全 クラスNPに含まれる問題のうち、問題に多項式時間の変形を施すことで別のクラスNPの問題に帰着させられるような問題をNP完全な問題という。 クラスNPに含まれる問題の中で最も難しい部類の問題であり、これがすべてクラスPに属するならN=NPが証明できたことになる。 NP困難 クラスNPの問題がある問題に帰着する（多項式時間多対一帰着や多項式時間チューリング帰着を用いるらしい）とき、その問題をNP困難という。 ここには非判定問題も含まれる。 定義よりクラスNPの問題以上に難しい問題であることが明らかな問題といえる。 "},"computer_science/algorithm/sort1.html":{"url":"computer_science/algorithm/sort1.html","title":"ソートアルゴリズム1","keywords":"","body":"ソートアルゴリズム1 要素を昇順・降順に並び替えるアルゴリズムについて言及する。 なお、時間計算量・空間計算量・安定性などの一覧表はwikipediaにきれいにまとまっている。 Wikipedia：ソート 次の動画もおすすめ。 【音付き】15種のソートアルゴリズムの可視化 サンプルプログラム 次のようなswap関数とmain関数が用意される前提で書く。 void swap(int* a, int* b) { int tmp = *a; *a = *b; *b = tmp; } int main(void) { int data[] = {8, 1, 5, 0, 2, 3, 6, 9, 7, 4}; //sort(data, 10); for (int i = 0; i ソートアルゴリズムに関する用語 内部整列と外部整列 すべての対象データが主記憶領域にある状態で行うソートを内部整列（internal sort）、一部のデータしか主記憶領域に置くことができない状態で行うソートを外部整列（external sort）と呼ぶ。 一般的に外部整列ではシーケンシャルアクセスに重きを置いたアルゴリズムを用いることで外部記憶領域のデータへのアクセスを高速化する。 安定なソート ソート対象に同じ値を持つ要素が存在するとき、その並び順がソートの前後で変化しないことが保証されるものを安定なソートアルゴリズムと呼ぶ。 このページでは特に言及しない限り安定なアルゴリズムである。 分割統治法（divide and rule / divide and conquer） 対象となる問題を小さな問題に分割し、それをすべて解くことで元の問題を解決する手法。 ソートに限らず、アルゴリズムの世界でよく用いられる。 比較 ソートアルゴリズムにおける「比較」は要素の値同士の直接比較のことを指す。 値を直接比較するソートアルゴリズムでは時間計算量の下限が O(nlogn) になることが証明されている。 単純なアルゴリズム バブルソート（bubble sort） 隣り合う要素の大小を比較し並べ替えることを繰り返すアルゴリズム。 前から順に比較して昇順に並べ替えることにすると、1回目の比較でn番目（最後）の要素が最も大きな値を取り、値が確定する。よって2回目はn−1番目の要素までを比較すればよい。3回目以降も同様と考えれば、最終的に ∑n−1i1∑n−1j=1(n−j)=n(n−1)/2 回の比較でソートが完了する。 時間計算量：O(n2) 空間計算量：O(1) void bubble_sort(int *arr, int len){ //前から確定していくように、昇順に並べ替える例 for (int i = len - 1; i > 0; i--) for (int j = 0; j data[j + 1]) swap(&(data[j]), &(data[j + 1])); } 選択ソート（selection sort） 未整列の領域に対して、そのうちで最小の要素を先頭に持ってくることを繰り返すアルゴリズム。 安定でないソートアルゴリズムである。 前から処理を進めて昇順に並べ替える場合、次のような手順によって実現できる。 未整列の領域 a[i]∼a[n] のうち最小の要素a[p]を見つけ、a[p]とa[i]を入れ替える a[i+1]∼a[n] 以降に対して同様の操作を繰り返す 最終的に ∑n−1i1∑n−1j=1(n−j)=n(n−1)/2 回の比較でソートが完了する。 時間計算量：O(n2) 空間計算量：O(1) void selection_sort(int *arr, int len){ //前から確定していくように、昇順に並べ替える例 for (int i = 0; i arr[j]) swap(&(arr[i]), &(arr[j])); //簡易化のため先頭より小さい要素を見つけた時点でswapしている } 挿入ソート（insertion sort） 未整列の要素を1つ取り出し、整列済みの領域の適切な位置に挿入することを繰り返すアルゴリズム。 平均時間計算量：O(n2) 空間計算量：O(1) void insertion_sort(int *arr, int len){ //前側を整列済みとして昇順に並べ替える例 for (int i = 0; i 0 && arr[j - 1] > arr[j]) { swap(&(arr[j - 1]), &(arr[j])); j--; } } } シェルソート（Shell sort） 挿入ソートを改良したアルゴリズム。改良挿入ソートとも。 ソート前後の要素の移動量の総和は ∑ni=1∑nj=1|i−j|≃n23=O(n2) である。 隣り合う要素の比較を繰り返す限り時間計算量は O(n2) を超える。 そこで、あらかじめ h 離れた要素同士を比較・交換するh-ソートを行ってから、挿入ソートを実行するのがシェルソートである。 手順は以下の通り。 幅 h を適当に決定する h 離れた要素同士を比較・交換する作業を1周させる h を小さくして上記の手順を繰り返す h=1 のソートが終わったら挿入ソートを実行する ただし、正確な時間計算量を求める問題は未解決である。実験的な手法により hi=3i−12 としたとき、平均時間計算量が O(n1.25) になることがわかっているため、これを利用することが多い。 平均時間計算量：O(n1.25) 空間計算量：O(1) void insertion_sort(int *arr, int len) { for (int i = 0; i 0 && arr[j - 1] > arr[j]) { swap(&(arr[j - 1]), &(arr[j])); j--; } } } //昇順に並び替える例 void shell_sort(int *arr, int len) { int h; for (h = 1; h 0; h /= 3) { for (int i = h; i = h && arr[j - h] > arr[j]) { swap(&(arr[j]), &(arr[j - h])); j -= h; } } } insertion_sort(arr, len); } "},"computer_science/algorithm/sort2.html":{"url":"computer_science/algorithm/sort2.html","title":"ソートアルゴリズム2","keywords":"","body":"ソートアルゴリズム2 分割統治法によるソート クイックソート（quick sort） 基準の値（pivot）を設定し、それより大きい要素の領域・同じ値の要素の領域・小さい要素の領域に分割する作業を繰り返すアルゴリズム。安定でないソートアルゴリズムになる。 以下の手順による実装が有名。昇順に並び替える例。 対象領域をpivotより大きい要素の領域・同じ値の要素の領域・小さい要素の領域に分割する 適当な値をpivotとして選択する 対象領域の中央値が望ましいが計算コストが高い ランダムに1つ選ぶ、ランダムに3つ選んで中央値を取る、などの実装が多い 対象領域の両端にポインターを置く pivot以上の値が現れるまで前のポインターを後ろに進める pivot以下の値が現れるまで後ろのポインターを前に進める 前のポインター・後ろのポインターの位置の値を入れ替える 2つのポインターが交差するまで1~5を繰り返す 分割した2つの領域に対して上の作業を行う 現在発見されている内部整列のアルゴリズムとしては最速。 ただし、pivotとして選択した値が領域内の最大値・最小値であった場合、単なる選択ソートになるため最悪時間計算量は O(n2)となる。 ソート対象の性質や状態によっては他のアルゴリズムの方が早くなる。 平均時間計算量：O(nlogn) 最悪時間計算量：O(n2) 最良時間計算量：O(nlogn) 最悪空間計算量：O(n) ※ただし再帰のためにcall stackを消費するだけ // l:最初のindex, r:最後のindex void recursion(int *arr, int l, int r) { if (l >= r) return; // 先頭・中央・末尾の中央値をpivotに int p; int x = arr[(r + l) / 2], y = arr[l], z = arr[r]; p = x p) rp--; if (lp >= rp) break; swap(&(arr[lp]), &(arr[rp])); lp++; rp--; } recursion(arr, l, lp - 1); recursion(arr, rp + 1, r); } void quick_sort(int *arr, int len) { recursion(arr, 0, len - 1); } マージソート（merge sort） 対象領域を分割し、それぞれをソートした後1つにまとめる（マージする）アルゴリズム。 マージは小領域の先頭の要素同士を比較し最も小さいもの（大きいもの）を選ぶ作業となる。 対象データ容量の倍の記憶領域が必要なかわり、シーケンシャルアクセスによって実装できるため、外部整列に適している。 実用的には、主記憶領域が許す容量まで分割しクイックソートなどでソートした後、外部記憶領域を利用しながらマージを行う。 最悪時間計算量のオーダーはクイックソートに勝るが、分割が多く1段階あたりの計算量が多いため、通常クイックソートのほうが早い。 ただし、各小領域のソートは互いに依存性がないため並列演算が可能であり、マルチコアの計算機では高速に実行できる。 最悪時間計算量：O(nlogn) 最良時間計算量：O(nlogn) 平均時間計算量：O(nlogn) 最悪空間計算量：O(n) void merge(int *arr1, int len1, int *arr2, int len2, int *res) { int i1 = 0, i2 = 0; for (int i = 0; i arr2[i2] ? arr2[i2++] : arr1[i1++]; } } int main(void) { int data[] = {8, 1, 5, 0, 2, 3, 6, 9, 7, 4}; int res[10]; // 前後に分割し、それぞれをクイックソートしたあとでマージ quick_sort(data, 5); quick_sort(data + 5, 5); merge(data, 5, data + 5, 5, res); for (int i = 0; i "},"computer_science/algorithm/sort3.html":{"url":"computer_science/algorithm/sort3.html","title":"ソートアルゴリズム3","keywords":"","body":"ソートアルゴリズム3 探索木を利用したソートアルゴリズム ヒープソート 「最も小さい要素を取り出す」という作業を探索木によって実現したアルゴリズム。 安定でないアルゴリズム。 木が平衡であれば探索の平均時間計算量・最悪時間計算量はともに O(logn) となるため、ヒープソートは常に O(nlogn) で実行できる。 これは最悪時間計算量が O(n2) であるクイックソートと比べると大きな利点である。 時間計算量：O(nlogn) 空間計算量：O(1) 通常、探索木にはプライオリティーキューを用いる。 プライオリティーキューに用いられる半順序木は対象の配列の上で実装できるため、追加のデータ領域は必要としない。 値を直接比較しないソートアルゴリズム ビンソート / バケットソート / バケツソート（bin sort / bucket sort） 取りうる値の範囲がわかっているとき、各値の箱（ビン/バケット/バケツ）を用意し、そこへ各要素を収納していくアルゴリズム。 基本となる手順は以下の通り。 取りうる値それぞれについてビンを用意する 対象データの先頭から順に値を検証し対応するビンに要素を格納する ビンに複数の要素を保持できるようにする、ビンを値の範囲ごとに用意してビンに割り振ってから中の要素をクイックソートで並べ替える、など実装にバリエーションがある。 いずれの実装でもアルゴリズムに固定値を埋め込むことになるため、対象データの特性（モデル）が判明しているケースでしか利用できない。 時間計算量（目安）：O(m+n) 空間計算量（目安）：O(m⋅n) ※ m はビンの数 ※ 実装方法により異なる キーの重複が多いようなら次の分布数え上げソートの方が性能が良くなる。 分布数え上げソート（distribution counting sort） 要素の値をキーと見なしてキーの出現回数を数え、その累計を参照することで、あるキーを持つ要素が何番目に来ればいいか検証するアルゴリズム。 基本となる手順は以下の通り。 対象データについて各キーの出現回数を数える 対象データの先頭から順に何番目に並べればよいか検証し、結果のデータ領域に格納する 例えばキー k を持つ要素が l 回目に現れたとき、「キー 1∼(k−1) を持つ要素の累計」 + l 番目に格納すれば良いことがわかる 実装の方針はビンソートとほぼ同じであり、各ビンで出現回数を管理する点が異なる。 キーの重複が少ないようならビンソートの方が性能が良くなる。 ビンソート同様に対象データの特性（モデル）が判明しているケースでしか利用できない。 平均時間計算量：O(m+n) 空間計算量：O(m⋅n) ※ m は現れるキーの数 ※ 実装方法により異なる 基数ソート（radix sort） 数字や文字列など、位によって上位下位の関係が定義できるデータに対して、各位について順に安定なソートを実行することで並び替えるアルゴリズム。 上位桁からソートしていく手法をMSD基数整列法（MSD radix sort）、下位桁からソートしていく手法をLSD基数整列法（LSD radix sort）と呼ぶ。 10進数表記（基数：10）を例に取ると、1の位、10の位、100の位...をキーとしたソートを順に行うことで並び替えを行う。 計算機の場合、整数値の内部表現は2進数のため2進数の基数ソートを利用するのが一般的であり、ビット演算を利用することで高速な実装ができる。 ただし符号ありの場合は最上位ビットが符号を示しているため工夫が必要となる。 またMSD基数整列法の場合は、クイックソートと同様に左右からポインタを進め要素を交換する手法を取ることで、もとの配列上でソートが可能になる（追加の記憶領域を必要としない）。 ただし、安定でないソートになる。 時間計算量：O(kn) 空間計算量：LSD - O(kn) ／ MSD - O(1) ※ k はデータの桁数 ※ 実装方法により異なる "},"computer_science/algorithm/greedy.html":{"url":"computer_science/algorithm/greedy.html","title":"貪欲法","keywords":"","body":"貪欲法（Greedy algorithm） 問題を部分問題に分割したうえで、その場の評価値が最大になる選択肢を選びながら部分問題を解いていく手法。 欲張り法、グリーディ算法とも。 特徴としては 手続きの中で現在解いている問題しか保持しない・一度選択した要素を再考しない つまり問題の「保留」はしない 部分問題の評価値の計算方法・ソートのアルゴリズムだけで実装できる 多項式時間で解ける 得られる解が最適解である保証はない 厳密解が求まる問題の例 n個の仕事がある。 各仕事は時刻{% math %}s_i{% endmath %}に始まり{% math %}t_i{% endmath %}に終わる。 また、開始時刻と終了時刻が一致する仕事を兼任することはできない。 できるだけ多くの仕事に参加するにはどうすればよいか。 この問題は、開始時刻からスタートし「終了時刻が最も早い仕事を選んでその時刻に立つ」を繰り返せば最適解が得られる。 実装例（C++） g++ (Ubuntu 4.8.4-2ubuntu1~14.04.3) 4.8.4 #include #include using namespace std; int main (void) { const int N = 10; int work_period[N][2] = { { 1, 2 }, { 1, 3 }, { 2, 5 }, { 3, 7 }, { 4, 5 }, { 5, 6 }, { 8, 9 }, { 7, 9 }, { 6, 10 }, { 8, 10 } }; //---------- pair itv[N]; for (int i = 0; i "},"computer_science/algorithm/dynamic_programming1.html":{"url":"computer_science/algorithm/dynamic_programming1.html","title":"動的計画法１","keywords":"","body":"動的計画法１（Dynamic Programming） 問題を部分問題に分割したうえで、部分問題の計算結果を記録しながら解いていくアルゴリズム。 特徴としては 分割統治法を利用する 部分問題を再帰的に解くことで問題全体を解く メモ化 前のステップで計算した評価値を利用して次のステップの評価値を計算する 解ける問題の例１ 有名な問題として01ナップサック問題がある。 重さw_i、価値v_iの品物がn個ある。 ここから重さの総和がWを超えないように持っていく品物を選ぶ。 持っていける品物の総価値の最大値はいくらか？ この問題を全探索で解くと O(2n) の処理になる。 全探索の場合xxxx010の重さと価値の総和を計算するという処理が難度も実行されており、計算量がかさむ要因になっている。 そこでこの計算をメモ化してみる。 使う品物・重さの制限を絞り部分問題とする方法 i番目までの品物から重さの総和がj以下になるよう選択したときの価値の最大値をテーブルに記憶するとする。 このとき、各要素をdp[i,j]とすると dp[0,j]=0dp[i+1,j]={dp[i,j](jwi)max(dp[i,j],dp[i,j−wi]+vi)else の漸化式が立てられる。 この方法では計算量はO(nW)となり、Wが極端に大きくならない限りは十分効率的なアルゴリズムといえる。 実装例 どの組み合わせが利用されたかの列挙も表示する例。 最大値だけが欲しい場合は後半のラムダ式以降を削ればよい。 #include #include #include using namespace std; int main (void) { const int N = 4; const int W = 5; int products[N][2] = { { 2, 3 }, { 1, 2 }, { 3, 4 }, { 2, 2 } }; //---------- int dp[N + 1][W + 1]; for (int i = 0; i )> f = [&](int i, int j, vector v){ if (i == 0){ for (auto num : v) cout = 0 && dp[i][j] == dp[i - 1][pj] + products[i - 1][1]) { v.push_back(i); f(i - 1, pj, v); v.pop_back(); } return; }; vector a; f(N, W, a); return 0; } 使う品物・価値の制限を絞り部分問題とする方法 実装例 "},"computer_science/algorithm/dynamic_programming2.html":{"url":"computer_science/algorithm/dynamic_programming2.html","title":"動的計画法２","keywords":"","body":"動的計画法２（Dynamic Programming） 解ける問題の例２ "},"computer_science/algorithm/hashing.html":{"url":"computer_science/algorithm/hashing.html","title":"ハッシュ法","keywords":"","body":"ハッシュ法（hashing） ハッシュ関数を用いた探索アルゴリズム。 探索対象に適切なハッシュ関数を適用して得たハッシュ値を配列のインデックスとすることで対象へランダムアクセスを行う。 ハッシュ値をインデックスではなくキーとして扱うケースもあるが、探索自体には別のアルゴリズムを用いる必要がありメリットが薄れる。 平均時間計算量（目安）：O(1) 平均空間計算量（目安）：O(m) ※ m はハッシュ値が取りうる値の総数 ※ 実装方法により異なる 衝突への対策 ハッシュ法では、扱うデータとハッシュ値がなるべく1対1に結びつくようなハッシュ関数を選択するが、必ずしもそのようなハッシュ関数が得られるとは限らない。 そこで、衝突が生じた際の対処法として次のような手法が考案されている。 チェイン法 同じハッシュ値を持つ値を連結リストで保持する。 つまり、ハッシュ値が指すアドレスに連結リストの先頭アドレスを格納しておき、ハッシュ法でリストを特定した後そのリストの中を探索する。 オープンアドレス法 衝突が生じたとき、再ハッシュと呼ばれるアルゴリズムを適用し別のハッシュ値を得る。 適切な再ハッシュのアルゴリズムを用意する必要があるほか、要素を削除した後で探索することを考慮して「空」「データあり」に加えて「削除済み」ステータスを用意し、削除済みに行き着いたときは再ハッシュ先も探索するように実装する必要がある。 "},"computer_science/algorithm/heap.html":{"url":"computer_science/algorithm/heap.html","title":"ヒープ・プライオリティキュー","keywords":"","body":"ヒープ・プライオリティキュー ヒープ は「親ノードの値 ≥（もしくは≤）子ノードの値」を満たす、半順序関係を実現した木構造を指す。 二分木で実装されたヒープを特に二分ヒープと呼ぶ。 プライオリティキュー は蓄えた値のうち最大（最小）のものをpopするデータ構造を指す。 プライオリティキューはヒープによって実装可能である。 ヒープの探索の時間計算量は木の深さに比例する 平均時間計算量はO(logn) 二分ヒープの原理 半順序木はインデックスの割り振り方を工夫することで1つの配列の上に木構造を展開できる。 計算の都合からインデックスを1始まりとする。 木構造の各ノードに下の図のようにインデックスを割り振ることにする（要素13個が格納されているヒープの例）。 graph TD 1 --- 2 1 --- 3 2 --- 4 2 --- 5 3 --- 6 3 --- 7 4 --- 8 4 --- 9 5 --- 10 5 --- 11 6 --- 12 6 --- 13 すると、あるノード i の子ノードは 2i, 2i+1、親ノードは floor(i/2) となるため、ノードを辿る作業が簡単に行える。 最小値の取り出し ヒープのpopは次のように実装できる。 根のノードの値を取り出す（これが最小値） 代わりに一番インデックスが大きいノードの値 p を根に格納する p より小さな値を持つ子ノードがあれば、最も小さい値を持つノードと値を交換する 3を繰り返す 値の挿入 ヒープのpushは次のように実装できる。 配列の最後尾に新しい値 p を挿入する 親ノードの値が p より大きければ値を交換する 3を繰り返す 実装 C++の場合は標準ライブラリのqueueにpriority_queueが用意されている。 プライオリティキューを用いて解ける問題の例 ガソリンは距離1に対して1消費する、ガソリンタンク容量が無制限のトラックにガソリンがPだけ積まれている。 このトラックで距離Lの道を移動する。 道の途中には距離A_iの地点にB_iのガソリンを持ったガソリンスタンドがある。 トラックは移動を燃料切れせず移動を完了できるか？また最小で何回の給油が必要か？ この問題は次の手順で解くことができる。 次のガソリンスタンドに移動できるか判定する。 移動できた場合、そこで給油できるガソリン量をプライオリティキューにpushする。 移動できない場合、プライオリティキューからこれまで通過したガソリンスタンドのうちガソリン量の最も多いものをpopし、そこで給油していたことにする。 上記の手順を繰り返す。 実装例 #include #include using namespace std; int main(void) { int n = 4, l = 25, p = 10; //簡単にするためゴールもガソリンスタンドのリストに追加する int stations[][2] = {{10, 10}, {14, 5}, {20, 2}, {21, 4}, {25, 0}}; //-------------------- priority_queue pq; int curpos = 0, ans = 0, tank = p; for (int i = 0; i "},"computer_science/algorithm/binary_search_tree.html":{"url":"computer_science/algorithm/binary_search_tree.html","title":"二分探索木","keywords":"","body":"二分探索木 「左の子ノードの値 ≦ 親ノードの値 ≦ 右の子ノードの値」となるような二分木。 探索の計算量は木の深さに比例 平均計算量はO(logn) 実装 C++では標準でsetクラスが定義されている。 "},"computer_science/algorithm/string_searching.html":{"url":"computer_science/algorithm/string_searching.html","title":"文字列探索","keywords":"","body":"文字列探索（string searching） ある文字列に特定の文字列が含まれているかの探索を行うアルゴリズムについて言及する。 ナイーブな探索（brute-force algorithm） 最も単純なアルゴリズムは以下の手順で実現できる。 検索対象の先頭と検索ワードの先頭を重ねて比較する 重ねる位置を1つずらして比較する 2を繰り返す 検索対象の末尾と検索ワードの末尾が重なったらその回で終了 探索の計算量は検索対象の長さ（n）と検索ワードの長さ（m）に比例 平均計算量はO(mn) KMP法（Knuth Morris Pratt algorithm） brute-force algorithmを改良し、何文字目で不一致になったかをもとに次の照合開始位置を決めるようにしたアルゴリズム。 KMP法では探索の前に検索ワードから、「その文字位置で不一致になったとき次の照合位置を何文字分ずらすか」という情報を格納したテーブルを生成する（細かい部分は実装により異なる）。 テーブルの作成 時間計算量：O(m2) 探索 時間計算量：O(n) ただし1回あたりの処理が重くなる上、一般的な文字列では部分的にでも一致することは稀なため、実用上はナイーブなアルゴリズムとほとんど差がない。 テーブルの作成 テーブルTは検索ワード同士（A,Bとする）の比較により作成する。 比較の際に1+T[i]ずらすようにテーブルの値を決めることにする。 以下に手順を示す。 1文字目で失敗したら1文字ずらすことにするT[0]=0 検索ワードA,Bを k 文字ずらして重ね合わせる 先頭が一致しなければT[k]=0 一致するところまでT[k]=1, T[k+1]=2, ...とする 例：検索ワードがABABCAのとき 1文字目 T[0]=0 2文字目 ABABCA .ABABCA 1文字も一致しないのでT[1]=0 3文字目 ABABCA ..ABABCA 2文字目・3文字目が一致するのでT[2]=1, T[3]=2 5文字目 ABABCA ....ABABCA 1文字も一致しないのでT[4]=0 6文字目 ABABCA .....ABABCA 1文字目が一致するのでT[5]=1 よってT=[001201]となる。 比較 検索対象の先頭と検索ワードの先頭を重ねて比較する 重ねる位置を1つずらして比較する 不一致の場合、不一致になった位置とテーブルを照らし合わせて次の照合位置を求める 2を繰り返す 検索対象の末尾と検索ワードの末尾が重なったらその回で終了 例：検索ワードがABABCAのとき 例えばABCDEFGAB…からABABCAを検索するとき、1回目の比較で2文字目まで一致し3文字目が不一致になる。 T[2]=1なので、2文字分ずらしてBCDEFGとの比較はスキップしてCDEFGAとの比較に進む。 BM法（Boyer-Moore algorithm） KMP法を改良し、照合の際に不一致になった文字に応じて次の照合位置を決めるアルゴリズム。 照合の際に検索ワードに含まれない文字が末尾に出現すれば m−1 回の照合をスキップできるため実用的にも性能がよい。 最悪時間計算量：O(n) 平均時間計算量：O(n/m) ※実装方法により異なる テーブル作成 ASCII文字が対象の場合は、各文字について「最後尾で不一致の場合何文字ずらすか」のテーブルTを作成する。 検索ワードに含まれる文字は「末尾から何文字目」であるかの値を求め、最も小さいものをT[ch]に格納する。 検索ワードに含まれない文字は検索ワードの長さ m をT[ch]に格納する。 マルチバイトの場合、文字の分だけメモリを確保するわけにいかないため工夫が必要になる。 例：検索ワードがABABCAのとき ABCDEFG…a…z 0216666…6…6 比較 検索対象の先頭と検索ワードの先頭を重ねて末尾の文字から順に比較する 不一致の場合、「不一致になった文字とテーブルを照らし合わせて得た値」ー「不一致になった位置の末尾からの距離」を次の照合位置とする（負になった場合は1文字だけずらす） 1を繰り返す 検索対象の末尾と検索ワードの末尾が重なったらその回で終了 例：検索ワードがABABCAのとき 例えばABCDEFGHIABABCATRS…からABABCAを検索するとき、 1回目 ABCDEFとABABCAを比較する。末尾が不一致で、不一致文字Fのテーブル上の値はT['F']=6なので6文字ずらす。 2回目 GHIABAとABABCAを比較する。末尾から1文字目が不一致で、不一致文字Bのテーブル上の値はT['B']=2なので3文字ずらす ABABCAとABABCAを比較する。一致したので一致判定を下す。複数探索なら1文字ずらして次の判定に進む。 "},"computer_science/algorithm/union_find_tree.html":{"url":"computer_science/algorithm/union_find_tree.html","title":"Union-Find木","keywords":"","body":"Union-Find木 素集合を管理するためのデータ構造。 内部に複数の木構造を持ち、1つの木が1つの集合に相当する。 実装例 集合に根を1つ定義する。 初期状態は全ての値が独立した状態とする。 ある値同士が同じ集合に属しているかは次のように判定する。 葉から順に値を探索する 発見したノードの親を辿り、木の根を見つける このとき辿ったノードを根に直接繋げ、次の探索を高速化する（木の縮退） 辿り着いた根が同じであれば2つの値は同じ集合に属する 2つの集合は次のように併合する。 各集合の根を見つける 片方の根をもう片方の根の子ノードにする サイズは併合の際に計算し保持する。 集合のサイズを求めるには全ノードの走査が必要となってしまうため 簡単のため集合の分割はできないものとする。 #include #include #include using namespace std; // Union-Find-Tree struct UnionFind { vector par; //そのノードの親ノード //（根ノードは自分を参照） vector sizes; //そのノードを根とする木のサイズ //（根でないノードについては無意味） int N; UnionFind(int n) : par(n), sizes(n, 1) { for (int i = 0; i f = [&](int x) { cout "},"computer_science/algorithm/bipartite_graph.html":{"url":"computer_science/algorithm/bipartite_graph.html","title":"2部グラフ判定","keywords":"","body":"2部グラフ判定 与えられたグラフが2部グラフであるかの判定について言及する。 解ける問題の例 頂点数nの多重編・ループのない無向グラフがある。 隣接している頂点同士が違う色になるように頂点に色を塗る。 2色以内ですべての頂点を塗ることができるか判定せよ。 2部グラフが応用できる問題、というより2部グラフの定義そのもの。 色をつけたノードに繋がるノードを見つけて別の色を塗る、という操作を再帰的に行えば良い（深さ優先探索）。ただし、連結グラフでない可能性があるため、main()の中でdfs()を各頂点に対して呼び出す必要がある。 実装例 #include #include #define MAX 4 using namespace std; int g[MAX][MAX] = {{0, 1, 0, 1}, {1, 0, 1, 1}, {0, 1, 0, 0}, {1, 1, 0, 0}}; int color[MAX]; bool dfs(int v, int c) { color[v] = c; for (int i = 0; i "},"computer_science/algorithm/state_space.html":{"url":"computer_science/algorithm/state_space.html","title":"状態空間表現","keywords":"","body":"状態空間表現 状態空間とは 機械学習・人工知能の分野における状態空間とは、問題の対象となる事象を状態とオペレーターの集合として記述したものを指す。 つまり取りうる状態をノード、それらの間をどのように遷移できるか・遷移にかかるコストを枝として表現したグラフのことである。 ボードゲームなどの複雑な問題も状態空間表現を利用することで、初期状態から目標状態までの最短経路問題に帰着される。 例 チェスなどのボードゲームは盤面を状態、差し手をオペレーターとした状態空間として表現できる。 この例では最初の盤面を初期状態、チェックメイトした盤面を目標状態とすることになる。 "},"computer_science/algorithm/exhaustive_search.html":{"url":"computer_science/algorithm/exhaustive_search.html","title":"ナイーブな探索","keywords":"","body":"ナイーブな探索 深さ優先探索（DFS : Depth-First Search） 縦型探索とも。 開始ノードから子ノードを辿っていく 子ノードが途切れれば親ノードに戻って別の子ノードを辿る 求めるノードに辿りついたら終了 という手順で解を探索する。 明示的に検証待ちのノードを記録するリストを作成する場合、これをOPENリストと呼ぶことがある。 探索対象がグラフの場合はループが存在する可能性があるため、検証済みのノードを記録するCLOSEDリストを導入し、辿った先のノードが検証済みであるかを確認しながら探索する。 特徴 再帰関数で簡単に記述できることが多い メモリの消費量が少ない 深さ無限の場合、解に辿りつける保証がない コストを考慮した探索対象の絞り込み・優先順位付けなどは行わない 単にすべての状態を列挙したいときは実装が楽なのでDFSを使うことが多い。 実装 再帰関数もしくは、LIFO（Last-In First-Out）のデータ構造つまりスタックをOPENリストとして実装する。 ※再帰関数は本質的にはスタックを利用した深さ優先探索の実装の一種と言える 幅優先探索（BFS : Breadth-First Search） 横型探索とも。 開始ノードを1層目、その子ノードを2層目、さらにその子ノードを3層目...とする 1層目の全てのノード、2層目の全てのノード...を順に検証していく 求めるノードに辿りついたら終了 という手順で解を探索する。 探索対象がグラフの場合は深さ優先探索同様にOPENリスト・CLOSEDリストを導入し、辿った先のノードが検証済みであるかを確認しながら探索する。 特徴 再帰関数で記述できないため実装がやや複雑 メモリの消費量が多い 深さ無限でも解に辿りつける コストを考慮した探索対象の絞り込み・優先順位付けなどは行わない 実装 FILO（First-In Last-Out）のデータ構造つまりキューをOPENリストとして実装する。 cpp "},"computer_science/algorithm/heuristic_search.html":{"url":"computer_science/algorithm/heuristic_search.html","title":"ヒューリスティック探索","keywords":"","body":"ヒューリスティック探索（heuristic search） 何らかの評価関数を基に探索するアルゴリズムをヒューリスティック探索・知識に基づく探索などと呼ぶ。 最良優先探索（best-first search） 評価関数が最小になる方向へ移動しながら探索するアルゴリズムを最良優先探索という。 また、これを用いた探索を山登り法という。 グラフにおける最良優先探索 グラフの単一始点経路探索問題の場合、ノードが格子状に配置されているならマンハッタン距離を目標ノードまでの推定距離とする方法がある。 ただし最短経路が求まる保証はない。 目標ノードが分かっていない状態で最短距離にある目標ノードを求める問題については、「初期ノードからそのノードまでの総コスト」が小さい順に検証していく均一コスト探索などがある。 これらはOPENリストにプライオリティーキューを用いることで実装できる。 領域における最良優先探索 非線形無制約最小化問題の数値解を求める問題では、傾きが急な方向へ微小距離ずつ移動する手法などが最良優先探索に当たる（ただし、このアルゴリズムでは大域的最適解が得られる保証がない）。 A∗アルゴリズム グラフの単一始点最短経路問題におけるアルゴリズムの一種。 グラフにおける最良優先法を改良したものに当たる。 最良優先探索では、「目標ノードまでの推定距離」だけを評価していたのに対し、A∗アルゴリズムでは「目標ノードまでの推定距離＋初期ノードからそのノードまでの距離」を評価する。 この評価関数をヒューリスティック関数と呼ぶ。 "},"computer_science/algorithm/game_tree.html":{"url":"computer_science/algorithm/game_tree.html","title":"ゲーム木の探索","keywords":"","body":"ゲーム木の探索 ゲーム木とは 組み合わせゲーム理論（チェスや囲碁のような展開型（逐次手番の）確定完全情報ゲームを題材とした理論）で扱う問題を状態空間表現で示したものをゲーム木という。 特に起こりうるすべての盤面を含むものを完全ゲーム木、そうでないものを部分ゲーム木と呼ぶ。 ミニマックス法 ゲーム理論における戦略の1つ。 ミニマックスとは、想定される最大の損害を最小化するように手を選択する、という意味。 ゲーム木を対象としたミニマックス法では以下のような手順で探索を行う。 あらかじめ決められた深さにあるすべてのノードの評価値（自分がどの程度有利な状況か）を計算する 末端から順に、以下の法則に従って１つ上の層のノードの評価値を再帰的に決めていく n−1 層目のあるノードが「自分が打つ前の状態」なら、繋がっている n 層目のノードの評価値の最大値をそのノードの評価値とする（このときの n−1 層目のノードをMAX節点という） n−1 層目のあるノードが「相手が打つ前の状態」なら、繋がっている n 層目のノードの評価値の最小値をそのノードの評価値とする（このときの n−1 層目のノードをMIN節点という） 根（現在の状態）の1つ下の層のノード（次の手を打った状態）のうち評価値が最も高いものを選択する つまり自他共に最善手を打つことを想定してゲームの展開を読む手法である。 末端のノードの評価値が適当で、プレイヤーが互いに最善手を打つならば、このアルゴリズムで求めたものが最善手となる。 しかし探索を深くするほどノードの数が指数関数的に増えるため、選択肢の多いゲームでは読める深さに限界がある。 アルファ・ベータ法（alpha-beta pruning） ミニマックス法の評価を枝刈りによって高速化した手法。 α カット 下の図は左下のノードから順に評価値を決めていく途中の図である。 いま A の評価値を求めるために孫ノードの1つ（青色）の評価値を得たところであるとする。 graph TD subgraph MAX A end subgraph MIN B1[2] B2[B] end A --> B1 A --> B2 subgraph MAX C1[4] C2[2] C3[1] C4[C] C5[D] end B1 --> C1 B1 --> C2 B2 --> C3 B2 --> C4 B2 --> C5 style B1 fill:#f88,stroke:#f55 style C3 fill:#99f,stroke:#55f ミニマックス法に従えば C,D,B,A を順に評価するところだが、B はMIN節点であるため B の評価値は 1 以下になることがこの時点でわかる。 また 1\">2>1 であるため、A の評価値が 2 であることが確定する。 このようにMAX-MIN-MAXの並びの中で、最下層の一部の評価を省略することをα カットという。 β カット α カット同様に次のような図について考える。 graph TD subgraph MIN A end subgraph MAX B1[6] B2[B] end A --> B1 A --> B2 subgraph MIN C1[6] C2[2] C3[7] C4[C] C5[D] end B1 --> C1 B1 --> C2 B2 --> C3 B2 --> C4 B2 --> C5 style B1 fill:#f88,stroke:#f55 style C3 fill:#99f,stroke:#55f ここでも B の評価値が 7 以上になることがわかる。 また 67 であるため A の評価値が 6 であることが確定する。 このようにMIN-MAX-MINの並びの中で、最下層の一部の評価を省略することをβ カットという。 AND/OR木によるミニマックス法 二人で対戦する打ち手の選択肢が有限である組み合わせゲーム（二人零和有限確定完全情報ゲーム）の完全ゲーム木のミニマックス法はAND/OR木の探索問題に帰着する。 すなわち、勝利をTrue、敗北をFalseとし、自分の手番をOR節点、相手の手番をAND節点としたAND/OR木で最善手を決定できる。 "},"computer_science/algorithm/minimum_spanning_tree_problem.html":{"url":"computer_science/algorithm/minimum_spanning_tree_problem.html","title":"最小木問題","keywords":"","body":"最小木問題（mininmum spanning tree） 無向グラフの中で枝のコストの和が最小になる全域木を見つける問題を最小木問題という。 詳細はグラフ理論>最小木問題へ。 以下に最小木問題を解くためのアルゴリズムを示す。 頂点数 |V|=n、辺の数 |E|=m とする。 解ける問題の例 都市の間を結ぶ道路を建設したい。 しかし建設費に限りがあるため、とりあえずはすべての都市を結べるような建設費が最小の道を建設したい。 建設可能な道とそのコストは以下の通りである。 graph LR; A((A))---|10|B((B)) A((A))---|5|C((C)) B---|2|D((D)) C---|7|D D---|1|G((G)) D---|3|F C---|1|F C---|8|E((E)) E---|5|F((F)) Prim法 Prim法はある頂点を始点に木から一番近い頂点を吸収する形で木を成長させていく手法。 任意の1頂点 r を指定し、U:={r}, F:=∅ とする U=V なら終了する、そうでなければ続行する min{w(e) | e=(u,v)∈E, u∈U, v∈V∖U} となる辺 e′=(u′,v′) を選択し、F:=F∪{e′}, U:=U∪{v′} とする 2~3を繰り返す 時間計算量は O(n2) だが、各頂点の情報をフィボナッチヒープに格納すれば O(m+nlogn) となる。 use std::cmp::Ordering; use std::collections::BinaryHeap; #[derive(Clone, Eq, PartialEq)] struct Edge { v1: usize, v2: usize, cost: isize, } impl Ord for Edge { fn cmp(&self, other: &Edge) -> Ordering { other.cost.cmp(&self.cost) } } impl PartialOrd for Edge { fn partial_cmp(&self, other: &Edge) -> Option { Some(self.cmp(other)) } } struct Graph { vert_count: usize, edges: Vec, } fn prim(graph: &Graph) -> Result, &str> { let mut edge_table: Vec> = vec![vec![-1; graph.vert_count]; graph.vert_count]; for e in graph.edges.iter() { edge_table[e.v1][e.v2] = e.cost; edge_table[e.v2][e.v1] = e.cost; } let mut used_verts: Vec = (0..graph.vert_count).map(|_| false).collect(); used_verts[0] = true; let mut used_edges: Vec = Vec::new(); let mut min_heap = BinaryHeap::::new(); for (i, c) in edge_table[0].iter().enumerate() { if c != &-1 { min_heap.push(Edge { v1: 0, v2: i, cost: c.clone() }); } } let mut used_verts_count = 1; while used_verts_count { if used_verts[v1] && used_verts[v2] { continue; } else { let i = if used_verts[v1] { v2 } else { v1 }; used_verts[i] = true; used_verts_count += 1; used_edges.push(Edge { v1, v2, cost }); for (j, c) in edge_table[i].iter().enumerate() { if c != &-1 { min_heap.push(Edge { v1: i, v2: j, cost: c.clone() }); } } } } None => { return Err(\"this is a disconnected graph\"); } } } Ok(used_edges) } fn main() { let mut edges = Vec::new(); edges.push(Edge { v1: 0, v2: 1, cost: 10 }); edges.push(Edge { v1: 0, v2: 2, cost: 5 }); edges.push(Edge { v1: 1, v2: 3, cost: 2 }); edges.push(Edge { v1: 2, v2: 3, cost: 7 }); edges.push(Edge { v1: 2, v2: 4, cost: 8 }); edges.push(Edge { v1: 2, v2: 5, cost: 1 }); edges.push(Edge { v1: 4, v2: 5, cost: 5 }); edges.push(Edge { v1: 3, v2: 5, cost: 3 }); edges.push(Edge { v1: 3, v2: 6, cost: 1 }); let graph = Graph { vert_count: 7, edges }; let res = prim(&graph); match res { Ok(edges) => { for e in edges.iter() { println!(\"{} - {} \\tcost:{}\", e.v1, e.v2, e.cost); } } Err(m) => println!(\"{}\", m), } } 0 - 2 cost:5 2 - 5 cost:1 5 - 3 cost:3 3 - 6 cost:1 3 - 1 cost:2 5 - 4 cost:5 Kruskal法 Kruskal法は重みの小さい辺を順に走査し、森を成長させていく手法。 F:=∅, i:=1 とし、辺を重みの小さい順にソートする（e1,e2,⋯） |F|=n−1 なら終了する、そうでなければ続行する F∪{ai} が閉路を含まないなら F:=F∪{ai} とする i:=i+1 とする 2~4を繰り返す ソートの時間計算量は O(mlogm) であり、メインループは O(nm) になる。 "},"computer_science/algorithm/shortest_path.html":{"url":"computer_science/algorithm/shortest_path.html","title":"単一始点最短経路問題","keywords":"","body":"単一始点最短経路問題 問題の特徴 始点から各頂点への最短距離を求める 「\"最短距離が確定している頂点\"に隣接する頂点の最短距離を再計算する」を繰り返せば全ての点への最短距離が求まる。 負の閉路がある場合は最短距離が定まらないため解けない ベルマンフォード（Bellman-Ford）法 重み付きグラフの単一始点最短経路問題を解くための手法。 次のような特徴がある。 負の重み付けがあっても対応できる 負の閉路の検出が可能 隣接行列を用いたときの計算量は O(|V|3) 隣接リストを用いたときの計算量は O(|V|⋅|E|) 手法 頂点 i までのその時点での最短距離を d[i] に格納するものとする。 以下の式を全ての頂点に対して繰り返し実行し、すべての d[i] が更新されなくなったら計算が完了したものとする。ただし d[s]=0（始点）, d[i]=INF を初期値として利用する。 d[i]=min{d[j]+cji | e=(i,j)∈E} 全ての頂点に対して繰り返し実行するのは、グラフが負の重み付けを持つ場合、最短距離が確定しているかの判断ができないため。 負の閉路の判定 負の閉路がない限り、d[i] の更新は高々 |V|−1 回しか行われないため、検証のアルゴリズムは最大でも (|V|−1)⋅|E| 回しか実行されない。 そのため、この回数を超えてループが実行されていればグラフに負の回路が存在することがわかる。 問題例 グラフ1 graph LR; A((A:始点))-->|2|B((B)); B-->|4|C((C)); A-->|5|C; B-->|10|E((E)); B-->|6|D((D)); C-->|2|D; E-->|3|F((F)); D-->|-1|F; E-->|5|G((G)); F-->|9|G; グラフ2 graph LR; A((A:始点))-->|2|B((B)) A-->|3|C((C)) C-->|-1|B B-->|-3|D((D)) D-->|2|C 実装例 無向グラフを検証する場合は逆向きの辺を追加することで対応できる。 struct Edge { from: usize, to: usize, cost: isize, } struct Vert { dist: isize, updated: bool, } struct Graph { vert_count: usize, start_vert: usize, edges: Vec, } fn bellman_ford(graph: &Graph) -> Result, &str> { let mut verts: Vec = Vec::new(); for _ in 0..graph.vert_count { verts.push(Vert { dist: 0, updated: false }); } verts[graph.start_vert].updated = true; for _ in 0..(graph.vert_count - 1) { let mut updated = false; for e in graph.edges.iter() { if verts[e.from].updated && (!verts[e.to].updated || verts[e.from].dist + e.cost = Vec::new(); edges.push(Edge { from: 0, to: 1, cost: 2 }); edges.push(Edge { from: 1, to: 2, cost: 4 }); edges.push(Edge { from: 0, to: 2, cost: 5 }); edges.push(Edge { from: 1, to: 4, cost: 10 }); edges.push(Edge { from: 1, to: 3, cost: 6 }); edges.push(Edge { from: 2, to: 3, cost: 2 }); edges.push(Edge { from: 4, to: 5, cost: 3 }); edges.push(Edge { from: 3, to: 5, cost: -1 }); edges.push(Edge { from: 4, to: 6, cost: 5 }); edges.push(Edge { from: 5, to: 6, cost: 9 }); let graph = Graph { vert_count: 7, start_vert: 0, edges }; let res = bellman_ford(&graph); match res { Ok(v) => { for d in v.iter() { println!(\"{}\", d); } } Err(s) => println!(\"{}\", s), } } グラフ1 0 2 5 7 12 6 15 グラフ2 graph has negative circuit ダイクストラ（Dijkstra）法 非負の重み付きグラフの単一始点最短経路問題を解くための手法。 次のような特徴がある。 隣接行列を用いたときの計算量は O(|V|2) プライオリティーキューを用いたときの計算量は O(|E|log|V|) 手法 重み付けが非負である場合、「未検証の頂点のうち最も d[i] が小さいものから順に隣接する頂点の最短距離を再計算する」を繰り返せば、最も d[i] が小さい頂点は最短距離が確定していることが帰納的に保証されるため、全ての頂点について最短距離が求まる。 "},"computer_science/algorithm/steepest_descent_method.html":{"url":"computer_science/algorithm/steepest_descent_method.html","title":"最急降下法","keywords":"","body":"最急降下法（steepest descent method） 傾きが最も急な方向を探索する手法。 あくまで探索方法を決定する手法であるため、実際の探索には直線探索などを用いる必要がある。 手順 探索開始点を決める（x0） 停止条件が満たされていれば終了する −∇f(xk) を探索方向とし xk+1 を探索する 例 Armijo条件の直線探索を用いた最急降下法を実装する。 Armijo条件 定数 ξ (0ξ1) と勾配ベクトル dk に対して f(xk+αdk)≤f(xk)+ξα∇f(xk)Tdk を満たす 0\">α>0 を選ぶ。αk+1=ταk の更新式を用いることが多い。 2変数の目的関数 f(x1,x2)=x41+x42+2x21+x22+x1x2 の極小値を求める。 Armijo条件の直線探索のパラメーターとして ξ=0.5,τ=0.8 を設定し、停止条件を (∇f(x1,x2))x+(∇f(x1,x2))y0.001 とする。 勾配ベクトルは ∇f(x1,x2)=[4x31+4x1+x24x32+2x2+x1] である。 use std::io; fn main() { let a: f64 = 5f64; let b: f64 = 5f64; println!(\"{:?}\", steepest_descent(a, b)); } fn cost_func(x1: &f64, x2: &f64) -> f64 { x1 * x1 * x1 * x1 + x2 * x2 * x2 * x2 + 2f64 * x1 * x1 + x2 * x2 + x1 * x2 } fn grad_func(x1: &f64, x2: &f64) -> (f64, f64) { ( -(4f64 * x1 * x1 * x1 + 4f64 * x1 + x2), -(4f64 * x2 * x2 * x2 + 2f64 * x2 + x1), ) } fn steepest_descent(x1: f64, x2: f64) -> (f64, f64) { let mut x1 = x1; let mut x2 = x2; loop { let mut alpha: f64 = 0.5; let d = grad_func(&x1, &x2); let fx = cost_func(&x1, &x2); let dk = -0.5 * (d.0 * d.0 + d.1 * d.1); println!(\"{}, {}\", x1, x2); while cost_func(&(x1 + alpha * d.0), &(x2 + alpha * d.1)) > fx + alpha * dk { alpha = alpha * 0.8; } x1 = x1 + alpha * d.0; x2 = x2 + alpha * d.1; if d.0.abs() + d.1.abs() "},"computer_science/algorithm/euclidean_algorithm.html":{"url":"computer_science/algorithm/euclidean_algorithm.html","title":"ユークリッドの互除法","keywords":"","body":"ユークリッドの互除法（Euclidean algorithm） ある2つの自然数 a,b の最小公倍数を求めるためのアルゴリズム。 すなわち ax+by=0 となる整数 x,y を求めることができる。 また後述するように ax+by=gcd(a,b) となる整数 x,y を求める拡張ユークリッドの互除法（extended Euclidean algorithm）も存在する。 原理 a,b  (b≠0) の商 q=floor(a/b) と剰余 r=a mod b を用いれば a=qb+r が成立する。 a=qb+r より gcd(b,r) は a を割り切れる。 また a−qb=r より gcd(a,b) は r を割り切れる。 よって、gcd(a,b) を求める問題は gcd(b,r) を求める問題と同値である。 また、r=0 なら a は b の倍数のため、b が最大公約数である。 よって r=0 を終了条件として再帰的に gcd(b,r) を求めることで gcd(a,b) が得られる。 手順 大きい方の値を小さい方の値で割ったときの剰余を取る 剰余が0なら小さい方の値が最小公倍数である 剰余が0でないなら小さい方の値と剰余に関して上の手順を繰り返す 図的に表現するとこのようになる（21と56の最小公倍数は7）。 2ステップで大きい方の値が半分以下になることが保証されるため、大まかな時間計算量は O(logmax(a,b)) になる。 実装例 x でも1回目の呼び出しで入れ替えが行われるので、呼び出し時に大小は気にしなくて良い。 fn gcd(a: usize, b: usize) -> usize { if b == 0 { a } else { gcd(b, a % b) } } fn main() { let x = 21; let y = 56; println!(\"gcd({}, {}) = {}\", x, y, gcd(x, y)); } 拡張ユークリッドの互除法（extended Euclidean algorithm） ax+by=gcd(a,b) となる絶対値が最小の整数の組 x,y を求めるアルゴリズム。 ax+by≠gcd(a,b) なら解が存在しない。 原理 通常のユークリッドの互除法を適用していき、k 回目の再帰で (ak,bk) が得られたとする。 すると、この組も akxk+bkyk=gcd(a,b) を満たさなければならない。 ここに bk−1=ak,  bk=ak−1−floor(ak−1/bk−1)⋅bk−1 を代入すると  bk−1xk+(ak−1−floor(ak−1/bk−1)⋅bk−1)yk=gcd(a,b) ak−1yk+bk−1(xk−floor(ak−1/bk−1)⋅yk)=gcd(a,b) となる。 よって、(ak,bk) に対応する (xk,yk) は {xk−1=xk−floor(ak−1/bk−1)⋅ykyk−1=xk の漸化式を満たす。 アルゴリズムの結果 (an,bn)=(an,0) で最小公倍数 gcd(a,b)=an が求まったとすれば an⋅1+bn⋅0=gcd(a,b) が絶対値の最も小さい (xn,yn) の組み合わせである。 上記の漸化式は絶対値が単調増加する数列になっているため (xn,yn) の絶対値が最小であれば (x0,y0) の絶対値は最小になる。 よって上記の漸化式を適用していけば絶対値が最小の組 (x,y) が求まる。 正負を調整したい場合は (lcm(a,b)/a,−lcm(a,b)/b) もしくは (−lcm(a,b)/a,lcm(a,b)/b) を (x,y) に加えればよい。 実装例 fn extgcd(a: isize, b: isize) -> (isize, isize, isize) { if b == 0 { return (a, 1, 4); } else { let (gcd, y, x) = extgcd(b, a % b); return (gcd, x, y - (a / b) * x); } } fn main() { let (gcd, x, y) = extgcd(56, 21); println!(\"56 * {} + 21 * {} = {}\", x, y, gcd); } "},"computer_science/algorithm/prime_factorization.html":{"url":"computer_science/algorithm/prime_factorization.html","title":"素数・素因数分解","keywords":"","body":"素数・素因数分解（prime / prime factorization） 素数判定 ナイーブな実装 ナイーブに実装すると O(√n) 。 数回だけ判定するような場合はこの方が速そう。 #include #include bool is_prime(long n) { if (n % 2 == 0) return false; for (int i = 3; i エラトステネスの篩 素数判定表を作りながら計算すると O(√n/logn) 。 下のコードはコンパイル時に最適化オプション付けないとstd::sqrt()で重くなるっぽいので注意。 #include #include #include //n以下の素数判定表 std::vector make_prime_checklist(long n) { std::vector list(n + 1, true); list[0] = list[1] = false; for (int i = 4; i make_prime_list(long n) { auto list = make_prime_checklist(n); std::vector ps; for (int i = 0; i 素因数分解 ナイーブな実装 ナイーブな実装として 2∼ の値で割れるか試していくと O(√n) 。 これでも十分速い。 #include #include #include std::vector> prime_factrize(long n) { std::vector> facts; long until = std::sqrt(n); for (long i = 2; n != 1 && i 1) facts.push_back(std::make_pair(n, 1)); return facts; } int main() { for (auto p : prime_factrize(11234)) std::cout 素数リストを利用 エラトステネスの篩を利用して素数リストを作ってから割れるか試していくと O(√n/logn) 程度らしい（素数定理から素数の出現率を近似）。 大量の数値の素因数分解を求めるときはこちらの方が速そう。 //make_prime_list()が必要 //素数リストから素因数分解 std::vector> prime_factrize(std::vector primes, long n) { std::vector> facts; long until = std::sqrt(n); for (auto p : primes) { if (n == 1 || p > until) break; long c = 0; while (n % p == 0) c++, n /= p; if (c) facts.push_back(std::make_pair(p, c)); } if (n > 1) facts.push_back(std::make_pair(n, 1)); return facts; } int main() { long to = 10000; auto ps = make_prime_list(std::sqrt(to)); for (long i = 1; i "},"computer_science/algorithm/exponentiation.html":{"url":"computer_science/algorithm/exponentiation.html","title":"冪乗","keywords":"","body":"冪乗（exponentiation） 高速に冪乗 xn を計算する際、偶数なら x2(n/2) 奇数なら x2(n/2)+1 と分解することで時間計算量が O(logn) になる。 #include long power(long x, int n) { if (n == 0) return 1; else if (n % 2) return x * power(x, n - 1); else return power(x * x, n / 2); } int main() { std::cout 冪乗の剰余 xnmodm を高速に計算したい。 周期性を利用する 合同類の性質上、同じ数をかけ合わせていったときのmodは周期的に循環する。 フェルマーの小定理を利用する m が素数で x,m が互いに素である場合、フェルマーの小定理が利用できる。 フェルマーの小定理 素数 p と整数 a が互いに素であるとき ap−1≡1(mod p) これによって上記の循環の周期が p−1 であることが確定するため実装が少し楽になる。 もう一歩踏み込むと次の法則が利用できる。 平方剰余の相互法則を利用する m が素数で x,m が互いに素である場合、次の法則を利用できる。 平方剰余の相互法則（reciprocity law） 相異なる奇素数 p,q に関して (qp)(pq)=(−1)p−12q−12 オイラーの基準 奇素数 p と自然数 a が互いに素であるとき (ap)≡ap−12(mod p) オイラーの基準から xn≡xn mod m≡xlxp−12≡(ap) (mod p) である。 (ap) は平方剰余の相互法則から求めることができるため、xl を両辺に掛け合わせて剰余を取ればよい。 "},"computer_science/algorithm/fast_fourier_transform.html":{"url":"computer_science/algorithm/fast_fourier_transform.html","title":"高速フーリエ変換","keywords":"","body":"高速フーリエ変換（Fast Fourier Transform : FFT） Cooley-Tukey algorithm mixed-radix algorithm 小さい素数に対して最適化されたFFTを実装（ O(N2) ） radix-2 algorithm N=2m にのみ対応（ O(nlogn) ） Prime Factor algorithm データ長を互いに素になるように 長さ p のFFTは長さ p−1 の畳み込みになる 基本 わかりやすいように N が因数2を持つとする。 WN=e−2πj/NXk=N−1∑n=0xnWnkN ここで右辺の奇数の項と偶数の項をわける。 Xk=N/2−1∑b=0(x2nW(2n)kN+x2n+1W(2n+1)kN)=N/2−1∑b=0(x2nW(2n)kN+WnNx2n+1W(2n)kN)=N/2−1∑b=0(x2n+WnNx2n+1)W(2n)kN この操作により N2 回必要だった積の計算が 2(N/2)2 に減る。 これを N の因数に対して再帰的に適用することで計算量を減らすのがFFTの基本概念となる。 N が素数である場合はこの操作が適用できないが、数論より N のFFTは N−1 の畳み込み積分に変換できるため、N−1 のFFTを行うことで高速に計算できる場合がある。 基数2のアルゴリズム（時間空間法） 理論 N=2m の場合は高速に計算が可能になる。 整数 a を a=[am−1⋯a1a0]=2am−1+⋯+2a1+a0 のようにビット表現することにして、まずフーリエ変換の定義式を n について展開する。 Xk=N−1∑n=0xnWnkN=1∑n0=0⋯1∑nm−2=01∑nm−1=0xnWk[nm−1⋯a1a0]N=1∑n0=0⋯1∑nm−2=0Wk[nm−2⋯n1n0]N1∑nm−1=0xnWknm−1N=1∑n0=0Wkn0N⋯1∑nm−2=0W2m−2knm−2N1∑nm−1=0xnW2m−1knm−1N ※このとき n に関して ∑ を分割することから時間空間法と呼ぶ。k に関して ∑ を分割する手法は周波数空間法と呼ばれる。 次に N=2m であることを利用して書き直す。 Xk=1∑n0=0Wkn0N⋯1∑nm−2=0Wknm−241∑nm−1=0xnWknm−12 WaN=e−2πja/N の a に対する周期性を利用しながら k もビット表現に展開する。 X[km−1⋯k1k0]=1∑n0=0W[km−1⋯k1k0]n0N⋯1∑nm−2=0W[k1k0]nm−241∑nm−1=0xnWk0nm−12 この式を下のように区切り、再帰的に表現する。 X[km−1⋯k1k0]=1∑n0=0W[km−1⋯k1k0]n0N⎛⎝⋯⎛⎝1∑nm−2=0W[k1k0]nm−24⎛⎝1∑nm−1=0(xn)Wk0nm−12⎞⎠⎞⎠⎞⎠ {r0(n)=xnri(n0,⋯,nm−i−1,k0,⋯,ki−1)=∑1ni=0W[ki−1⋯k0]ni2iri−1(n0,⋯,nm−i,k0,⋯,ki−2)(Xk=rm(km−1,⋯,k0)) ri は n0,⋯,nm−i−1,k0,⋯,ki−1 を変数とする関数と見なせる。 そこで [n0⋯nm−i−1ki−1⋯k0] を各 ri の変数と見なす。 上の漸化式で ki−1={0,1} のときで場合分けすると以下のようになる。 [ri([n0⋯nm−i−10ki−2⋯k0])ri([n0⋯nm−i−11ki−2⋯k0])]=⎡⎢⎣ri−1([n0⋯nm−i−10ki−2⋯k0])+W[0ki−2⋯k0]2iri−1([n0⋯nm−i−11ki−2⋯k0])ri−1([n0⋯nm−i−10ki−2⋯k0])+W[1ki−2⋯k0]2iri−1([n0⋯nm−i−11ki−2⋯k0])⎤⎥⎦=⎡⎢⎣ri−1([n0⋯nm−i−10ki−2⋯k0])+W[ki−2⋯k0]2iri−1([n0⋯nm−i−11ki−2⋯k0])ri−1([n0⋯nm−i−10ki−2⋯k0])−W[ki−2⋯k0]2iri−1([n0⋯nm−i−11ki−2⋯k0])⎤⎥⎦ この式より r1(∗),r2(∗),⋯ を計算するとき、上段のあるペアの値は下段の対応するペアの値から計算できることがわかる（これをバタフライ演算と呼ぶ）。 よって下段から順に計算していけば領域計算量は O(N) となり、ペアで計算を進めることによるメモ化の効果から時間計算量は O(nlogn) となる。 実装 import numpy as np def radix2fft(data): n = len(data) r = 1; m = 0 while r 例（N=8） r0([n0n1n2])=x[n2n1n0] r0([000])=x0r0([100])=x1r0([010])=x2r0([110])=x3r0([001])=x4r0([101])=x5r0([011])=x6r0([111])=x7 [r1([n0n10])r1([n0n11])]=[111−1][r0([n0n10])r0([n0n11])] r1([000])=r0([000])+r0([001])r1([100])=r0([100])+r0([101])r1([010])=r0([010])+r0([011])r1([110])=r0([110])+r0([111])r1([001])=r0([000])−r0([001])r1([101])=r0([100])−r0([101])r1([011])=r0([010])−r0([011])r1([111])=r0([110])−r0([111]) [r2([n00k0])r2([n01k0])]=[111−1][r1([n00k0])W[k0]4r1([n01k0])] r2([000])=r1([000])+r1([010])r2([100])=r1([100])+r1([110])r2([010])=r1([000])−r1([010])r2([110])=r1([100])−r1([110])r2([001])=r1([000])+W14r0([011])r2([101])=r1([100])+W14r0([111])r2([011])=r1([000])−W14r0([011])r2([111])=r1([100])−W14r0([111]) [r3([0k1k0])r2([1k1k0])]=[111−1][r2([0k1k0])W[k1k0]8r2([1k1k0])] r3(0)=r3([000])=r2([000])+r2([100])r3(4)=r3([100])=r2([000])−r2([100])r3(1)=r3([001])=r2([001])+W18r2([101])r3(5)=r3([101])=r2([001])−W18r2([101])r3(2)=r3([010])=r2([010])+W28r2([110])r3(6)=r3([110])=r2([000])−W28r2([110])r3(3)=r3([011])=r2([000])+W38r2([111])r3(7)=r3([111])=r2([000])−W38r2([111]) "},"computer_science/knowledge_representation/production_system.html":{"url":"computer_science/knowledge_representation/production_system.html","title":"プロダクションシステム","keywords":"","body":"プロダクションシステム（production system） 1973年にNewellによって提案された、if-thenルールに基づいた知識表現並びにそれを用いた推論を行うシステム。 役割によって前向き推論のシステムと後向き推論のシステムに分類される。 プロダクションシステムはルールの結合を動的に行うため、利用者はルールを列挙するだけでよく、大量の知識の処理に向いている。 参考：http://www.ownway.info/Home/cpp/ps/small/1.html 構成要素 プロダクションシステムは以下のコンポーネントから構成される。 知識ベース if-thenルールを格納する 作業領域／ワーキングメモリ 観測された事象や仮説、推論の途中経過を保持する 推論エンジン／rule interpreter 知識ベースから知識を取り出し、推論のアルゴリズムを実行する 前向き推論／前向き連鎖（forward chaining） 観測された事象に関して順にルールを適用していくことで、観測された事象から何が言えそうかを推論するシステム。 知識表現 前向き推論のプロダクションシステムでは、命題 A(t) を条件部とし、命題 B(t) について操作を施すようなルールすなわち if A(t) then {make/modify/remove  etc...} B(t) をif-thenルールとして保持する。 これを順に適用することで、新たな事実が追加されたり、既存の事実が否定・修正されたりしながら推論が進んでいく。 競合戦略 ルールの結論部にmodifyやremoveが含まれる場合、どのような順序でルールを適用するかによって結論が変わってくる。 Example R1 ： if A(t) then make C(t) R2 ： if A(t)∧B(t) then remove C(t) ここまで極端な例はないようにすべきだが、複雑な系では想定されるケースである。 このような競合に対応する手法を競合戦略という。 一般的には、適用可能なルールの競合集合（｛ルール, ｛条件となる事実｝｝の形で列挙したもの）から、一定の基準で実行するものを選択する。 このときの基準として、以下のLEX戦略（lexicographic sort）が有名である。 既に実行した組は除く 最近追加された事実を条件とする組を採用する ルールの条件部が複雑（詳細）な組を採用する 任意の組を採用する Example 先ほどの例に従うと競合集合は { {R1,{A}}, {R2,{A,B}} } となる。LEX戦略の1,2には当てはまらないものとすれば、3によって R2 が採用される。 後向き推論／後向き連鎖（backward chaining） 観測された事象と何らかの仮説が与えられたとき、その仮説が満たされうるかを知識に基づいて判断するシステム。 知識表現 後向き推論のプロダクションシステムでは、命題 A(t) を条件部とし、命題 B(t) を結論部とする論理式すなわち A(t)→B(t) をif-thenルールとして保持する。 このとき、推論は与えられた仮説を根としたAND/OR木が恒偽にならないかの検証に帰着できる。 手順は以下のように再帰的に表現される。 仮説を根とする 検証したい命題を結論部に持つルールを探す 見つからなければ検証不可としてルールごと木から取り除く つまりルール A(t)→B(t) の A(t) が証明できないならルールごとなかったことにする 見つけたルールの条件部が真になるか検証する 最終的に根が恒偽にならないかを検証する また、検証に用いた木を推論ネットワークということがあり、なぜその仮説が満たされうると考えたかの説明に用いられる。 "},"computer_science/knowledge_representation/frame.html":{"url":"computer_science/knowledge_representation/frame.html","title":"フレーム","keywords":"","body":"フレーム（frame） 1975年にM.Minskyによって提案された、典型的知識・階層的知識・事象に付随する手続き的知識を表現するためのデータ構造。 構造 フレームは以下の要素からなる。 なお、これらの呼び方は設計・実装によって微妙に異なることがある。 フレーム名 スロット／属性 ファセット（属性自体の性質を示すもの） 値 暗黙値（継承先で特に上書きされなかったとき暗黙的に利用する値） IF-NEEDED（必要ならデータとして格納された処理を実行する） IF-ADDED（データとして処理が格納されていればそれを実行する）　　etc... データ 値・処理・他のフレームなど またフレームは継承の概念（is-a関係）を持っており、あるフレームを親としてそれを継承する子フレームを定義できる。 "},"computer_science/knowledge_representation/semantic_network.html":{"url":"computer_science/knowledge_representation/semantic_network.html","title":"意味ネットワーク","keywords":"","body":"意味ネットワーク（semantic network） 概念の間の意味関係を表現する知識表現手法。 プロダクションシステムやフレームより単純な構造をしており、表現力が高い。 しかし、概念形成の処理が複雑になる、工夫しなければ探索空間が無限に広がるなどの問題点がある。 構成要素 頂点 概念を表す 辺・枝 概念の間の関係を表す 辺のラベル 関係の意味を表す 例 graph TD; 犬 --> |食べ物| 雑食 犬 --> |走る速度| 速い 犬 --> |is-a| 動物 ライオン --> |食べ物| 肉食 ライオン --> |is-a| 動物 ライオン --> |性格| 凶暴 動物 --> |属性| 動く 動物 --> |属性| 食べる 動物 --> |属性| 呼吸する 動物 --> |is-a| 生物 "},"computer_science/machine_learning/history.html":{"url":"computer_science/machine_learning/history.html","title":"人工知能の歴史","keywords":"","body":"人工知能の歴史 参考：https://www.ai-gakkai.or.jp/whatsai/AIhistory.html 1950 A.M.Turingがチューリングテストを提唱 1950 C.Shannonが初めてチェスを探索問題として解析 1956 ダートマス会議でJ.McCarthyにより初めて”Artificial Intelligence”（人工知能）という言葉が使われた 1965 J.Weizenbaumが対話型プログラムのELIZA（イライザ）を開発 1962 F.RosenblattがB.Widrowのニューラルネットをパーセプトロンと呼び，その集束定理を示した -------------------------------------------------------------------------------- 1973 A.Newellがプロダクションシステムを提案 "},"computer_science/machine_learning/abstract.html":{"url":"computer_science/machine_learning/abstract.html","title":"概要","keywords":"","body":"機械学習概要 Microsoft Azureのページで紹介されている分類をベースに解説する。 （From:https://docs.microsoft.com/ja-jp/azure/machine-learning/machine-learning-algorithm-cheat-sheet） 教師あり学習 ２クラス分類（two-class classification） データが2つのクラスのどちらに属するかを判断する識別器を学習する手法。 多クラス分類（multi-class classification） データがどのクラスに属するかを判断する識別器を学習する手法。 回帰分析（regression） ある変数とある変数の間にどのような相関関係が存在するかを学習する手法。 教師なし学習 クラスタリング（clustering） 大量のサンプルデータを性質の近いもの同士に分類する手法。 異常検知（anomaly detection） 他と比べて異常なデータを見つけ出す手法。 "},"computer_science/machine_learning/neural_network.html":{"url":"computer_science/machine_learning/neural_network.html","title":"ニューラルネットの基礎","keywords":"","body":"ニューラルネットの基礎 ニューラルネットワーク（neural network : NN） graph LR; s1((s1)) --> a1((a1)) s2((s2)) --> a1 s1 --> a2((a2)) s2 --> a2 s1 --> a3((a3)) s2 --> a3 a1 --> r1((r1)) a1 --> r2((r2)) a2 --> r1 a2 --> r2 a3 --> r1 a3 --> r2 subgraph Layer S s1 s2 end subgraph Layer A a1 a2 a3 end subgraph Layer R r1 r2 end 動物の脳のシナプスの結合を基に考案された数学モデル。 入力層（S層）、中間層（隠れ層・A層）、出力層（R層）に分類される複数のノードを互いに結んだ構造をしている。 単純パーセプトロン（simple perceptron） graph LR; a((Input1)) -->|weight1| c(Perceptron) b((Input2)) -->|weight2| c c -->|bias| d((Output)) 1957年にアメリカのFrank Rosenblattが提案したニューラルネットの一種。 人口ニューロンと呼ぶこともある。 構造 単純パーセプトロンは複数の入力・入力への重み付け・バイアスを考慮した評価値を出力する。 この時の評価値の算出に用いる関数を活性化関数（activation function）・伝達関数（transfer function）という。 また2層以上からなるパーセプトロンの集まりを多層パーセプトロン（multi-layered perceptron）と呼ぶこともある。 表現力 単純パーセプトロン1層で入力空間を線形に分類できるためNOT/AND/OR/NAND/NORを表現でき、2層にすればAND/NAND/ORの組み合わせによりXORを表現できる。 シグモイド関数を活性化関数とする2層のパーセプトロンを用いることで任意の関数を表現できることが理論的に証明されている。 活性化関数（activation function） よく用いられる活性化関数として次のようなものがある。 ステップ関数（step function） 0) \\\\ 0 & (x \\leq 0) \\end{cases} \\end{eqnarray}\">h(x)={1(x>0)0(x≤0) シグモイド関数（sigmoid funciton） h(x)=11+exp(−x) ReLU（reactified linear unit） 0) \\\\ 0 & (x \\leq 0) \\end{cases} \\end{eqnarray}\">h(x)={x(x>0)0(x≤0) ソフトマックス関数（soft-max function） 分類問題の出力層によく用いられる。 hk(x)=exp(xk)∑exp(xk) 次のような性質がある。 0hk(x)1 ∑hk=1 ニューラルネットにおける学習 教師あり学習ではパラメーター w のNNに訓練データ x を入力し、その結果 f(x;w) を教師データ t と比較し、相違に応じてパラメーター w を調整することで学習を行う。 このときの t と f(x;w) の相違の度合いを評価する関数を損失関数（loss function）といい、NNの学習は損失関数が最小になるようなパラメーターを探索する問題に帰着する。 バッチ学習 すべての訓練データで一度に学習させる手法。 ミニバッチ学習 訓練データをある程度まとめて少しずつ入力して学習させる手法 オンライン学習 学習データを1つずつ入力して学習させる手法。 "},"computer_science/machine_learning/deep_learning1.html":{"url":"computer_science/machine_learning/deep_learning1.html","title":"深層学習 読書メモ","keywords":"","body":"深層学習 読書メモ 第1章 階層型ニューラルネットワークによる深層学習 1.1 はじめに 機械学習の研究は「暗黙的な知識を具体的な事例などから計算機に学習させること」を目的に始まった。 ニューラルネットワークは人間や生物の脳神経系を参考に提唱された情報処理モデル。 深層学習はニューラルネットワークの一種。 この章では深層学習の実現形の1つである階層型ニューラルネットワークについて解説する。 1.2 内部表現のデータからの学習 深層学習では観測データから本質的な情報（内部表現）を抽出・学習する。 内部表現（internal representation）・潜在表現（latent representation）・特徴（feature） 1.2.1 内部表現の重要性とその学習法 次元削減（dimension reduction）：多変量データ解析の分野では、主成分分析・因子分析などから「データ変動の構造」を説明しようという取り組みが重要な課題の1つであった 可視化しやすい->人間が認識しやすい クラス識別器による分類がしやすくなる 関連するトピック 汎用的な学習の必要性 マルチタスク学習：複数のタスクを同時に学習する手法 転移学習：あるタスクに対する学習結果を他のタスクに転用する 状態空間表現：強化学習 記号の創発 圧縮センシング：低次元のセンシングからスパース性を利用して元の信号を推定する手法 醜いアヒルの子の定理（ugly duckling theorem）：注目する特徴量を決めないことには、対象の分類は不可能である 普通のアヒルAと普通のアヒルBに共通する特徴量、普通のアヒルAと醜いアヒルに共通する特徴量、といったすべての特徴量を同等に扱うとき、普通のアヒル同士の差と普通のアヒル・醜いアヒルの間の差は同程度である ノーフリーランチ定理（no free lunch theorem）：数学的にありうるすべての問題について見たとき、すべての探索アルゴリズムは同じ平均性能を示す あるアルゴリズムが他のアルゴリズムより優秀であるのはその問題に対して特殊化されている場合だけ 優秀なアルゴリズムを見つけたければ問題領域の知識を可能な限り利用して特殊化すべし どんなパターンにおいても優秀な万能学習アルゴリズムというものは存在しない 1.2.2 特徴工学と表現学習 特徴工学（feature engineering）：あるタスクに適した内部表現を見つける問題 特徴工学へのアプローチ 人手によって内部表現を設計する方法 画像認識におけるSIFT特徴量などはここに分類される データから内部表現を機械学習させる方法（表現学習（representation learning）） 特徴選択、カーネル設計、マルチカーネル学習、データ行列の低ランク分解など 候補を人手で提示しその先は機械学習、といった折衷的なアプローチも 特徴量の評価点 情報量：入力信号の情報量をできるだけ多く保持しているか 独立性：相互の特徴がなるべく独立していて重複していないか 説明性：どのような情報が特徴量として抽出されているかを説明できるか スパース性：値ゼロを取る特徴が多いか 不変性：入力信号の特定の変換に対して変化しないか ロバスト性：入力信号の微小変動に対して変化しないか 平滑性：元の情報が変化したときに特徴の値が滑らかに変化するか 学習手法の例 主成分分析（principal component analysis:PCA） 次元削減後の分散が最大になるように信号空間上の部分空間を選ぶ 元の情報が多変数正規分布に従うなら、分散の最大化と次元削減後の情報量の最大化は等価になる 因子分析（factor analysis:FA） 主成分分析の軸を回転させてより説明性の高い特徴を探索する 独立成分分析（independent component analysis:ICA） 独立性の高い特徴量を抽出し、元の情報を特徴の線形和に見立てる スパースモデリング スパース性の高い内部表現を得る 多様体学習（manifold learning） （主成分分析などは信号空間を部分空間に射影を得ようとするの対し）低次元多様体への非線形な射影を得る "},"computer_science/machine_learning/prml1.html":{"url":"computer_science/machine_learning/prml1.html","title":"パターン認識と機械学習1","keywords":"","body":"パターン認識と機械学習 序章 機械学習とは 訓練集合（training set）{x1,⋯,xn}   (xi∈X) （教師あり学習の場合は加えて目標ベクトル（target vector）t∈T） の組み合わせから関数 y:X→T を得る手法。 汎化（generalization） 得られた関数 y(x) は、訓練集合になかった事例についても正しく分類する能力が求められる。 この能力は汎化と呼ばれ、パターン認識の中心的な課題となっている。 前処理（preprocessing）・特徴抽出（feature extraction） 学習の前段階でデータを加工すること。 主に学習の精度向上・計算の高速化を目的として施される。 例えば、数字のクラス分類問題で画像サイズ・方向を揃えて文字部分を切り抜いたものを入力とする、顔認識で長方形の小領域における画像強度の平均値を入力とする、など。 ただし、問題を解く上で重要な情報まで削ってしまうとシステムの性能が落ちる。 機械学習手法の分類 教師あり学習（supervised learning） 訓練データが入力ベクトルと目標ベクトルの組み合わせで構成される問題に対する学習手法。 クラス分類（classification） 入力を有限個の離散カテゴリの1つに割り当てる問題 回帰（regression） 入力から1つないし複数の連続変数を得る問題 教師なし学習（unsupervised learning） 訓練データが入力ベクトルのみからなり、それらの目標ベクトルが不明な問題に対する学習手法。 クラスタリング（clustering） 類似した入力のグループを見つける問題 密度推定（density estimation） 入力空間におけるデータの分布を求める問題 視覚化（visualization）のための次元削減 高次元のデータを次元削減する問題 強化学習（reinforcement learning） 与えられた状況下で報酬を最大にするような行動を見つける問題に対する学習手法。 ゲームAIの学習などに利用される。 最終的な目標（ゲームなら勝利）は与えられるが、局面ごとの最善手はアルゴリズム自ら発見しなければならない、という点で上記の手法と区別される。 主な課題として、結果的に勝利したとして途中の手が全て最善手であったかはわからない、という信頼度割り当て（credit assignment）問題がある。 一般的には、新しい行動がどの程度有効か試す探査（exploration）と高い報酬が得られることが分かっている行動を取る知識利用（exploitation）をうまく選択することで学習効率がよくなる。 ※遺伝的アルゴリズムと同じで、優性遺伝させつつ突然変異を混ぜると効率が良くなるという話だと思われる "},"computer_science/machine_learning/scikit_mnist.html":{"url":"computer_science/machine_learning/scikit_mnist.html","title":"scikit-learnでMNIST","keywords":"","body":"scikit-learnでMNIST とりあえず試したみた。 scikit-learnにもMNISTの縮小版データが含まれているらしいが解像度が低いとのことなので、MNIST本家からデータを落としてくることにした。 環境 macOS Sierra 10.12.5 python 3.6.0 numpy 1.12.0 scikit-learn 0.18.1 データの取得・変換 とりあえずダウンロード。 wget http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz wget http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz wget http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz wget http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz gzip -d * imagesの方は、先頭にマジックナンバー(4byte)・データ総数(4byte)・画像縦幅(4byte)・画像横幅(4byte)が書かれており、その後ひたすら1byteデータ（28×28ビットの画像の画素値）が並んでいる。 labelsの方は、先頭にマジックナンバー(4byte)・データ総数(4byte)が書かれており、その後ひたすら1byteデータ（画像に書かれている数字）が並んでいる。 BSD系のodコマンドは改行位置の指定ができないっぽいのでとりあえず16要素ごとに改行されたスペース区切りのtxtファイルに。 od -An -v -j16 -tu1 train-images-idx3-ubyte | sed 's/^ *//' | tr -s ' ' > train-images.txt od -An -v -j8 -tu1 train-labels-idx1-ubyte | sed 's/^ *//' | tr -s ' ' > train-labels.txt od -An -v -j16 -tu1 t10k-images-idx3-ubyte | sed 's/^ *//' | tr -s ' ' > test-images.txt od -An -v -j8 -tu1 t10k-labels-idx1-ubyte | sed 's/^ *//' | tr -s ' ' > test-labels.txt Pythonへデータを取り込み import numpy as np from sklearn.ensemble import RandomForestClassifier print(\"Loading MNIST data...\") images = np.loadtxt('train-images.txt', dtype=np.uint8) images = images.reshape((-1, 28*28)) labels = np.loadtxt('train-labels.txt', dtype=np.uint8) labels = labels.reshape((-1)) print(\"...Completed\") print(\"Loading test MNIST data...\") test_images = np.loadtxt('test-images.txt', dtype=np.uint8) test_images = test_images.reshape((-1, 28*28)) test_labels = np.loadtxt('test-labels.txt', dtype=np.uint8) test_labels = test_labels.reshape((-1)) print(\"...Completed\") 学習・テスト ランダムフォレストを使ってみる。 import numpy as np from sklearn.ensemble import RandomForestClassifier print(\"Fitting...\") rfc = RandomForestClassifier() rfc.fit(images, labels) print(\"Testing...\") print(rfc.score(test_images, test_labels)) 0.9452 "},"computer_science/language_processing/nlp100_1.html":{"url":"computer_science/language_processing/nlp100_1.html","title":"言語処理100本ノック1","keywords":"","body":"言語処理100本ノック 2015 http://www.cl.ecei.tohoku.ac.jp/nlp100/ 第1章 準備運動 00. 文字列の逆順 文字列\"stressed\"の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ． str1 = 'stressed' print(str1[::-1]) desserts 01. 「パタトクカシーー」 「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ． str1 = 'パタトクカシーー' print(str1[1::2]) タクシー 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」 「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ． str1 = 'パトカー' str2 = 'タクシー' str3 = '' for a, b in zip(str1, str2): str3 = str3 + a + b str3 += str1[len(str2):] if len(str1) > len(str2) else str2[len(str1):] print(str3) パタトクカシーー 03. 円周率 \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\"という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ． str1 = \"Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.\" str2 = str1.replace(',', '').replace('.', '') words = str2.split(' ') res = [len(s) for s in words] print(res) [3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9] 04. 元素記号 \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\"という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭の2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ． str1 = \"Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.\" checked = [1, 5, 6, 7, 8, 9, 15, 16, 19] words = str1.replace('.', '').split(' ') dic = {i+1:s[0] if i + 1 in checked else s[:2] for i, s in enumerate(words)} print(dic) {1: 'H', 2: 'He', 3: 'Li', 4: 'Be', 5: 'B', 6: 'C', 7: 'N', 8: 'O', 9: 'F', 10: 'Ne', 11: 'Na', 12: 'Mi', 13: 'Al', 14: 'Si', 15: 'P', 16: 'S', 17: 'Cl', 18: 'Ar', 19: 'K', 20: 'Ca'} 05. n-gram 与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，\"I am an NLPer\"という文から単語bi-gram，文字bi-gramを得よ． n-gramとは 検索対象の文章からn文字・n単語ずつ切り出したものをインデックス、文章IDを値とした辞書を作成し、検索ワードに一致する文字・単語をインデックスから検索することで文章を検索する手法。 特にn=1のときuni-gram、n=2のときbi-gram、n=3のときtri-gramという。 def gen_n_gram(source, n): return {tuple(source[i:i + n]) for i in range(len(source) - n + 1)} str1 = \"I am an NLPer\" chars_bigram = gen_n_gram(str1, 2) words_bigram = gen_n_gram(str1.split(' '), 2) print(chars_bigram) print(words_bigram) {('n', ' '), ('a', 'm'), ('e', 'r'), ('N', 'L'), ('L', 'P'), (' ', 'a'), ('a', 'n'), ('P', 'e'), ('m', ' '), (' ', 'N'), ('I', ' ')} {('am', 'an'), ('an', 'NLPer'), ('I', 'am')} 06. 集合 \"paraparaparadise\"と\"paragraph\"に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，'se'というbi-gramがXおよびYに含まれるかどうかを調べよ． def gen_n_gram(source, n): return {tuple(source[i:i + n]) for i in range(len(source) - n + 1)} str1 = \"paraparaparadise\" str2 = \"paragraph\" X = gen_n_gram(str1, 2) Y = gen_n_gram(str2, 2) print(X | Y) print(X & Y) print(X - Y) {('a', 'p'), ('d', 'i'), ('a', 'r'), ('s', 'e'), ('a', 'd'), ('p', 'h'), ('p', 'a'), ('r', 'a'), ('i', 's'), ('a', 'g'), ('g', 'r')} {('a', 'p'), ('r', 'a'), ('a', 'r'), ('p', 'a')} {('i', 's'), ('d', 'i'), ('s', 'e'), ('a', 'd')} 07. テンプレートによる文生成 引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=\"気温\", z=22.4として，実行結果を確認せよ． def gen_message(x, y, z): return str(x) + '時の' + y + 'は' + str(z) print(gen_message(12, '気温', 22.4)) 12時の気温は22.4 08. 暗号文 与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ． 英小文字ならば(219 - 文字コード)の文字に置換 その他の文字はそのまま出力 この関数を用い，英語のメッセージを暗号化・復号化せよ． 補足 アトバシュ暗号（Atbash Cipher）。 ord('a') -> 97、ord('z') -> 122のため、219から引き算するとアルファベット順が逆転する。 def cipher(s): return ''.join([chr(219 - ord(ch)) if ch.islower() else ch for ch in s]) str1 = 'abcdefghijklmnopqrstuvwxyz' print(cipher(str1)) print(cipher(cipher(str1))) zyxwvutsrqponmlkjihgfedcba abcdefghijklmnopqrstuvwxyz 09. Typoglycemia スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば\"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"）を与え，その実行結果を確認せよ． 補足 タイポグリセミア（typoglycemia）は、人間は単語の両端さえ合っていれば内側の文字がシャッフルされていても文章を読める、という現象。 import random def typoglycemia(s): def parse(w): if len(w) I c'dnluot belevie that I could altlacuy utrnsedand what I was rniedag : the pmaohenenl poewr of the human mind . "},"computer_science/language_processing/nlp100_2.html":{"url":"computer_science/language_processing/nlp100_2.html","title":"言語処理100本ノック2","keywords":"","body":"言語処理100本ノック 2015 http://www.cl.ecei.tohoku.ac.jp/nlp100/ 第2章 UNIXコマンドの基礎 hightemp.txtは，日本の最高気温の記録を「都道府県」「地点」「℃」「日」のタブ区切り形式で格納したファイルである．以下の処理を行うプログラムを作成し，hightemp.txtを入力ファイルとして実行せよ．さらに，同様の処理をUNIXコマンドでも実行し，プログラムの実行結果を確認せよ． 高知県 江川崎 41 2013-08-12 埼玉県 熊谷 40.9 2007-08-16 岐阜県 多治見 40.9 2007-08-16 山形県 山形 40.8 1933-07-25 山梨県 甲府 40.7 2013-08-10 和歌山県 かつらぎ 40.6 1994-08-08 静岡県 天竜 40.6 1994-08-04 山梨県 勝沼 40.5 2013-08-10 埼玉県 越谷 40.4 2007-08-16 群馬県 館林 40.3 2007-08-16 群馬県 上里見 40.3 1998-07-04 愛知県 愛西 40.3 1994-08-05 千葉県 牛久 40.2 2004-07-20 静岡県 佐久間 40.2 2001-07-24 愛媛県 宇和島 40.2 1927-07-22 山形県 酒田 40.1 1978-08-03 岐阜県 美濃 40 2007-08-16 群馬県 前橋 40 2001-07-24 千葉県 茂原 39.9 2013-08-11 埼玉県 鳩山 39.9 1997-07-05 大阪府 豊中 39.9 1994-08-08 山梨県 大月 39.9 1990-07-19 山形県 鶴岡 39.9 1978-08-03 愛知県 名古屋 39.9 1942-08-02 10. 行数のカウント 行数をカウントせよ．確認にはwcコマンドを用いよ． 補足 wcは行数・文字数・バイト数を計算するコマンド。 $ wc hightemp.txt 24 98 813 hightemp.txt with open('hightemp.txt') as f: lines = f.readlines() print(len(lines)) 11. タブをスペースに置換 タブ1文字につきスペース1文字に置換せよ．確認にはsedコマンド，trコマンド，もしくはexpandコマンドを用いよ． 補足 OS Xなどに入っているBSD sedはエスケープ文字を展開してくれない。 そのため、直接タブ文字などを入力するか$''を使ってshellの段階で展開する必要がある。 # OS X $ sed -e $'s/\\t/ /g' hightemp.txt > output11.txt $ sed -e s/$'\\t'/g' '/g hightemp.txt > output11.txt # Linux $ sed -e 's/\\t/ /g' test.txt > output11.txt with open('hightemp.txt') as f: str1 = f.read() print(str1.replace('\\t',' ')) 12. 1列目をcol1.txtに，2列目をcol2.txtに保存 各行の1列目だけを抜き出したものをcol1.txtに，2列目だけを抜き出したものをcol2.txtとしてファイルに保存せよ．確認にはcutコマンドを用いよ． $ cut -d $'\\t' -f 1 hightemp.txt > col1.txt $ cut -d $'\\t' -f 2 hightemp.txt > col2.txt import os with open('hightemp.txt') as f: lines = f.readlines() col1lines = map(lambda s: s.split('\\t')[0], lines) with open('col1.txt', 'w') as f: f.write('\\n'.join(col1lines)) col2lines = map(lambda s: s.split('\\t')[1], lines) with open('col2.txt', 'w') as f: f.write(os.linesep.join(col2lines)) 13. col1.txtとcol2.txtをマージ 12で作ったcol1.txtとcol2.txtを結合し，元のファイルの1列目と2列目をタブ区切りで並べたテキストファイルを作成せよ．確認にはpasteコマンドを用いよ． paste col1.txt col2.txt > output13.txt import os with open('col1.txt') as f1: col1lines = f1.readlines() with open('col2.txt') as f2: col2lines = f2.readlines() with open('output13.txt', 'w') as f: for col1, col2 in zip(col1lines, col2lines): f.write(col1.replace(os.linesep, '') + '\\t' + col2) 14. 先頭からN行を出力 自然数Nをコマンドライン引数などの手段で受け取り，入力のうち先頭のN行だけを表示せよ．確認にはheadコマンドを用いよ． N=2 head -n $N hightemp.txt import os n = 2 with open('hightemp.txt') as f: for i in range(n): print(f.readline().replace(os.linesep, '')) 15. 末尾のN行を出力 自然数Nをコマンドライン引数などの手段で受け取り，入力のうち末尾のN行だけを表示せよ．確認にはtailコマンドを用いよ． N=2 tail -n $N hightemp.txt > output15.txt import os n = 2 with open('hightemp.txt') as f: lines = f.readlines() for i in range(n): print(lines[-n+i].replace(os.linesep, '')) 16. ファイルをN分割する 自然数Nをコマンドライン引数などの手段で受け取り，入力のファイルを行単位でN分割せよ．同様の処理をsplitコマンドで実現せよ． N=5 split -l $N hightemp.txt output. import math n = 5 with open('hightemp.txt') as f: lines = f.readlines() for i in range(math.ceil(len(lines) / n)): with open('output16-' + str(i+1) + '.txt', 'w') as f: f.writelines(lines[n*i:n*(i+1)]) 17. １列目の文字列の異なり 1列目の文字列の種類（異なる文字列の集合）を求めよ．確認にはsort, uniqコマンドを用いよ． cut -d $'\\t' -f 1 hightemp.txt | sort | uniq with open('hightemp.txt') as f: print({line.split('\\t')[0] for line in f}) 18. 各行を3コラム目の数値の降順にソート 各行を3コラム目の数値の逆順で整列せよ（注意: 各行の内容は変更せずに並び替えよ）．確認にはsortコマンドを用いよ（この問題はコマンドで実行した時の結果と合わなくてもよい）． sort -r -k 3 hightemp.txt import os with open('hightemp.txt') as f: lines = f.readlines() lines.sort(key=lambda line: float(line.split('\\t')[2])) lines.reverse() for line in lines: print(line.replace(os.linesep, '')) 19. 各行の1コラム目の文字列の出現頻度を求め，出現頻度の高い順に並べる 各行の1列目の文字列の出現頻度を求め，その高い順に並べて表示せよ．確認にはcut, uniq, sortコマンドを用いよ． cut -d $'\\t' -f 1 hightemp.txt | sort | uniq -c | sort -r -k 1 import pandas, os with open('hightemp.txt') as f: df = pandas.DataFrame([line.replace(os.linesep, '').split('\\t') for line in f]) grouped = [(g[0], len(g[1])) for g in df.groupby(0)] grouped.sort(key=lambda t: t[1]) grouped.reverse() for g in grouped: print(g[0] + '\\t' + str(g[1])) "},"computer_science/language_processing/nlp100_3.html":{"url":"computer_science/language_processing/nlp100_3.html","title":"言語処理100本ノック3","keywords":"","body":"言語処理100本ノック 2015 http://www.cl.ecei.tohoku.ac.jp/nlp100/ 第3章 正規表現 Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzがある． 1行に1記事の情報がJSON形式で格納される 各行には記事名が\"title\"キーに，記事本文が\"text\"キーの辞書オブジェクトに格納され，そのオブジェクトがJSON形式で書き出される ファイル全体はgzipで圧縮される jawiki-country.json 以下の処理を行うプログラムを作成せよ． 20. JSONデータの読み込み Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ． import json with open('jawiki-country.json') as f: for line in f: jdata = json.loads(line) if jdata[\"title\"] == \"イギリス\": print(jdata[\"text\"]) 21. カテゴリ名を含む行を抽出 記事中でカテゴリ名を宣言している行を抽出せよ． 補足 pythonの正規表現は基本は最長マッチ。 最短マッチさせたいときは.+?のように?を加える。 import re with open('jawiki-country.json') as f: for line in f: for m in re.findall(r'\\[\\[Category:.+?\\]\\]', line): print(m) 22. カテゴリ名の抽出 記事のカテゴリ名を（行単位ではなく名前で）抽出せよ． import re with open('jawiki-country.json') as f: for line in f: for m in re.findall(r'(? 23. セクション構造 記事中に含まれるセクション名とそのレベル（例えば\"== セクション名 ==\"なら1）を表示せよ． 補足 pythonの正規表現でグループを定義した場合、グループごとに分割されたtupleが返ってくる。 import re with open('jawiki-country.json') as f: for line in f: for m in re.findall(r'(={2,})(.+?)\\1', line): print(m[1] + '\\t' + str(len(m[0])-1)) 24. ファイル参照の抽出 記事から参照されているメディアファイルをすべて抜き出せ． 補足 JSONに書かれたRedmine記法的なものなので、改行が平文字の\\nで書かれている部分がある。 import re with open('jawiki-country.json') as f: for line in f: for m in re.findall(r'(ファイル|File):(.+?)[\\|\\]\\\\]', line): print(m[1]) 25. テンプレートの抽出 記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ． import re, json res = {} with open('jawiki-country.json') as f: for line in f: dic = {} for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line): for p in re.findall(r'\\\\n\\|\\s*(.+?)\\s*=\\s*(.*?)\\\\n\\|', m[0]): dic[p[0]] = p[1] res[json.loads(line)['title']] = dic 26. 強調マークアップの除去 25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: マークアップ早見表）． 補足 強調は''hoge'','''fuga''','''''piyo'''''の3種類。 import re, json res = {} with open('jawiki-country.json') as f: for line in f: dic = {} for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line): text = re.sub(r\"'{2,}\", '', m[0]) #強調表記の除去 for p in re.findall(r'\\\\n\\|\\s*(.+?)\\s*=\\s*(.*?)\\\\n\\|', text): dic[p[0]] = p[1] res[json.loads(line)['title']] = dic 27. 内部リンクの除去 26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: マークアップ早見表）． 補足 [hoge] -> hoge [hoge|fuga] -> fuga [hoge#fuga|piyo] -> fuga import re, json res = {} with open('jawiki-country.json') as f: for line in f: dic = {} for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line): #強調表記の除去 text = re.sub(r\"'{2,}\", '', m[0]) #内部リンクの除去 text = re.sub(r'\\[\\[(?!ファイル:|File:)(((?!\\]\\]).)+?\\|)?(.+?)\\]\\]', r'\\3', text) for p in re.findall(r'\\\\n\\|\\s*(.+?)\\s*=\\s*(.*?)\\\\n\\|', text): dic[p[0]] = p[1] res[json.loads(line)['title']] = dic 28. MediaWikiマークアップの除去 27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ． import re, json res = {} with open('jawiki-country.json') as f: for line in f: dic = {} for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line): #強調表記の除去 text = re.sub(r\"'{2,}\", '', m[0]) #内部リンク・画像情報の除去 text = re.sub(r'\\[\\[(((?!\\]\\]).)+?\\|)?([^\\|]+?)\\]\\]', r'\\3', text) #外部リンクの除去 text = re.sub(r'\\[http.+?\\]', '', text) #htmlタグの除去 text = re.sub(r'', '', text) for p in re.findall(r'\\\\n\\|\\s*(.+?)\\s*=\\s*(.*?)\\\\n\\|', text): dic[p[0]] = p[1] res[json.loads(line)['title']] = dic #完全ではないけどとりあえずいいことにする 29. 国旗画像のURLを取得する テンプレートの内容を利用し，国旗画像のURLを取得せよ．（ヒント: MediaWiki APIのimageinfoを呼び出して，ファイル参照をURLに変換すればよい） import re, json, requests res = {} with open('jawiki-country.json') as f: for line in f: for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line): for p in re.findall(r'\\\\n\\|\\s*(.+?)\\s*=\\s*(.*?)\\\\n\\|', m[0]): if p[0] == '国旗画像' or p[0] == '国章画像': filename = re.search(r':(.+?)\\|', p[1]) if filename is not None: print(json.loads(line)['title'] + '\\t' + filename[1]) url = \"https://en.wikipedia.org/w/api.php\" payload = {\"action\": \"query\", \"titles\": \"File:{}\".format(filename[1]), \"prop\": \"imageinfo\", \"format\": \"json\", \"iiprop\": \"url\"} jdata = requests.get(url, params=payload).json() print(re.search(r\"'url'\\s*:\\s*'(.+?)'\", str(jdata))[1]) "},"computer_science/language_processing/nlp100_4.html":{"url":"computer_science/language_processing/nlp100_4.html","title":"言語処理100本ノック4","keywords":"","body":"言語処理100本ノック 2015 http://www.cl.ecei.tohoku.ac.jp/nlp100/ 第4章 形態素解析 夏目漱石の小説『吾輩は猫である』の文章（neko.txt）をMeCabを使って形態素解析し，その結果をneko.txt.mecabというファイルに保存せよ．このファイルを用いて，以下の問に対応するプログラムを実装せよ． なお，問題37, 38, 39はmatplotlibもしくはGnuplotを用いるとよい． 30. 形態素解析結果の読み込み / 31. 動詞 / 32. 動詞の原形 形態素解析結果（neko.txt.mecab）を読み込むプログラムを実装せよ．ただし，各形態素は表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をキーとするマッピング型に格納し，1文を形態素（マッピング型）のリストとして表現せよ．第4章の残りの問題では，ここで作ったプログラムを活用せよ． 若干異なるが、JUMANの解析結果を読み込めるプログラムを作成した。 from pyknp import MList import subprocess with open('neko.txt') as f: for line in f: if line != \"\": res = subprocess.Popen(\"echo '{}' | jumanpp\".format(line), shell=True, stdout=subprocess.PIPE).communicate()[0].decode('utf-8') for m in MList(res).mrph_list(): print(m.midasi) print(m.genkei) 33. サ変名詞 サ変接続の名詞をすべて抽出せよ. from pyknp import MList import subprocess with open('neko.txt') as f: for line in f: if line != \"\": res = subprocess.Popen(\"echo '{}' | jumanpp\".format(line), shell=True, stdout=subprocess.PIPE).communicate()[0].decode('utf-8') for m in MList(res).mrph_list(): if m.hinsi_id == 6 and m.bunrui_id == 2: print(m.midasi) 34. 「AのB」 2つの名詞が「の」で連結されている名詞句を抽出せよ. from pyknp import MList import subprocess with open('neko.txt') as f: for line in f: if line != \"\": res = subprocess.Popen(\"echo '{}' | jumanpp\".format(line), shell=True, stdout=subprocess.PIPE).communicate()[0].decode('utf-8') ms = list(MList(res).mrph_list()) for i, m in enumerate(ms): if m.hinsi_id == 9 and m.bunrui_id == 3 and m.midasi == \"の\" and ms[i-1].hinsi_id == 6 and ms[i+1].hinsi_id == 6: print(ms[i-1].midasi + m.midasi + ms[i+1].midasi) "},"computer_science/graphic/3dcg.html":{"url":"computer_science/graphic/3dcg.html","title":"3次元コンピューターグラフィックス","keywords":"","body":"3次元コンピューターグラフィックス モデリング（modeling） シーンとオブジェクト（scene / object） 画像化の対象となる仮想空間をシーンという。 また、シーンに配置された仮想物体・光源・カメラなどをオブジェクトという。 シーングラフ（scene graph） シーン上のオブジェクトのサイズ・向き・位置関係をグラフで表現したものをシーングラフという。 ラスタライズの処理を効率化するため、一般的には木構造・DAGで表現する。 ポリゴン（polygon） 通常、3DCGオブジェクトは多数の多角形（ポリゴン）の組み合わせで近似的に表現する。 これをポリゴンメッシュという（ポリゴンメッシュを省略してポリゴンと呼ぶこともある）。 四角形以上の多角形をポリゴンとすると非平面ポリゴンを想定した処理を実装する必要がありアルゴリズムが煩雑になる。 そのため、一般的には三角形をポリゴンとすることが多い。 テクスチャマッピング（texture mapping） オブジェクトの表面に定義済みの画像を貼り付けて表面特性（質感）を表現する手法をテクスチャマッピングという。 メモリ上に保持したテクスチャを使いまわせるため処理が軽くなる反面、視点からの距離に応じた解像度の変化に対応できないなどの欠点がある。 レンダリング（rendering） シーンを記述したデータから画像・映像・音声などを生成することをレンダリングという。 また、レンダリングを行うソフトウェアをレンダリングエンジン・レンダラーと呼ぶ。 また一連のレンダリング処理の手順をレンダリングパイプライン・グラフィックスパイプラインと呼ぶ。 OpenGL4.0では次のようにレンダリングパイプラインが定義されている。 Vertex Specification Vertex Processing Vertex Shader Tessellation Geometry Shader Vertex Post-Processing Transform Feedback Primitive Assembly Face Culling Rasterization Fragment Shader Per-Sample Processing Scissor Test Stencil Test Depth Test Blending Logical Operation Write Mask またDirectX10では次のようにレンダリングパイプラインが定義されている。 Input-Assembler Stage Vertex-Shader Stage Geometry-Shader Stage Stream-Output Stage Rasterizer Stage Pixel-Shader Stage Output-Merger Stage シェーディング（shading） 光源距離・光源と面の角度などを考慮して物体表面の色を変化させ、陰影をつける処理をシェーディングという。 シェーディングを施すことで、物体に奥行き感を加わり立体的な形状が把握しやすくなる。 シェーディングを行うプログラムをシェーダと呼ぶ。 バーテックスシェーダ（頂点シェーダ）（vertex shader） シーン上のオブジェクトの頂点に関する座標変換の処理を行うプログラムをバーテックスシェーダと呼ぶ。 テッセレーション（tessellation） 必要に応じて描画時にモデルのポリゴンを細かく分割することをテッセレーションという。 テッセレーションを利用することで最初に読み込むモデルのポリゴンを粗めにし、データ量を抑制することができる。 ジオメトリシェーダ（geometry shader） バーテックスシェーダから出力された頂点を以降の処理で利用するデータ構造（OpenGLではプリミティブと呼ぶ）に変換するシェーダ。 必要に応じて頂点数を増減させたり利用するプリミティブの種類を変えるなどの拡張を行う。 ラスタライズ（rasterization） セルを格子状に並べたようなデータ構造をラスタ形式（ラスタデータ）といい、あるデータをラスタ形式に変換する処理をラスタライズという。 レンダリングパイプラインにおけるラスタライズとは、描画する平面に投影された各ポリゴンを画素に対応したフラグメントに割り当てる処理を指す（設定によっては1画素につき複数のフラグメントを持たせることができるらしい）。 フラグメントシェーダ（fragment shader） ラスタライズによって生成されたフラグメントを画像に変換するシェーダ。 双方向反射率分布関数（Bidirectional reflectance distribution function : BRDF） 最も単純な反射モデルの1つ。 ある入射方向からある波長の光が入射したとき、各方向にどれだけ反射するかを表した関数。 入射・反射の関係を入れ替えても同じ値が得られる相反性（reciprocity）を持つ。 ランバート反射（Lambertian reflection） 入射した光がすべての方向に均等に拡散されるという理想的な拡散反射を表したシェーディングモデル。 フラットシェーディング・コンスタントシェーディング（flat shading / constant shading） 1つのポリゴン面全体に一定の反射モデルを適用するシェーディング手法。 ポリゴン面上の輝度が一様になるためフラット・コンスタントシェーディングと呼ばれる。 処理速度は速いが、全体的に角ばった表現になり、リアルさに欠ける。 グーローシェーディング（Gouraud shading） 1971年ユタ大学のHenri Gouraudが考案したシェーディングモデル。 フォンシェーディング（Phong shading） 1973年ユタ大学のBui Tuong Phongが考案したシェーディングモデル。 拡散反射成分・鏡面反射成分に加えて、表面の法線方向に依存しない、すなわち光源と物体色にのみ依存してシーン内に一様に与えられる項を導入している。 環境光反射成分は本来、二次反射などを考慮して計算されるものだが、フォンのシェーディングモデルではシーン中に一様に光を値得ることでこれを近似的に表している。 シェーディング言語（shading language） シェーダーのプログラミングに特化したプログラミング言語。 GLSL（OpenGL Shading Language） HLSL（High Level Shading Language） Cg（C for Graphics） "},"computer_science/graphic/zhang_camera_calibration.html":{"url":"computer_science/graphic/zhang_camera_calibration.html","title":"Zhangの方法によるカメラキャリブレーション","keywords":"","body":"Zhangの方法によるカメラキャリブレーション パターンをプリントした板を用意し、それを違う角度から撮影した何枚かの画像からカメラパラメーターを取得する手法。 表記の約束ごと 二次元座標を m=[u,v]T 、三次元座標を M=[X,Y,Z]T 、それぞれの末尾に要素 1 を加えたものを ~m=[u,v,1] 、~M=[X,Y,Z,1] と表記する。 ピンホールカメラを3次元座標 M と画像上の点 m の関係を定義するものとして見ると、その関係は s~m=A[Rt]~M と表される（s はスケール、R は回転行列、t は並進ベクトル）。 ここで A はカメラの特性を表す行列で、次のように構成される。 A=⎡⎢⎣αγu00βv0001⎤⎥⎦ α, β はそれぞれ画像の u,v 軸方向のスケール、(u0,v0) は画像中心の座標、γ はアフィン歪みの歪度を表している。 パターン面と画像のホモグラフィ 一般性を失わずにパターン面を Z=0 と仮定できる。 すると先程の式は次のような同次の線形変換になる。 s~m=H~MH=[h1h2h3]=A[r1r2t] r1, r2 は直交するため、 hT1A−TA−1h2=0hT1A−TA−1h1=hT2A−TA−1h2 の2つの制約式が得られる。 解法 A−TA−1 に注目すると、 B=A−TA−1=⎡⎢⎣B11B12B13B12B22B23B13B23B33⎤⎥⎦=⎡⎢ ⎢ ⎢ ⎢ ⎢ ⎢⎣1α2−γα2βv0γ−u0βα2β−γα2βγ2α2β2+1β2−γ(v0γ−u0β)α2β2−v0β2v0γ−u0βα2β−γ(v0γ−u0β)α2β2−v0β2(v0γ−u0β)2α2β2+v20β2+1⎤⎥ ⎥ ⎥ ⎥ ⎥ ⎥⎦ とおける。 ここで b=[B11B12B22B13B23B33]Thi=[hi1hi2hi3]Tvij=[hi1hj1hi1hj2+hi2hj1hi2hj2hi3hj1+hi1hj3hi3hj2+hi2hj3hi3hj3]T とすると、先程の制約式は次のように表される。 [vT12(v11−v22)T]b=0 未知パラメーターは b の6つのため、H が3つ以上つまりパターンを別角度から撮影した画像が3枚以上あればパラメーターを推定できる。 "},"computer_science/graphic/bezier_curve.html":{"url":"computer_science/graphic/bezier_curve.html","title":"ベジェ曲線","keywords":"","body":"ベジェ曲線（Bézier_curve） ベジェ曲線とはN+1個の制御点から得られるN次曲線である。 フォントなど大幅な拡大縮小が想定される画像の表現には3次ベジェ曲線が利用される。 定義 制御点をC0,…,CN+1とすると、ここから得られるN次曲線は次のように表される。 P(t)=N∑i=0CiBni(t)Bni(t)= nCiti(1−t)n−1=n!i!(n−i)!ti(1−t)n−i Bni(t)はバーンスタイン基底関数と呼ばれる。 3次ベジェ曲線の描画例 import matplotlib.pyplot as plt import numpy as np def bezier3(p0, p1, p2, p3, n): ts = [i/n for i in range(n)] ts.append(1) def f(t): a0 = (1-t)**3 a1 = 3 * (1-t)**2 * t a2 = 3 * (1-t)* t**2 a3 = t**3 return ( a0*p0[0] + a1*p1[0] + a2*p2[0] + a3*p3[0], a0*p0[1] + a1*p1[1] + a2*p2[1] + a3*p3[1] ) return map(f, ts) ps = list(bezier3((0,0),(0.3,0.3),(0.3,0),(1,0),100)) xs = list(map(lambda p: p[0], ps)) ys = list(map(lambda p: p[1], ps)) plt.plot(xs, ys) plt.xlim(0, 1) plt.ylim(0, 1) plt.show() "},"computer_science/graphic/3d.html":{"url":"computer_science/graphic/3d.html","title":"3D技術","keywords":"","body":"3D技術 ホログラフィー（holography） 通常の写真では光の振幅（明度）・周波数（色調）を記録しているのに対し、ホログラフィーは位相を記録する手法。 後述するステレオグラムなどは厳密にはホログラフィーとは異なる原理を利用しているが、近年は「空中に映像が浮かび上がる」技術のことを「ホログラム」と誤った呼び方をすることが多い。 原理 記録方法の一例として、コヒーレントなレーザー光を用いて物体の反射光と参照光の干渉縞をつくり、ある平面におけるそれを透明な記録媒体に記録する。 すると記録媒体はある種の回折格子になる。 この回折格子に参照光と同じ方向から光を当てると物体の反射光を再現するように光が屈折するため、物体を取り除いても物体がそこにあるかのように見える。 コヒーレント 位相が揃った干渉縞が観測しやすい波のこと。逆はインコヒーレント。 ホログラム（hologram） ホログラフィーにおける干渉縞を記録した記録媒体のこと。 ホログラフィックステレオグラム（holographic stereogram） ホログラフィーは干渉縞を利用するため撮影に厳密な条件が課される。 一方、ホログラフィックステレオグラムは様々な角度から撮影した2次元画像からホログラムを合成するものを指す。 場における光を再現するのではなく、視差を利用して立体視を実現している。 ステレオグラム（stereogram） 目の焦点を前後にずらして見ることで立体的に見ることができる平面に描かれた図・絵のこと。 3D映像方式 参考：http://bjns.blog113.fc2.com/blog-entry-54.html アナグリフ（anaglyph） 赤青メガネを通すことで立体視を可能にする技術。 赤色・青色のフィルターを通すことで右目画像・左目画像を見ることができる。 サイドバイサイド（side by side） 右目画像と左目画像を横に並べた記録方式。 基本的に交差法で正しく見えるよう右側に左目画像、左側に右目画像を配置することが多い。 現在最もメジャーな方法。 "},"computer_science/security/cipher_and_code.html":{"url":"computer_science/security/cipher_and_code.html","title":"暗号技術のすべて読書メモ","keywords":"","body":"暗号技術のすべて読書メモ セキュリティの6要素 OECD（経済協力開発機構）ガイドライン 機密性（Confidentiality） 意図した相手以外に情報が漏れないこと 完全性（Integrity） 届いた情報が正確であること（ノイズ・改竄に強いこと） 可用性（Availability） 必要な時点で利用できること（障害に強いこと） ISO/IEC TR13335ガイドライン 上3つに加えて 責任追跡性（Accountability） ユーザーの行動・責任を追跡できること 真正性（Authenticity） ユーザー、システムによる振る舞いが明確であること（なりすましに強いこと） 信頼性（Reliability） システムやプロセスが矛盾なく動作すること、一貫して動作すること 用語 平文：もとの文章 暗号文：もとの文章を暗号化したもの 平文空間：平文に利用される符号の集まり 暗号空間：暗号文に利用される符号の集まり オラクル：要求に対してデータを返すもの コンピューター以前の暗号 シーザー暗号（ROT3） コード 事前に辞書（符牒）を作る 第二次世界大戦時のアメリカ軍通信におけるナバホ語 スキュタレー暗号 n飛び読み 転置式暗号 n文字のブロックに分割し中で並び替え 単一換字式暗号 文字を1対1で置換 アルベルティの暗号円盤 頻度分析 多表式暗号 トマス・ジェファーソンの暗号筒 側面に26文字のアルファベットを刻んだ円盤を棒に差し込み、ある列を平文・別の列を暗号文にする ヴィジュネル暗号 26×26の表を用意し秘密鍵のk文字目と対応する位置の置換を表のk行目を用いて行う カシスキー法 パターンから秘密鍵の文字数を推測する 一致指数法 IC=∑25i=0Fi(Fi−1)N(N−1) の値から確率的に秘密鍵の文字数を推測する スーパーインポジション 同じ秘密鍵を利用した暗号文が複数あると同じ文字位置で同じ置換規則を使っていることが明らかなので頻度分析が可能になる エニグマ暗号 共通鍵暗号 記述 k：秘密鍵生成パラメーター m：平文 key：秘密鍵 c：暗号文 key = KeyGen(k)：秘密鍵生成アルゴリズム c = Enc(m, key)：暗号化アルゴリズム m' = Dec(c, key)：復号アルゴリズム 攻撃モデル 暗号文単独攻撃（Ciphertext Only Attack : COA） c*のみから解読 既知平文攻撃（Known Plaintext Attack : KPA） 複数の(m, c)の組と解読対象c*から解読 選択平文攻撃（Chosen Plaintext Attack : CPA） 暗号化オラクルへのアクセスと解読対象c*から解読 選択暗号文攻撃（Chosen Ciphertext Attack : CCA, CCA1） 復号オラクルへのアクセス（ただしc*の取得前にのみアクセス可能）と解読対象c*から解読 適応的選択暗号文攻撃（Adaptive Chosen Ciphertext Attack : CCA2） 復号オラクルへのアクセスと解読対象c*から解読 ブルートフォース攻撃 鍵全数探索攻撃 keyを総当りする方法 テーブル参照法 事前に暗号化オラクルを入手して(key, m, c)の組を大量に計算しておき、そこからの検索でkeyを見つける方法 タイムメモリトレードオフ 事前計算の結果からkeyの探索範囲を狭めてkeyを見つける方法 ショートカット攻撃 アルゴリズムの特性を利用して(m, c)の組の集まりからkeyを見つける方法 識別攻撃 mが持つ何らかの法則を見破ること 見破られたからといって即座にmからkeyを得ることが極端に簡単になったりはしないがヒントにはなるので、mとランダムビット列の識別不可能性はアルゴリズムの設計において重要視される 求められる性質 正当性 暗号文を復号すると元の平文に戻ること 秘匿性 暗号文から平文のヒントが一切得られないこと ケルクホフスの原理 秘密鍵以外がすべて漏れても秘匿性が保たれること P(M=m | C=c)=P(M=m) これを満たす暗号は平文より秘密鍵を短くすることはできない 識別不可能性 秘匿性をより詳細にした概念 keyがわからないときmがランダムビット列と区別できないこと 完全識別不可能性 確率分布が完全に一致すること 統計的識別不可能性 確率分布がほぼ一致すること 計算量的識別不可能性 確率分布が違ってもアルゴリズムから見て区別できないこと バーナム暗号 ケルクホフスの原理を満たす完全な共通鍵暗号。 key：ランダムなnビット列（n：平文の長さ） Enc/Dec：keyとの排他的論理和を取る ストリーム暗号 1ビット・1バイトなどの単位で暗号化を施す方法。 秘密鍵をシードに疑似乱数を生成したものを鍵ストリームとし、鍵ストリームとの排他的論理和を取る処理で暗号化・復号する。 つまり、鍵ストリームを秘密鍵にするのではなく疑似乱数のシードを秘密鍵とすることでバーナム暗号を扱いやすくしたものと考えればよい。 ブロック暗号 1ビット・1バイトよりも長いブロックと呼ばれる単位で暗号化を施す方法。 秘密鍵をシードに擬似乱数などで複数のサブキー（副鍵・拡大鍵・ラウンド鍵）を生成し、ブロックの暗号化に利用する。 平文がある程度の長さであればストリーム暗号より高速に動作する。 また後述のラウンド関数を正しく設計し秘密鍵を十分長くすれば平文・暗号文の組からサブキー・秘密鍵を特定するのは困難になるため、秘密鍵を固定してもそれが漏れない限りは安全といえる。 そのため、ICカード情報の暗号化（カードに秘密鍵を記録しておく）などに利用される。 Feistel構造 平文を左右に分割し、入れ替え・サブキーをシードとした処理（ラウンド関数）を複数回適用して暗号化する。 例 DES Camellia MISTY1 SEED SPN構造 Substitution-Permutation Network。 平文をいくつかのブロックに分割し、それぞれにサブキーをシードとした処理を施し、最後にそれらを非線形変換（単なる置換ではなく、あるビットを変化させると別の位置のビットも影響を受ける）で結合することで暗号化する。 例 AES ハッシュ関数 任意長の入力に対して固定長のハッシュ値を出力する関数。 求められる性質 高速な動作 一方向性（原像計算困難性） あるハッシュ値が得られたとき、対応する入力を見つけるのが困難であること 第2原像計算困難性 ある入力・ハッシュ値の組が得られたとき、同じハッシュ値が得られる別の入力を見つけるのが困難であること 衝突困難性 同じハッシュ値を持つような入力の組を1つ見つけるのが困難であること 近似衝突困難性 よく似たハッシュ値を持つ入力の組を効率的に特定できないこと 部分原像計算困難性 一部が欠けたハッシュ値から欠けた部分を特定するのが困難であること 安全性 入力が q パターン、出力が n パターンのとき、アルゴリズムが最良の場合でも q−n 組以上の衝突ペアが存在する（鳩の巣の原理）。 また、qn であったとしてもバースデーパラドックスの問題がある。 たとえば q=√n のとき、衝突ペアが存在する確率は0.3以上、q=1.18√n のとき0.5以上になる。 これを考慮すると、各性質を破るために必要な平均計算回数は以下のようになる。 性質 回数 一方向性 2n−1 回程度 第2原像計算困難性 2n−1 回程度 衝突困難性 2n/2 回程度 "},"computer_science/security/cyber-terrorism.html":{"url":"computer_science/security/cyber-terrorism.html","title":"サイバー攻撃","keywords":"","body":"サーバー攻撃 ネットワークを介して行われるクラッキングをサイバー攻撃という。 情報の狙い方による分類 スパイウェア（spyware） 寄生したマシン上のデータを収集し、配信者の元に報告するマルウェアをスパイウェアと呼ぶ。 狭義にはユーザーのインターフェース操作を記録し、情報を抜き出すソフトウェアを指す。 キーロガー キーボード入力を記録するスパイウェアを特にキーロガーと呼ぶ。 スニッフィング（sniffing） 盗聴、特にネットワークを流れる情報を抜き出すことで情報を盗む手法をスニッフィングと呼ぶ。 フィッシング（phishing） 偽装されたソフト・サービスを利用するユーザーが現れるのを待ち、そのユーザーから情報を抜き取る手法をフィッシングと呼ぶ。 fishingと綴りが異なるのは単なる言葉遊び。 攻撃方法による分類 踏み台攻撃 ゾンビマシン（後述）を利用して間接的に攻撃を行い、攻撃元を偽装する攻撃を踏み台攻撃という。 中間者攻撃（Man-in-the-middle：MITM attack） 通信開始の段階で通信の間に割り込み、双方の通信相手に成りすますことで情報を盗む攻撃を中間者攻撃という。 DNS偽装・証明書の検証不備による脆弱性・脆弱な暗号の解読などにより暗号化通信のセッションに割って入るため、通信者からは暗号化通信で保護されているように見える。 その他の用語 バックドア コンピュータに侵入するための非正規のルート（裏口）をバックドアという。 ルートキット 攻撃・潜入のために利用されるツール群のうち、ルート権限の確保・活動の隠ぺい・バックドアの設置など、攻撃者が継続的に活動できるような環境を作るものをルートキットと呼ぶ。 ゾンビマシン マルウェアに侵入され、遠隔操作できる状態になったマシンをゾンビマシンという。 \"役に立たなくなったもの・悪の手先になったもの\"といったニュアンス。 ランサムウェア（ransomware） 感染したマシンのファイルを暗号化し復号と引き換えに金銭を要求する身代金要求型ウイルスに用いられるマルウェアをランサムウェアという。 "},"computer_science/security/malware.html":{"url":"computer_science/security/malware.html","title":"マルウェア","keywords":"","body":"マルウェア（malware） 悪意のあるソフトウェアを総じてマルウェアと呼ぶ。 ウイルス（virus） マシン上のプログラム（実行ファイル）を書き換え、そのプログラムが実行されたときに他のプログラムを書き換えて感染していくものをウイルスと呼ぶ。 ユーザーが信頼しているプログラムの中に紛れるため、一度感染するとウイルス対策ソフトを用いない限り発見が難しい。 ワーム（worm） ネットワークを介して他のマシン上に自身を複製し増殖していくプログラムをワームと呼ぶ。 トロイの木馬（Trojan horse） ユーザーが欲しがるようなプログラムに偽装して配布され、インストール後に悪意のある動作をするプログラムをトロイの木馬と呼ぶ。 "},"computer_science/security/rsa.html":{"url":"computer_science/security/rsa.html","title":"RSA暗号","keywords":"","body":"RSA暗号 桁数の大きい合成数の素因数分解が困難であることを利用した公開鍵暗号の一種。 手順 巨大な素数 p,q と ϕ(pq)=(p−1)(q−1) と互いに素な自然数 e を準備する 通常は適当な素数として65537を e とする n=pqとする ed≡1  (mod ϕ(n)) となる最小の d を求める ed+kϕ(n)=1 となる d を求める e,n を公開鍵、d を秘密鍵とする 暗号化は c=me mod n 、復号化は m=cd mod n で行う n をビット表記にしたときの長さによってRSA-1024、RSA-4096などと呼ぶことがある。 近年の計算機性能の向上に伴い、現状ではRSA-4096が推奨されている（10進数で1000桁程度）。 原理 暗号化は次のように行うことにした。 c=me mod n ここで両辺に d をかけて cd=med mod n=m1+kϕ(n) mod n ここでオイラーの定理によると m,n が互いに素であれば mϕ(n) mod n=1 となるため cd≡m  (mod n) mn より復号化は次のように行えることがわかる。 m=cd mod n 例 e = 65537 n = 1517330236262917595314610888889322115651087080826711948897066340883208205571592392362650858571076247939805436226544833224526137582834770402681005343930059463684528957271778199162575053306238099823295117697031968370690372250916935800738698142103275969223264184374648246277564306900886005299731265812255274723175925185522344831066577166867786835955092059346244885587228196357297758371381557924676260190209536670230008561217008649261974735505203813478978893582292682827884118215872470401293272325715864815977064075988643101088355047954735427424641386870772845440782632933485165110172437511822736907550777817722248753671107339823410418938404382732079381329288400012929311347390423061254658780185245562668131009832293474920208834795460061115101364091252176594144096675899952570380792978037217747311595899301451192342027799533264325948876556110474850761538179748318187805312451895898751337975457949549497666542175077894987697085521882531938339334715190663665300179658557458036053188152532948734992896239950564081581184284728802682982779186068791931259198917308153082917381616147108543673346682338045309449569430550618884202465809290850964525390539782080230737593560891353558335337408957948041667929154230334506735825418239563481028126435029 p = 34111525225922333955113751419357677129436029651245533697825114748126342624744832960936498161825269430327019858323450578875242014583535842110912370431931233957939950911741013017595977471949767235426490850284286661592357779825212265055931705799916913817655743434497422993498931394618832741336247426815710164342599150990608143637331068220244525541794855651643135012846039439355101027994945120698530177329829213208761057392236875366458197098507252851244132455996468628957560178868724310000317011912994632328371761486669358065577269198065792981537378448324923622959249447066754504943097391628716371245206444816309511381323 q = 44481453884385518268018625442920628989497457642625668259648790876723318635861137128631112417617317160816537010595885992856520476731882382742220627466006460645416066646852266992087386855491152795237153901319521506429873434336969666536995399866125781057768075533560120399184566956433129854995464893265403724034960689938351450709950699740508459206785093693277541785285699733873530541918483842122691276322286810422297015782658645129421043160749040846216892671031156465364652681036828461619272427318758098538927727392459501761203842363017121432657534770898181975532066012149902177196510416802134121754859407938165610800223 c = 225549592628492616152632265482125315868911125659971085929712296366214355608049224179339757637982541542745010822022226409126123627804953064072055667012172681551500780763483172914389813057444669314726404135978565446282309019729994976815925850916487257699707478206132474710963752590399332920672607440793116387051071191919835316845827838287954541558777355864714782464299278036910958484272003656702623646042688124964364376687297742060363382322519436200343894901785951095760714894439233966409337996138592489997024933882003852590408577812535049335652212448474376457015077047529818315877549614859586475504070051201054704954654093482056493092930700787890579346065916834434739980791402216175555075896066616519150164831990626727591876115821219941268309678240872298029611746575376322733311657394502859852213595389607239431585120943268774679785316133478171225719729917877009624611286702010936951705160870997184123775488592130586606070277173392647225589257616518666852404878425355285270687131724258281902727717116041282358028398978152480549468694659695121115046850718180640407034795656480263573773381753855724693739080045739160297875306923958599742379878734638341856117533253251168244471273520476474579680250862738227337561115160603373096699944163 "},"computer_science/information_theory/abstract.html":{"url":"computer_science/information_theory/abstract.html","title":"概要","keywords":"","body":"情報理論 情報理論は情報分野におけるデータ容量の削減・通信の速度と確度の向上などの課題について数学的に議論する分野。 1948年にA.Shannonが提唱した情報源符号化理論が起源とされる。 シャノンの情報理論 graph LR 情報源 -->|message| 送信器 送信器 -->|signal| 通信路 通信路 -->|signal| 受信器 受信器 -->|message| 受信者 A[ ] -->|noise| 通信路 シャノンの情報理論では通信を上のようにモデル化する（シャノンの通信モデル）。 まず情報源（information source）から発生する通報（message）を送信器（transmitter）で符号化（coding）し信号（signal）として送り出す。 送り出された信号はノイズの影響を受ける通信路（channel）を通り、受信器（receiver）で復号（decoding）されたものを受信者が受け取る。 シャノンの情報理論では値と時間軸を離散化したディジタル情報源を仮定し、情報源から生じる通報を記号化したものを情報源記号と呼ぶ。 また、いくつかの情報源記号をまとめて符号化するとき、その単位をブロックと呼ぶ。 ある情報源記号を符号化したものを符号語という。 符号語を構成する記号は符号アルファベットと呼ばれる。 現代の計算機では実質的に0,1を符号アルファベットとする2ビット表現の符号語に置き換えることを符号化と呼んでいる。 情報源から生じる通報と受信者が受け取る通報は有限個の候補のいずれかが生じるという側面から一種の確率変数であるといえる。 シャノンは、確率の知識を利用して通報が持つ情報量を定義し、通信路や符号化手法の効率を数学的に論じた。 "},"computer_science/information_theory/entropy.html":{"url":"computer_science/information_theory/entropy.html","title":"情報量","keywords":"","body":"情報量 シャノンの情報理論の中で定義される情報量について言及する。 情報量（self-information） 定義 ある情報源記号 Ai の生起確率を P(Ai) としたとき I(Ai)=−logP(Ai) を Ai の情報量・選択情報量・自己エントロピーという。 対数の底は何を選んでも尺度が定数倍されるだけだが、ビット表現での利用を考えて 2 とすることが多い。 また、0log0 は定義されない値だが、limx→+0xlogx=0 であることから情報量の計算の際には 0log0=0 と定義する。 直観的にはその事象の「起こりにくさ」を情報量として定義しており、「起こりにくいことが起きた」という観測は情報量が多いものと考える（したがってそれが受信者の役に立つかどうかなどとは無関係である）。 情報量の性質 0≤P(Ai)≤1 であるため、情報量は常に 0∼∞ の値を取り、生起確率 P(Ai) が高くなるほど小さくなる（単調減少）。 また、事象 A1,A2 の情報量の和は I(A1)+I(A2)=−logP(A1)−logP(A2)=−logP(A1)P(A2)=I(A1∩A2) と表される。 つまり、ある事象同士の情報量の和は「それらの事象が同時に生じた」という情報が持つ情報量を表す。 平均情報量（シャノンの情報量・エントロピー）（Shannon entropy） 定義 確率空間 (Ω,A,P) の下での各事象の情報量の平均値 H を平均情報量・シャノンの情報量・エントロピーと呼ぶ。 H(A)=−∑Ai∈ΩP(Ai)logP(Ai) すなわち、平均情報量はある観測によって得られる情報量の期待値を示しており、観測結果の予測しにくさを示したものとも解釈できる。 平均情報量の性質 起こりうる事象の数を n とすると、このときの平均情報量は次の条件を満たす。 0≤H(A)≤logn H(A)=0 となるのは P(Ak)=1, P(Ai)=0  (Ai∈Ω, i=1,⋯,n)(i≠k) つまり起こる事象が確定しているとき、平均情報量は 0 である H(A)=logn となるのは P(Ai)=1/n  (i=1,⋯,n) のとき すべての事象が均等に起こりうるとき、平均情報量は最大になる（どれが起こるか最も事前に予測しにくい） 条件付きエントロピー（conditional entropy） 事象 Bj が観測された下での確率変数 A の条件付き確率 PAB(A|Bj) としたときのエントロピーは H(A|Bj)=−∑Ai∈ΩAPAB(Ai,Bj)logPAB(Ai,Bj) となり、これを Bj の生起確率も考慮して期待値を取ると H(A|B)=∑Bj∈ΩBP(Bj)H(A|Bj)=−∑Ai∈ΩA,Bj∈ΩBP(Ai,Bj)logP(Ai|Bj) となる。これを事象 Bi の下での条件付きエントロピーという。 結合エントロピー（joint entropy） 2つの系の結合事象 (Ai,Bj) が観測される確率（結合確率）を PAB(Ai,Bj)=PA(Ai)PB(Bj) とする。 このとき定義される H(AB)=∑Ai∈ΩA,Bj∈ΩBI(Ai,Bj)=−∑Ai∈ΩA,Bj∈ΩBPAB(Ai,Bj)logPAB(Ai,Bj) を結合エントロピーという。 条件付きエントロピー・結合エントロピーの性質 H(AB)=H(A|B)+H(B)=H(B|A)+H(A) 結合事象系 (A,B) の予測しにくさは系 A の予測しにくさと A が確定した状況での B の予測しにくさである、といったイメージ 0≤H(A|B)≤H(A)≤H(AB) H(AB)≤H(A)+H(B) 系 A,B が独立であるとき H(AB)=H(A)+H(B) 結合事象系 (A,B) の予測しにくさは系 A,B が独立であるときに最大となり、独立でないときは一方の結果からもう一方の結果を推測しやすくなるため結合エントロピーは小さくなっていく 相互情報量（mutual information） 以上の定義を用いて、実際の通信路で情報を送るケースについて考察する。 情報源（確率変数）A の観測結果を通信路で伝達するとき、雑音によりある確率で間違った情報が届くものとする。 届いた情報を通報と呼ぶことにする。 このとき、観測者から見れば「A の推測しにくさが通報 B によって多少緩和された」ことになり、観測の前後でエントロピーが減少している。 エントロピーの減少量は「通報によって得られた情報量」に対応しており、これを A と B の相互情報量と呼ぶ。 定義 確率変数 A,B について I(A;B)=H(A)−H(A|B)=∑Ai∈ΩA,Bj∈ΩBPAB(Ai,Bj)logPAB(Ai,Bj)PA(Ai)PB(Bi) で定義される情報量を相互情報量と呼ぶ。 相互情報量の性質 相互情報量は次の性質を満たす。 確率変数 A,B が独立であるとき (A,B)=0 通報 B と情報源 A に相関関係がなければ全く参考にならない 0≤I(A;B)≤H(A) 通報 B が届くことで情報源 A の推測しやすさは改善されるはずである I(A;B)=I(B;A)=H(A)+H(B)−H(AB) 確率変数 A,B について対称である "},"computer_science/information_theory/markov_source.html":{"url":"computer_science/information_theory/markov_source.html","title":"マルコフ情報源","keywords":"","body":"マルコフ情報源（Markov source） マルコフ情報源は最も基本的な記憶のある情報源（情報源記号の生起確率が前後の情報源記号に依存する情報源）である。 シャノンの情報理論以前から確率過程（stochastic process）の研究で提唱されていたマルコフ連鎖の概念を情報源に適用したものである。 定義 情報源記号の生起確率がその直前の m 個の情報源記号に依存するとき、これを m 重マルコフ情報源（mth-order Markov source）という。 特に m=1 のとき単純マルコフ情報源（simple Markov source）という。 状態遷移図・シャノン線図（state transition diagram / Shannon diagram） 情報源記号が n 個の m 重マルコフ情報源は nm の状態を持つことになる。 取りうる状態を S={s1,⋯,snm} としたとき、ある状態からある状態へ遷移するときの条件付き確率を行列表記したものを遷移確率行列という。 ⎡⎢ ⎢ ⎢ ⎢ ⎢⎣P(s1|s1)P(s1|s2)⋯P(s1|snm)P(s2|s1)P(s2|s2)⋯P(s2|snm)⋮⋮⋱⋮P(snm|s1)P(snm|s2)⋯P(sn|snm)⎤⎥ ⎥ ⎥ ⎥ ⎥⎦ また、これを図にしたものを状態遷移図またはシャノン線図という。 マルコフ情報源の平均情報量（エントロピー） 情報源記号を A={a1,⋯,an} とする n 元 m 重マルコフ情報源の平均情報量は次のように計算できる。 まず、遷移を無限回繰り返したときの各状態の生起確率（定常確率分布）を求める。 定常確率分布を uT=[P(s1)⋯P(snm)]、任意の初期状態を u∗ とすれば u=P∞u∗=PP∞u∗=Pu となるため、 ⎧⎨⎩(P−E)u=0∑ui=1ui≥0 を満たす u を求めればよい。 次に求めた定常確率分布 u=[P(s1)⋯P(snm)] を用いて H(A)=nm∑si∈SP(si)H(A|si)=−nm∑si∈SP(si)n∑aj∈AP(aj|si)logP(aj|si) を計算すれば平均情報量が求まる。 "},"computer_science/information_theory/discrete_channel.html":{"url":"computer_science/information_theory/discrete_channel.html","title":"離散通信路","keywords":"","body":"離散通信路（discrete_channel） 送信する情報が標本化・量子化されたディジタル情報であるようなノイズのある通信路について考える。 通信路行列 送信する符号アルファベットを A={a1,⋯,an} 受信する符号アルファベットを B={b1,⋯,bm} とおく。 記憶領域を持たない無記憶通信路を仮定する。 すると通信路の性質は「ai を送信したとき一定の確率で b1∼bn のいずれかが届く」という条件付き確率 P(bj|ai) で表現できる。 これを次のような行列で表記したものを通信路行列（channel matrix）という。 ⎡⎢ ⎢ ⎢ ⎢ ⎢⎣P(b1|a1)P(b1|a2)⋯P(b1|an)P(b2|a1)P(b2|a2)⋯P(b2|an)⋮⋮⋱⋮P(bm|a1)P(bm|a2)⋯P(bm|an)⎤⎥ ⎥ ⎥ ⎥ ⎥⎦ また、通信路行列と A の各符号アルファベットの生起確率がわかっていれば B の各符号アルファベットの生起確率が得られる。 ⎡⎢ ⎢ ⎢ ⎢ ⎢⎣P(b1)P(b2)⋮P(bm)⎤⎥ ⎥ ⎥ ⎥ ⎥⎦=⎡⎢ ⎢ ⎢ ⎢ ⎢⎣P(b1|a1)P(b1|a2)⋯P(b1|an)P(b2|a1)P(b2|a2)⋯P(b2|an)⋮⋮⋱⋮P(bm|a1)P(bm|a2)⋯P(bm|an)⎤⎥ ⎥ ⎥ ⎥ ⎥⎦⎡⎢ ⎢ ⎢ ⎢ ⎢⎣P(a1)P(a2)⋮P(an)⎤⎥ ⎥ ⎥ ⎥ ⎥⎦ 通信路の例 2元対称通信路（binary symmetric channel） 確率 p で正しい情報が伝達される通信路 [1−ppp1−p] 2元消失通信路（binary symmetric erasure channel） 確率 p で情報が判別不能になる通信路 [1−pp00p1−p] 通信路の伝達情報量（transinformation） 相互情報量での解説の通り、通信路を通ったあとの情報（通報）から得られる情報量（伝達情報量）は A,B の相互情報量として定義できる。 I(A;B)=H(A)−H(A|B)=n∑i=1m∑j=1P(ai,bj)log2P(ai,bj)P(ai)P(bj) 通信路容量（channel capacity） 通信路行列は通信路固有のものであるため変えることは困難だが、送信する符号アルファベット A の生起確率は符号化の方法によってある程度変えられる。 送信系列を変えたときの伝達情報量の最大値を通信路容量と呼び、次のように表す。 C=maxP(a)I(A;B) 例：通信路容量の例 2元対称通信路 通信路行列より、H(B|A)=−plogp−(1−p)log(1−p) である。 a0 の生起確率を P(a0)=w としたとき、 b0 の生起確率は P(b0)=P(a0,b0)+P(a1,b0)=(1−p)w+(1−p)(1−w) となる。 P(b0)=q と置けば、 H(B)=−P(b0)logP(b0)−P(b1)logP(b1)=−qlogq−(1−q)log(1−q) となるので I(A;B)=H(B)−H(B|A)=−qlogq−(1−q)log(1−q)+plogp+(1−p)log(1−p) f(x)=−xlogx−(1−x)log(1−x) は x∈[0,1] の範囲では x=1/2 で最大値 1 を取るため、q=1/2 を満たすとき伝達情報量は最大値 1+plogp+(1−p)log(1−p) を取る。 よって通信路容量 C=maxI(A;B)=1+plogp+(1−p)log(1−p) である。 2元消失通信路 a0 の生起確率を P(a0)=w としたとき、 b0,b1,b2 の生起確率は P(b0)=(1−p)w, P(b1)=(1−p)(1−w), P(b2)=p となり、 H(B)=−P(b0)logP(b0)−P(b1)logP(b1)−P(b2)logP(b2)=−(1−p)wlog(1−p)w−(1−p)(1−w)log(1−p)(1−w)−plogp=(1−p){wlogw+(1−w)log(1−w)}+(1−p)log(1−p) H(B|A)=−∑A,BP(Ai,Bj)logP(Bj|Ai)=−(1−p)wlog(1−p)−pwlogp −(1−p)(1−w)log(1−p)−p(1−w)logp=−plogp−(1−p)log(1−p) となる。よって I(A;B)=H(B)−H(B|A)=(1−p){wlogw+(1−w)log(1−w)}+(1−p)log(1−p) +plogp+(1−p)log(1−p)=−(1−p){wlogw+(1−w)log(1−w)} より w=1/2 のとき最大値は 1−p となる。 よって通信路容量 C=1−p である。 "},"computer_science/information_theory/coding.html":{"url":"computer_science/information_theory/coding.html","title":"符号化","keywords":"","body":"符号化 情報源を n 元符号に符号化した際の符号の性質について考える。 復習：シャノンの通信モデル graph LR 情報源 -->|message| 送信器 送信器 -->|signal| 通信路 通信路 -->|signal| 受信器 受信器 -->|message| 受信者 A[ ] -->|noise| 通信路 符号化に関する用語 一意な復号可能性 情報源と符号語が1対1に結びついているような符号を一意に復号可能な符号という。 例：一意に復号不可能な符号 s1 : 0, s2 : 00, s3 : 1 ブロック001を受信しても、{s1,s1,s3}と{s2,s3}の区別がつかない。 瞬時復号可能性 各符号語の最後尾の符号アルファベットを受信した時点で復号先が一意に決まるような符号を瞬時復号可能な符号という。 瞬時復号可能であるかは、枝に符号アルファベットを割り振った n 分木を描き、すべての情報源記号が葉ノードに位置するか確認することで判別できる。 瞬時に復号可能であるということは、受信した信号のバッファの使用量と判別アルゴリズムを最小限にできるということであり、実用上重要な概念である。 例：瞬時復号不可能な符号 s1 : 0、s2 : 01、s3 : 011、s4 : 0111 01110を1ビットずつ受信した場合、0（s1,s2,s3,s4）、01（s2,s3,s4）、011（s3,s4）、0111（s3,s4）、01110（s4 確定）と4ビット分のバッファが必要になる上、判別の効率が悪い。 クラフトの不等式（Kraft's inequality） 各符号語の長さが li  (i=1,⋯,n) となる r 元符号について、 瞬時復号可能である　⇔　∑ni=1r−li≤1 またこの不等式は一意に復号可能な符号が存在するための必要条件でもあることがマクミラン（B.McMillan）によって証明された。 ノイズのない通信路のための符号化 情報源符号化定理（source coding theorem / noiseless coding theorem） シャノンの第一基本定理とも。 情報源は次式を満たす平均符号長 L の 可逆 n 元符号に符号化できる。 H(S)=−∑Ai∈ΩP(Ai)lognP(Ai)≤L すなわち情報源を符号化する際、平均符号長は底を n としたときの平均情報量より長くなることを示している。 あるいは、通信速度が一定のノイズのない無記憶通信路（通信路容量：1）で伝達する情報量を最大化するような符号の平均符号長が ceil(H(S)) になることを示している。 逆に言えば、シャノンの情報量（エントロピー）は「情報源を n 元符号に符号化したときの最短の平均符号長」を情報量として捉えたものである。 符号の効率・冗長度 情報源符号化定理により最良の平均符号長は H(S) となる（実際は天井関数をかけたものになるがここでは無視する）ことを利用して、ある符号がどの程度効率的であるかを評価できる。 ある符号の平均符号長が L であるとき、η=H(s)/L を符号の効率、r=1−η=(L−H(s))/L を符号の冗長度と呼ぶ。 ノイズのある通信路のための符号化 通信路符号化定理（noisy-channel coding theorem） シャノンの第二基本定理とも。 シャノンによって提唱され、1954年にA.Feinsteinによって完全に証明された。 通信路容量 C のノイズのある無記憶通信路を通して速度 R の通信を行うとき、次の定理が成り立つ。 RC　⇔　誤り率を任意に小さくするような符号化が存在する つまり、適切な誤り訂正符号を用いて速度 C 以上の通信を行えばほぼ誤りなく情報を伝達できることを示している。 この定理を逆に用いれば、通信路容量は「その通信路を通して任意に小さな誤り率の通信を達成できる情報量の上限」であると言える。 ただし、誤り率を限りなく0に近づけるには符号長を長くする必要があり、それに応じて符号化のブロック長も長くなるため実用性は低下する。 "},"computer_science/information_theory/huffman_coding.html":{"url":"computer_science/information_theory/huffman_coding.html","title":"ハフマン符号化","keywords":"","body":"ハフマン符号化（Huffman coding） ハフマン符号化とは、1952年にA.Huffmanによって提案された、コンパクト符号を作成する手法を指す。 コンパクト符号（compact code） ある情報源記号とそれぞれの生起確率が与えられたとき、情報源符号化定理に基づいて平均符号長が最小になるように符号化したもの。可逆圧縮かつ記号と符号を1対1に紐付ける符号化としては最良のものを指す。 手順 情報源記号を n 進数に符号化することを考える。 ハフマン符号化では以下の手順に従って、枝に1桁の符号、葉ノードに情報源記号を持つ木を構築する。 情報源記号をそれぞれ1つの木とする 根の中から生起確率の小さいものを n 個選び、それらの生起確率の和を値とする親ノードを追加する 2の手順を繰り返し、全体が1つの木になったら終了する 例 6つの情報源記号を2進数に符号化する。 graph TD A[1.00] ---|0| B1[0.65] A[1.00] ---|1| B2[0.35] B1 ---|0| S1[S1 : 0.35] B1 ---|1| C1[0.30] B2 ---|0| S2[S2 : 0.20] B2 ---|1| S3[S3 : 0.15] C1 ---|0| S4[S4 : 0.15] C1 ---|1| D1[0.15] D1 ---|0| S5[S5 : 0.10] D1 ---|1| S6[S6 : 0.05] 情報源記号 符号 S1 00 S2 10 S3 11 S4 010 S5 0110 S6 0111 "},"computer_science/information_theory/error_detection_and_correction.html":{"url":"computer_science/information_theory/error_detection_and_correction.html","title":"誤り検出・訂正符号","keywords":"","body":"誤り検出・訂正符号 通信で生じた誤りを検出するまたは訂正するための冗長性を持たせた符号化手法について言及する。 この項目では2元符号を想定して話を進める。 パリティチェック（parity check） ブロックの後に検査用のビット（パリティビット）を1ビット追加することで誤り検出手法。 ブロックに含まれる1の数が奇数のときにパリティビットを1とする方式を偶数パリティ、偶数のときにパリティビットを1とする方式を奇数パリティという。 これは全体の1の数を偶数・奇数にする、という意味から名付けられている。 受信者はパリティビットを含めて1の数の偶奇を確認し、偶数（奇数）でなければ誤りを含むものと判断し、そのデータを棄却する。 パリティチェックは2箇所同時にエラーが生じる確率は低いという前提に立ったものであり、同じブロックで2箇所以上のエラーが生じるケースには対処できない。 チェックサム（checksum） ブロックの一部を切り取り、総和を取ったものをパリティビットとした誤り検出手法。 遇奇のみを調べるパリティチェックよりも広範囲のエラーを検出できる。 巡回冗長検査（cyclic redundancy check : CRC） 除算を利用したアルゴリズムから導かれる値をパリティビット（規格によって長さは変わる）とした誤り検出手法。 ブロック長や信頼度の設定に応じていくつかの規格が存在する。 CRCは今日のコンピューターのメインメモリに適用されており、メモリの読み出しの際にエラーを検出した場合はメモリコントローラーに警告付きでデータを返すようになっている。 MD5 MD5で得たデータブロックのハッシュ値を誤り検出用に添付する誤り検出手法。 計算コストが高いため回路レベルで利用されることはないが、データ通信などで利用される。 ハミング符号（Hamming code） 1950年にR.W.Hammingにより提案された誤り訂正符号。 ハミング符号はパリティビット列を追加することで、任意の符号語の組のハミング距離が一定値以上になるよう設計される。 これにより、エラーが検出されたときはハミング距離が最も近い符号語に戻すことでエラーを訂正する。 ハミング距離が h のハミング符号では h−1 個までのエラーを確実に検出でき、h/2 より小さい個数のエラーなら正しく訂正できる。 ハミング距離（Hamming distance） 2つの符号語を見比べたときの、符号アルファベットが異なるビットの総数。 "},"computer_science/architecture/floating_point_number.html":{"url":"computer_science/architecture/floating_point_number.html","title":"浮動小数点数","keywords":"","body":"浮動小数点数（floating point number） 主にコンピューターで小数を表すための数値表現手法。 原理 浮動小数点数では符号ビット・指数フィールド・仮数フィールドの3つで数値を保持する。 IEEE 754の仕様 基数2の基本形式のみを示す。 参考：https://www.csee.umbc.edu/~tsimo1/CMSC455/IEEE-754-2008.pdf 各部のビット長と指数バイアス値 符号：S 指数：E 仮数：T バイアス symbol b w t bias 単精度(float) 1bit 8bit 23bit 127 倍精度(double) 1bit 11bit 52bit 1023 四倍制度 1bit 15bit 112bit 16383 表現値 S E T 備考 qNan ∗ 2w−1（全部1） IEEEによる指定はなし エラーを出さず伝播する sNan ∗ 2w−1（全部1） IEEEによる指定はなし エラーを出す +∞ 0 2w−1（全部1） 0（全部0） −∞ 1 2w−1（全部1） 0（全部0） (−1)S×2E−bias×(1+2−t×T) ∗ 1∼2w−2 ∗ ケチ表現 (−1)S×21−bias×(0+2−t×T) ∗ 0 ∗ (−1)S×(+0) ∗ 0 0 符号付き0 "},"computer_science/architecture/turing_machine.html":{"url":"computer_science/architecture/turing_machine.html","title":"チューリングマシン","keywords":"","body":"チューリングマシン（Turing machine） チューリングマシンは1936年にチューリングにより提案された計算機モデル。 計算機の計算能力とその限界について理解するために仮定する単純なモデルであり、今日の研究でも広く利用されている。 構成要素 チューリングマシンは次の要素から構成される。 表面がセルで区切られておりその中に符号アルファベットを1つ書き込めるような無限に長いテープ セルに格納された符号アルファベットを読み書きできるヘッド マシンの状態を保持するレジスタ 形式的な定義 構成要素を数学的に記述すると次のようになる。 Q：状態を表す有限集合 X：テープに書き込まれうる符号アルファベットの集合 Σ⊂X：書き込む符号アルファベット δ:(Q∖F)×X→Q×X×{left shift,right shift(,no shift)}：関数 q0∈Q：初期状態 B∈X：空白を表す符号アルファベット F⊂Q：終了（Halt）状態の集合 動作 チューリングマシンの動作前には、テープの全てのセルになんらかの符号アルファベットが記録されており（初期入力）、ヘッドの初期位置とマシンの初期状態が与えられている。 この状態から以下の動作を1ステップとして繰り返すことで動作する。 状態レジスタ・現在のセルの値を読む 状態が終了状態であれば動作を停止する δ に従って、現在のセルに書き込みを行う・状態レジスタを変更する・テープをシフトさせる チューリングマシンの例 Q={q0,q1,q2,qf} X={0,1} Σ={1} q0={q0} B=∅ F={qf} δ は以下の表の通り。 現在の値\\状態 q0 q1 q2 0 q11R q01L qf1L 1 q21L q11R qf1R このチューリングマシンは次のような動作をする。 初期位置が1なら、初期位置の左のセルを1にして終了する 初期位置が0なら、初期位置の右側で初めて0が現れるセルまでを1で埋めて終了する 万能チューリングマシン（Universal Turing machine） あらゆるチューリングマシンの機能を再現するようなチューリングマシンが存在することがA.Turingによって示されている。 これを万能チューリングマシンと呼ぶ。 万能チューリングマシンは、テープの初期入力として他のチューリングマシンの性質とそのマシンへの入力データを記録しておき、それに従って動作するように設計される（エミュレータの原理）。 チューリング完全（Turing-complete） ある計算機のメカニズムが万能チューリングマシンと同等の計算能力を持つことをチューリング完全であるという。 一般的なプログラミング言語はすべてチューリング完全であるように設計されている。 またノイマン型コンピュータは記憶容量が無限であるときチューリング完全であると見なせる。 停止性問題（halting problem） あるチューリングマシンがある入力条件の下で有限時間内に動作を停止するかという問題を停止性問題という。 "},"computer_science/architecture/von_neumann-type_computer.html":{"url":"computer_science/architecture/von_neumann-type_computer.html","title":"ノイマン型コンピューター","keywords":"","body":"ノイマン型コンピューター（Von Neumann-type computer） ノイマンモデルとは、1945年にノイマンらにより提唱されたコンピューターの構成モデルを指す。 これに則って設計されたコンピューターをノイマン型コンピューターといい、現代のコンピューターのほとんどはノイマン型である。 ちなみに、フォン・ノイマンは理論分野を担当しジョン・エッカートとジョン・モークリーが技術分野を担当したとされるが、時代背景もあってノイマンひとりの名前で有名になったという事情があり、この名前を好んで使わない人もいる。 構成要素 演算装置 記憶装置 制御装置 特徴 プログラム内蔵方式（stored program computer） プログラム（命令）とデータをともに記憶装置に記録する ただし、自己書き換えコード（self-modifying code）はメンテナンスが複雑になるため、多くのプログラム（≒プログラミング言語）ではプログラム・データは区別する フォン・ノイマン・ボトルネック プログラム内蔵方式を採用しているため、制御装置と記憶装置の伝送速度がコンピューター全体のボトルネックとなる 線形記憶 メモリのセルはアドレスで管理され、ランダムアクセスが可能である 逐次制御 命令1つに対して後述する1つのステップを実行する形でプログラムを実行していく 低機能の機械命令セット 機械命令自体は四則演算・転送・条件分岐など低レベルのものに留め、汎用性を確保している チューリング完全性 記憶領域が十分確保されていればチューリング完全であるとみなせる 制御 制御装置は以下の手順を1ステップとしてプログラムを実行していく。 制御装置内のプログラムカウンタで指定されたアドレスの命令を記憶装置から読み出す（機械命令フェッチ） 命令を解読する（デコード） 命令のオペランド部に従って記憶装置からオペランドを読み出す 命令のオペコードに従って演算装置に演算を実行させる 結果を記憶装置に記録する 命令パイプライン（instruction pipeline） 制御装置は複数回のクロックで上記の1ステップを実行するが、見てわかるようにフェッチ・デコード・演算などの各回路は1ステップの中で1度しか利用されない。 そのため、ある命令の処理中に空いた回路でその次の命令の処理を開始しても問題ない。 これを命令パイプラインといい、現代のCPUほぼ全てで利用されている技術である。 "},"computer_science/architecture/glossary.html":{"url":"computer_science/architecture/glossary.html","title":"その他用語","keywords":"","body":"その他用語 ※そのうち1つずつの記事にするかも。 ヘテロジニアス・コンピューティング（heterogeneous computing） 異なる種類のプロセッサを組み合わせて構築したコンピュータシステムを用いて演算を行うこと。 CPUとGPUの併用などがこれに該当する。 プロセッサごとに異なるアーキテクチャが採用されることが多いため、それらを協調して動作させるには高度な技術が要求される。 "},"computer_science/network/computer_networks.html":{"url":"computer_science/network/computer_networks.html","title":"Computer Networks読書メモ","keywords":"","body":"Computer Networks読書メモ 1 INTRODUCTION computer network 自律的に動くマシンを互いに情報を交換できるよう接続したもの distributed system 独立したマシンを接続して構築されているが、ユーザーからは1つの大きなシステムと見なせるもの middleware 分散システムを実現するための統一的なモデルに基づいた機能を提供するソフトウェア ex) World Wide Web 1.1 USES OF COMPUTER NETWORKS ざっと読み飛ばした。 1.2 NETWORK HARDWARE transmission technologyとscaleの観点から分類できるが、この本では主にscaleの観点から解説する。 transmission technology broadcast 全員に伝送される、自分宛てでなければ破棄 point-to-point 送信元から特定の送信先にだけ伝送される 特に1対1ならunicasting scale Class Keywords Personal(PAN) PCと周辺機器の接続・Bluetooth Local(LAN) 1つの建物で完結しているネットワーク・AP(Access Point) / wireless router / base station・IEEE 802.11(WiFi)：無線、11~100Mbps・IEEE 802.3(Ethernet)：有線、100M~1Gbps・VLAN：1つのLANを複数のLANに分割する技術 Metropolitan(MAN) 都市間を結ぶネットワーク・cable TV network・IEEE 802.16(WiMAX) Wide(WAN) 国や大陸内を結ぶネットワークLANとの違いとして多くの場合はネットワークプロバイダーや電話会社が運営しており、異なる方式のネットワーク同士を結ぶことで構築されている・subnet：hostを結ぶswitching element / transmission lineの集まり（ip addressにおけるsubnetは派生的な意味）・VPN：WANを介した仮想的な専用ネットワーク・ISP network：Internet Service Providerが提供するネットワーク・衛星回線・routin algorithm：ルーターに用いるアルゴリズム Internetworks ネットワーク同士を結んで構築した巨大なネットワーク・network：subnet+hosts、実際は曖昧な意味で用いられることが多い。あえて定義するなら「単一の技術に基づく通信網とマシンの集まり」・gateway：network同士を結ぶ役割を担うハードウェア・ソフトウェア、異なる通信方式の変換機能を含む 1.3 NETWORK SOFTWARE 1.3.1 Protocol Hierarchies カプセル化・交換可能性のため、プロトコルを複数のlayerに分割する考え方が一般的。 peer 各layerのinstance マシン同士が通信しているとき、同じプロトコルでやり取りしているソフトウェア（ハードウェア）同士のこと network architecture layerと対応するprotocolの定義から定まる 1.3.2 Design Issues for the Layers 各layerの設計において留意すべき問題。 信頼性の問題 符号化における信頼性 error detection error correction ルーティング ある経路が使用不可であるとき、他の経路を使うようにする 進化(evolution)の問題 規模の拡大・新技術の投入に応じて各layerのプロトコルを差し替えることで対応する addressing/naming：ネットワーク内で送信元・送信先を特定すること internetworking：一度に送れる情報のサイズや情報へ順序を付加する方法などが異なるプロトコルのネットワークを繋げること scalable：ネットワークの拡大に柔軟に対応できること リソースの問題 なるべくマシン同士が干渉しないようなリソースの配分が必要 statistical multiplexing：統計に基づいて短い期間ごとに帯域を利用者（host）に振り分ける手法 flow control：高速な送信元から低速な送信先への送信をどうするか？ 送信元へ受信完了のフィードバックを返す手法がよく用いられる congestion（輻輳）：伝送路の飽和、当然処理しきれない分は破棄されることになる->再送が頻発するためいつまでたっても輻輳から回復できなくなる 輻輳を感知したら送信量を抑える方法がよく用いられる Quality of Services（QoS）：リアルタイム性が重視されるアプリの通信などに優先的に帯域を割り当てる仕組み（単にサービス品質の意味でも用いられる） セキュリティの問題 暗号化・信頼できる認証で対応 eavesdropping：立ち聞き・盗み聞き surreptitious changes：データの改竄 1.3.3 Connection-Oriented Versus Connectionless Service ネットワークアーキテクチャーはconnection-oriented / connectionlessの2つに分類できる。 Connection-oriented 電話に倣った設計 connection：connectionの確立->通信->connectionの破棄 チューブのような役割を果たす 送った順にデータが届く negotiation：message size / QoS requiredなどの取り決め 送信元・送信先・subnetで利用可能なものでなければならない 一方がproposeし他方がaccept / reject / counter-proposalのいずれかを返す方法が一般的 Connectionless 郵便に倣った設計 packet：network layerにおけるmessage store-and-forward switching：すべてのmessageを受け取ってから次のノードに流す手法 cut-through switching：受け取ったmessageから順次次のノードに流す手法 reliability：ここでは途中でデータが失われないことを指す reliable connection-oriented service message sequences message boundaryが固定 byte streams unreliable connection-oriented service 速度優先のアプリ（voice over IPなど）に利用可能 unreliable connectionless service datagram serviceとも呼ばれる 様々なnetworkで利用される reliable connection-oriented service acknowledged datagram serviceとも呼ばれる request-reply service server-client modelでよく用いられる Ethernetはreliableなものは提供していない。 1.3.4 Service Primitives 通信を利用するプロセスは規定された操作の集まり（primitives）でserviceへ指示を出す。 当然、serviceによってprimitivesは異なる。 多くの場合、protocolはOSの組み込みとして提供されるので、システムコールがprimitivesに相当する。 1.3.5 The Relationship of Services to Protocols serviceとprotocolは全く別の概念であり、完全に切り離して考えることができる。 service layerが上位のlayerに対して提供するprimitiveの集まり インターフェース protocol 同じlayerのpeer entityが交わすpacket / messageのフォーマット・意味を定義するルール layerの実装に関するルール 1.4 REFERENCE MODELS layered networksの具体例としてOSI参照モデルとTCP/IP参照モデルについて見ていく。 OSI参照モデルのprotocols自体は現在は使われていないが、そのmodel自体は広く用いられている。 TCP/IP参照モデルはmodelはあまり使われないが、protocolsは広く用いられている。 1.4.1 The OSI Reference Model 1983年にInternational Standards Organization(ISO)が統一的なprotocolを設計する先駆けとして提唱したモデル。 1995年に改定された。 OSIはOpen Systems Interconnectionの略。 OSI参照モデル自体はserviceやprotocolを定義するものではないので、network architectureではない。 The Physical Layer 1を送信したとき0ではなく1を受信するにはどうすればよいか、という問題に対処する データから電気信号への変換法、伝送レート、双方向に通信できるようにするか、通信開始・終了の方法、コネクターのピン数、ピンの役割などを規定する The Data Link Layer 通信時のエラーを確実に検出する機能を提供するのが主な役割 通信開始の方法も規定 入力データをdata framesに分解し、このframeを順に送信する reliable serviceの場合は受信後にacknowledgement frameを返信することで信頼性を確保する broadcast networkの場合、shared channelへのアクセスをどう制御するかも問題になる これに対処するためのsublayerとしてmedium access control sublayerがある The Network Layer subnetにおける処理を規定する どのようにpacketを送信元から送信先へ導くかのアルゴリズムを提供するのが主な役割 動的なルートテーブルの更新、初期接続時の動作、輻輳への対処、QoS機能の提供、protocolの異なるネットワーク同士の接続に関する問題（addressingの方法が異なる、packetサイズの上限を超えているなど）への対処などを担う broadcast networkの場合は話が単純なのでそんなに規定すべきことがない The Transport Layer transport layerより上のlayerは送信元と送信先の間でのみ機能するprotocol（end-to-end） 逆に1~3層は間のswitchやrouterなどの機材にも関与するprotocol セッション層からの入力データを必要なら分割してネットワーク層に流し、受取先ですべてが届いたかを確認する どのserviceを利用するかはconnection作成時に確認される error-free point-to-point channel トランスポート層が提供する典型的なservice 送った順にbyteが届く error-freeと言っても完全ではない（実用的に許容できる程度のエラー発生率であることを示す） broadcasting The Session Layer sessionを構築する（としか書かれてない） dialog control（対話制御） 誰が話す番か管理するためのprotocol token management 二人が同時に重要な操作を実行しないようtokenによって管理するためのprotocol synchronization 長い通信中にエラーが生じても途中回復できるようにチェックポイントを設ける The Presentation Layer 伝送される情報の文法・意味を定義する 内部データ表現が異なるマシン同士で通信するため、通信に用いる\"標準的な\"表現方法を設ける The Application Layer （役割については詳述されてない） HTTP(HyperText Transfer Protocol) WWWの基本的なprotocolとして利用されている 1.4.2 The TCP/IP Reference Model ARPANETの歴史とTCP/IP参照モデル DoD（アメリカ防衛省）をスポンサーとしたreserch networkとして発足 100以上の大学・機関の設備を結ぶネットワークに発展 後に衛星回線や無線回線を搭載するとき、既存のprotocolでは難しくなった そこで1974年に新しい参照アーキテクチャーとしてTCP/IP参照モデルが提唱された 1989年に改定 DoDの懸念としてソ連にARPANETを破壊されないかというものがあった そのため一部のhardwareが喪失してもロスタイムなく機能し続けることが求められた ファイルの送信から電話まで幅広い用途に対応できる必要があった The Link Layer OSI参照モデルのData Linkに相当 connectionless internet layerに対して下位層がどのようなserviceを提供すべきか定義したもの（当初はconnectionlessのみを想定していたため） ここまでの説明におけるlayerのようなはっきりした概念ではなかった The Internet Layer OSI参照モデルのNetworkに相当 hostがpacketを任意のnetworkに流し込め、個々のpacketが独立に相手に届けられるようなserviceを規定する インターネットでは公式のpacketのformat / protocolとしてIP(Internet Protocol)、その補助機能としてICMP(Internet Control Message Protocol)が規定されている The Transport Layer OSI参照モデルのTransportに相当 TCP(Transmission Control Protocol) reliable connection-oriented protocol / byte stream routing algorithmを内包する 低速な送信先に高速にデータ転送してパンクさせないための機能も含まれている UDP(User Datagram Protocol) unreliable connectionless protocol 正確さより迅速さが重要視されるときによく用いられる The Application Layer sessionやpresentationの機能もここに含まれる 多くのアプリケーションではこの辺りの機能はさほど肥大化しない TELNET：virtual terminal FTP：ファイル転送用のprotocol SMTP：電子メール用のprotocol DNS：動的名前解決 HTTP：WWWで重用されるprotocol RTP：音声・映像のリアルタイムな伝送を目的としたprotocol 1.4.3 The Model Used in This Book OSI参照モデルはmodelの説明に適しており、TCP/IP参照モデルはprotocolの説明に適している。 この本では折衷案として次のようなハイブリッドモデルに基づいて説明を進める。 Physical 電気信号などの異なる種類の媒体を通してどのようにbitを伝送するか Link 直接接続されているデバイス間において、どのように適度な信頼性を保ちつつ有限な長さのmessageを伝送するか Network 複数のlinkや小規模なnetworkをどのように繋げてnetworkとして機能させるか 目的地への経路探索などの機能を含む Transport Network層の伝送の信頼度を高める Application ネットワークを利用するためのprogramを提供する 1.4.4 A Comparison of the OSI and TCP/IP Reference Models 2つの参照モデルは、end-to-end serviceを提供するtransport層が存在しているなど共通する箇所もある一方で、いくつかの重要な違いがある。 OSI参照モデルはServices / Interfaces / Protocolsの3つの概念を支柱としている。 このモデルの功績はこの3つの概念の違いを明示したことにある。 service：そのlayerが何をするか（どうするかではない）を示す interface：上位layerがそのlayerに対してどのようなアクセスが可能であるかを示す（その際に必要なパラメーターの定義も含む） protocol：そのlayerの仕事内容（実装）を示す TCP/IP参照モデルはもともとこの3つの区別が曖昧で、OSI参照モデルよりlayerの透過性が悪い。 またOSI参照モデルは対応するprotocolの設計前に提案されたため、特定のprotocolによるバイアスがかかっていない。 逆にTCP/IP参照モデルは特定のprotocol群によるバイアスがかかっている上、透過性が悪いため他の実装に当てはまりにくいことがある。 一方でTCP/IP参照モデルは実際にprotocolを設計した経験を元に提案できたという利点がある。 例えばデータリンク層はもともとpoint-to-pointで設計されていたが、broadcastの出現と共に新たなsublayerが追加された。 そのほかにもsublayerが追加された例はいくつかあるらしい。 またOSI protocolは他のprotocolを利用するnetworkとの接続を想定していなかった。 OSI参照モデルはネットワーク層でconnection-oriented / connectionless両方に対応し、トランスポート層でconnection-orientedに対応している。 TCP/IP参照モデルはネットワーク層でconnectionlessに対応し、トランスポート層で両方に対応している。 ユーザーが実際に利用する際に参照するのはトランスポート層なのでOSIの仕様ではユーザーが選択することができなくなってしまっていることになる。 1.4.5 A Critique of the OSI Model and Protocols この本の第二版が出た頃（1989）にはOSI参照モデルとprotocol群が覇権を握ると主張する専門家が多くいたが、実際にはそうならなかった。 その要因は次のようにまとめられる。 Bad timing 「提唱->研究（活性期間1）->標準化->投資・普及（活性期間2）」（apocalypse of the two elephants：”標準化の定理”）の標準化の段階で破綻した 標準化が早すぎると早熟で失敗、標準化が遅すぎるとみんな他の技術に投資してしまう、標準化期間が短すぎると破綻してしまう OSI protocolsが登場したときにはすでにTCP/IP protocolsが教育・研究機関へ浸透しつつあった Bad technology serviceとprotocolsの定義が非常に複雑だった addressing, flow control, error controlが各layerで何度も登場した 批判の例として、Saltzerらがerror controlは上位layerで一括して行うべきであると指摘している Bad implementations 複雑なservece, protocolsの定義も相まって非常に重かった 対象的に、TCP/IP protocolsはBSDに非常によい実装がされた上で搭載されていた Bad politics TCP/IPはUNIXの1機能として認知されることになった OSIはヨーロッパの通信省による手先、といったイメージがあった イメージはともかく、官僚が推し進めようとする不適当な標準化は研究者やプログラマーには浸透しなかった 1.4.6 A Critique of the TCP/IP Reference Model ここまでにもちらほら出てきたように、TCP/IP参照モデルにもいくつか問題がある。 前述のように、service / interface / protocolの区別が不明瞭である 他のプロトコル群にあまり当てはまらない 例えばBluetoothをTCP/IP参照モデルで記述するのはほぼ不可能 リンク層がlayered protocolsにおけるlayerとしての体裁を保っていない どちらかと言えばinterfaceに相当する 物理層とデータリンク層の区別がない IP / TCP protocols以外は微妙なものが含まれたまま広まってしまった TELNETは10 char/secのテレタイプ端末にのみ対応しており、GUIやマウスには対応していないが、現在も使われている 1.5 EXAMPLE NETWORKS 1.5.1 The Internet The Internetは特定のprotocolsを用いるnetworkの集合体。 特定の誰かによって企画されたものでも制御されるものでもない。 これについて深く理解するためにThe Internetの歴史を紐解く。 The ARPANET 冷戦真っ只中の1950年代後半、アメリカ防衛省が核戦争の中でも利用可能な司令網を欲したことからARPANETの開発が始まった。 当時は司令に公衆電話網が用いられていたが、toll office->switching office->telephoneという階層構造になっていたため重要なtoll officeが破壊されると通信網が機能しなくなるという欠点があった。 1957 スプートニク・ショック 1958 アイゼンハワー大統領の命令に従いARPA(Advanced Research Projects Agency)設立 1960 DoDがRAND Corporationと契約 1964 RANDのPaul Baranがデジタルなpacket-switching技術を提唱 ペンタゴン事務局がAT\\&TとUS telephone monopolyにこれを作れないか依頼するも不可能だとされた 1967 イギリスのNPL(National Physical Laboratory)がネットワークのデモシステム開発研究を発表 ARPAのLarry RobertsがARPANETの構築に移る IMP(Interface Message Processors)にDDP-316、56kbpsのlineを利用 IMP-IMP、host-IMPの2つのprotocolを利用 1968 ARPAがBBNにsubnetの構築を依頼 1969 実験的ARPANETがUCLA,UCSB,SRI,Univ Utahの4拠点間で開通 1972 ARPANETが数十の拠点からなるネットワークに成長 ARPANETに衛星回線・無線ネットワークの追加実験、プロトコルに難があることが明らかに 1974 TCP/IP model / protocols開発 BSDにTCP/IPベースのsocket、種々のutilityが搭載される 1980s ARPANETに多くのLANが接続されるようになりネットワークが成長 DNS(Domain Name System)の実装 DoDと契約していない研究機関でも利用できるネットワークへの需要が高まる 1981 NSF(US National Science Foundation)が研究・教育機関を結ぶCSNET(Computer Science Network)を構築 1986 CSNETを再構成しNSFNET誕生 56-kbpsのlineを利用 6台のスーパーコンピューターを内包 fuzzball(LSI-11)をrouterに利用 初のTCP/IP WAN NSFNETのsecond backbone開発 IBM PC-RTをrouterに 光ファイバー448kbps -> 1.5Mbps ネットワークの商用利用を目的にNSFがMERIT,MCI,IBMに働きかけてANS(Advanced Networks and Services)を設立 1990 ANSがNSFNETを継承しANSNETに 45Mbps lineにアップグレード 様々な企業がIPサービスを利用するようになり、ネットワークビジネスの民営化の要請が高まる NSFがPacBell,Ameritech,MFS,Sprintと契約しNAP(Network Access Point)を構築 NAP各社が市場競争を繰り広げthe internetの基盤が構築されていった 1990s前半 WWW登場 1990s ヨーロッパでもEuropaNET,EBONEなどのネットワークが登場 Architecture of the Internet インターネットに接続するには、コンピューターをユーザーの契約したISPと接続する。 これによりネットワーク上の任意のコンピューターとpacketを送受できるようになる。 一般的な接続の方法は、ISPである電話会社と契約すること。 DSL(Digital Subscriber Line)の技術を用いれば既存の電話線をネット接続用のデジタル信号線として利用できる。 コンピューターはDSL modemを介して電話線と接続され、電話会社側ではDSLAM(Digital Subscriber Line Access Multiplexer)を用いて信号をpacketに変換する。 このネットワーク接続形態をdial upと呼ぶ。 ダイアルアップ接続では帯域が最大でも56kbpsまでに制限される。 逆にダイアルアップ接続を超える帯域を持つ接続方法をbroadbandと呼ぶ。 他には既存のケーブルTV回線を利用するCATVがある。 このとき家庭側のmodemはcable modem、基地局側のmodemはCMTS(Cable Modem Termination System)と呼ばれる。 近年は光ファイバーケーブルを利用したFTTH(Fiber to the Home)が広まっている。 モバイル回線としては3Gがある。 ユーザーのpacketがISPネットワークに流れ込む地点をPOP(Point of Presence)と呼ぶ。 POPとそれらの間を結ぶsubnetをISPのbackboneという。 異なるISPネットワーク同士はIXP(Internet eXchange Points)で接続されている。 このとき接続されるISPを各々peerと呼ぶ。 IXPは世界中の都市に設けられており、アムステルダムのIXPでは数百のISPが接続されており、数百Gbpsのトラフィックがある。 ISP間の契約は複雑化しており、インターネットにおいてpacketは必ずしも最短ルートを通るわけではない。 そこと契約するだけでインターネット全体へフルアクセスできるようになるような上位一握りのISPはTier1 ISPと呼ばれる。 GoogleやYahooのようなアクセスが集中する企業は内部にdata centerを持っている。 これらのdata centerとISPのbackboneはなるべく短い距離で接続されるように配慮されている。 近年、仮想マシンの普及などによりdata centerは集約される傾向も現れている。 また電気代も相当な額になるため電気代の安い土地に建設されるなどの事情もある。 ISPはすべてのマシンに固有のIPアドレスを与えるわけではなく、そのとき利用されているマシンにのみIPアドレスを与えることで使いまわしをしている。 IPアドレスが与えられたISPに接続されているマシンはすべてthe internetを構成する要素であると考えられる。 逆にintranetのようにthe internetではないinternetも存在する（あくまでprotocolsによって複数のsubnetが相互に接続されていればinternet）。 "},"computer_science/network/reference_model.html":{"url":"computer_science/network/reference_model.html","title":"参照モデル","keywords":"","body":"参照モデル OSI参照モデル 1977~1984年に策定されたOSI（Open Systems Interconnection）のために提唱された通信機能を階層構造に分割したモデル。 OSI自体は普及しなかったもののネットワークの解説のためによく用いられる。 layer explain 第7層 アプリケーション層 データの中身の構造を規定する 第6層 プレゼンテーション層 データの表現方法を規定する 第5層 セッション層 通信の開始から終了までの手順を規定する 第4層 トランスポート層 エラー訂正・再送制御など通信を保証する方法を規定する 第3層 ネットワーク層 通信経路の選択方法・中継方法を規定する 第2層 データリンク層 隣接する機器間での送受方法を規定する 第1層 物理層 ケーブル・コネクタなど物理的な規格を規定する TCP/IP階層モデル TCP/IPプロトコル群を説明するときに用いられる階層モデル。 OSI参照モデルの5~7層をまとめてアプリケーション層としている。 layer example アプリケーション層 FTP／HTTP／SMTP／DNS／SSL トランスポート層 TCP／UDP／SCTP／DCCP ネットワーク層 IP／ARP／ICMP ネットワークインターフェース層 Ethernet／ADSL 物理層 Ethernet／ADSL "},"computer_science/network/topology.html":{"url":"computer_science/network/topology.html","title":"トポロジー","keywords":"","body":"ネットワーク・トポロジー（network topology） ネットワークの構成要素である端末（station）・交換機（node）・伝送路（link）の幾何学的な関係を表したもの。 基本形態 スター型（star） 中央ノードから放射状に端末・ノードが接続された形態。 長所 各端末の伝送路が独立しているため端末の追加・削除を容易に行える 伝送路の故障の影響範囲が1つの端末のみになる 短所 中央ノードが故障するとネットワーク全体が影響を受ける リング型（ring） ノードを数珠つなぎにし、信号を一定の方向に一周させる形態。 長所 伝送路の総距離が短い 構築が比較的単純 比較的高速 短所 ノードが1つでも故障するとネットワーク全体が影響を受ける ノードの追加・削除のためにネットワークを停止させる必要がある 通常はネットワークを二重化しておき、故障点に最も近い両端のノードで信号を折り返すようにする。 バス型（bus） 1本の基幹伝送路に複数の端末がぶら下がるように接続された形態。 長所 構築が簡単 伝送路の総距離が短い 短所 輻輳が生じる ノードを挟まないため全ての端末に通信が漏洩しセキュリティ的に弱い メッシュ型（mesh） ノードが複数のノードと接続された形態。 特に完全グラフになっているものをフルメッシュという。 長所 通信経路が複数あるためトラフィックの変動に柔軟に対応できる 故障に対する冗長性がある ノードの追加・削除のためにネットワークを停止させる必要がある 短所 伝送路の総距離が長い ツリー型（tree） 根ノードに1本の基幹伝送路があり、そこから複数の伝送路を枝分かれさせ、先端に端末を置く形態。 長所 端末の追加・削除が容易 根からの情報発信に便利 短所 輻輳が生じる 端末同士の通信に制約が多い "},"computer_science/network/baseband.html":{"url":"computer_science/network/baseband.html","title":"ベースバンド伝送","keywords":"","body":"ベースバンド伝送 帯域（bandwidth） 一般に周波数の範囲のことを帯域という。 デジタル通信においては、伝送波の帯域が伝送路容量・ボーレートなどと関連を持つことから、曖昧に伝送速度を指すような意味で用いられることも多い。 ベースバンド（baseband） 伝送対象となる元の信号の帯域をベースバンドという。 ベースバンド伝送（ベースバンド方式） 元の信号をそのまま伝送する通信方式をベースバンド伝送という。 交流成分を増やせば長距離伝送での減衰が抑えられる一方、伝送路に求められる伝送帯域が高くなる、というトレードオフがある。 Pulse / NRZ / NRTZ 単純に0をLow、1をHighとしたもの RZ(Return to Zero) / RTZ 信号の変わり目の前に0[V]に戻す 複流（dipolar） 信号の中で±E[V]の二極信号を利用するもの バイポーラ（bipolar） 1の度に極性を入れ替えるRZ 差分 0と1のどちらかで極性を反転させるもの ダイコード（dicode） 0から1のとき+E[V]、1から0のとき-E[V]、1や0が連続するときは0[V]とするもの ダイパルス（dipulse） 正転のRZと反転のRZを1セットとしたもの バイフェーズ（biphase） 値が変化するなら信号の変わり目で立上り・立下りするようにしたRZ マンチェスタ（Manchester） バイフェーズを複流にしたもの MLT-3 差分を二極信号に拡張したもの 0と1のどちらかで0,±E[V]の間を遷移する "},"computer_science/network/ip_address.html":{"url":"computer_science/network/ip_address.html","title":"IPアドレス","keywords":"","body":"IPアドレス クラス IPアドレスには以下のようなクラス分けが存在する。 ただし、ほとんどのネットワークでクラスAは大きすぎクラスCは小さすぎるという問題が生じたことで、後述するCIDR記法などを利用して柔軟にアドレスを割り振るようになったため、現在はほとんど使用されない。 クラス 範囲 ネットワークアドレス長 ホストアドレス長 A 0.0.0.0 - 127.255.255.255(0-) 8 24 B 128.0.0.0 - 191.255.255.255(10-) 16 16 C 192.0.0.0 - 223.255.255.255(110-) 24 8 D 224.0.0.0 - 239.255.255.255(1110-) IPマルチキャスト専用 E 240.0.0.0 - 255.255.255.255(1111-) 予約済み（使われていない） CIDR（Classless Inter-Domain Routing） 上位何ビットをネットワークアドレスと見なすかをクラスに頼らずビット長で表現する手法。 記載する際にはIPアドレスに/24のような形で追記する。 特別なIPアドレス ループバックアドレス 自分自身を意味するアドレス。 127.0.0.0 ローカルIPアドレス（プライベートIPアドレス） 専門書の例示、LAN内のアドレスなどに利用するアドレス。 10.0.0.0 - 10.255.255.255 172.16.0.0 - 172.31.255.255 192.168.0.0 - 192.168.255.255 ネットワークアドレス ホスト部を0としたIPアドレス。 ネットワーク自体を指すアドレス。 ブロードキャストアドレス ホスト部を1としたIPアドレス。 ブロードキャスト（サブネットワーク内のすべての機器への一斉送信）のために用いられるアドレス。 "},"computer_science/network/ssh.html":{"url":"computer_science/network/ssh.html","title":"ssh","keywords":"","body":"ssh 暗号・認証を用いて安全にリモートコンピューターと通信するためのプロトコル。 実装はいくつかあるものの、最近はオープンソースのOpenSSHが一般的となっている。 sshにはパスワード認証と公開鍵認証の2種類がある。 パスワード認証 linuxユーザーのパスワードで認証を行う。 Clientが公開鍵を使って共通鍵を暗号化して送信し、Serverが復号することで共通鍵を共有する。 パスワードを解析されるリスクが比較的高いため、利用は推奨されない。 sequenceDiagram Client->>Server:Request Server->>Client:Send public key Client->>Server:Send encrypted common key Server->>Client:Notify Client->>Server:Send encrypted password 公開鍵認証 Client側で生成した秘密鍵・公開鍵で認証を行う。 事前にServer側に公開鍵を登録し、Client側がそれに対応する秘密鍵を持たなければ認証されない。 sequenceDiagram Client->>Server:Request Server-->Client:Compare public key Server->>Client:Send encrypted random number Client-->Server:Compare checksum "},"hpa/camera_mesurement.html":{"url":"hpa/camera_mesurement.html","title":"カメラ計測","keywords":"","body":"カメラを使った測量 概要 単眼カメラ1台で3次元平面内の座標を測量する手法について書いてみます。 鳥人間的には桁試験での桁のたわみ量を見るときとかに使えるのではないでしょうか。 準備するもの 単眼カメラ 1台 ペイントなど、画像中の画素座標を調べられるソフト マーカーとなるモノ 方法 測量する3次元平面を決める 桁試験なら桁がたわむときに通過する平面が測量対象になります。 マーカーの配置 "},"hpa/foil_bezier.html":{"url":"hpa/foil_bezier.html","title":"翼型のベジェ曲線表現","keywords":"","body":"翼型のベジェ曲線表現 翼型の外形を4つの3次ベジェ曲線で表現してみる。 描画 import matplotlib.pyplot as plt import numpy as np def bezier3(p0, p1, p2, p3, n): ts = [i/n for i in range(n)] ts.append(1) def f(t): a0 = (1-t)**3 a1 = 3 * (1-t)**2 * t a2 = 3 * (1-t)* t**2 a3 = t**3 return ( a0*p0[0] + a1*p1[0] + a2*p2[0] + a3*p3[0], a0*p0[1] + a1*p1[1] + a2*p2[1] + a3*p3[1] ) return map(f, ts) def bezier_params_to_points(upper, lower, front, rear, n): # 点数の割り振り part1 = abs(lower[0]) + 1 - lower[2] part2 = abs(lower[0]) + lower[2] part3 = abs(upper[0]) + upper[2] part4 = abs(upper[0]) + 1 - upper[2] total = part1 + part2 + part3 + part4 # 後縁下側 ps1 = list(bezier3( (lower[2], lower[0]), (lower[3], lower[0]), (rear[0], rear[1]), (1, 0), int(n * part1 / total))) # 前縁下側 ps2 = list(bezier3( (0, 0), (0, front[0]), (lower[1], lower[0]), (lower[2], lower[0]), int(n * part2 / total))) # 前縁上側 ps3 = list(bezier3( (0, 0), (0, front[1]), (upper[1], upper[0]), (upper[2], upper[0]), int(n * part3 / total))) # 後縁上側 ps4 = list(bezier3( (upper[2], upper[0]), (upper[3], upper[0]), (rear[2], rear[3]), (1, 0), int(n * part4 / total))) return (ps1, ps2, ps3, ps4) # 上端・下端の(y1, x2, x1, x3) upper = (0.11991, 0.13077, 0.38109, 0.67725) lower = (-0.015984, 0.0063793, 0.029729, 0.17167) # 前縁下側、前縁上側のコントロールポイント(y1,y2) front = (-0.011888, 0.041121) # 後縁下側、後縁上側のコントロールポイント(x1,y1,x2,y2) rear = (0.51552, 0.055408, 0.79526, 0.044435) n = 200 pss = bezier_params_to_points(upper, lower, front, rear, n) for ps in pss: xs = list(map(lambda p: p[0], ps)) ys = list(map(lambda p: p[1], ps)) plt.plot(xs, ys) plt.xlim(0, 1) plt.ylim(-0.4, 0.4) plt.show() xfoilの解析へ import subprocess # 上端・下端の(y1, x2, x1, x3) upper = (0.11991, 0.13077, 0.38109, 0.67725) lower = (-0.015984, 0.0063793, 0.029729, 0.17167) # 前縁下側、前縁上側のコントロールポイント(y1,y2) front = (-0.011888, 0.041121) # 後縁下側、後縁上側のコントロールポイント(x1,y1,x2,y2) rear = (0.51552, 0.055408, 0.79526, 0.044435) n = 200 pss = bezier_params_to_points(upper, lower, front, rear, n) pss[0].reverse() pss[1].reverse() ps = [] ps.extend(pss[0][:-1]) ps.extend(pss[1][:-1]) ps.extend(pss[2][:-1]) ps.extend(pss[3]) with open('test.dat', 'w') as f: f.writelines(map(lambda p: '%.4f'%p[0] + ' ' + '%.4f'%p[1] + '\\n', ps)) path2xfoil = r'C:\\Program Files\\XFOIL6.99\\xfoil.exe' proc = subprocess.Popen(path2xfoil, stdin=subprocess.PIPE) command = \"\"\"LOAD test.dat newfoil OPER ITER 100 VISC 8e5 PACC result.txt ASeq -5 20 0.5 QUIT \"\"\" proc.communicate(command.encode('utf-8')) "},"develop/device/steamvr_vive.html":{"url":"develop/device/steamvr_vive.html","title":"SteamVR / HTC Vive","keywords":"","body":"SteamVR / HTC Vive Steam SteamはアメリカのValve Corporationが開発・運営するゲーム配信プラットフォーム。 app storeやgoogle playなどと同様に 購入したゲームの端末間共有 ゲームのアップロード・インストール・アップデート 対戦ゲームのためのプラットフォーム などの機能を提供する。 SteamVR / HTC VIVE 概要 SteamVRはValveが台湾のHTC Corporationと提携・開発したPCゲーム用VRシステム。 HTC VIVEはSteamVR向けに提供されているデバイスの名称である。 （出典：http://ascii.jp/elem/000/001/147/1147736/） セットで購入すると ヘッドマウントディスプレイ ベースステーション x 2 コントローラー x 2 が付属している。 またオプションでVRトラッカーを購入できる。 これはリストバンドやモデルガンなどに固定することで任意のオブジェクトをトラッキングすることができる。 （出典：https://www.vive.com/jp/vive-tracker-for-developer/） 仕組み Outside-In型のトラッキングを行なっている。 ベースステーション2台が赤外線平面を順に上下方向・左右方向に走査させ、トラッキング対象に仕込まれたセンサーがそれを受信する。 具体的には 同期信号 x 2 （0μs, 400μs） 走査 （1222–6777μs） をベースステーション2台×縦横の4回行うのを1サイクルを繰り返しているらしい（参考：https://github.com/ashtuchkin/vive-diy-position-sensor）。 赤外線平面は一定の角速度で走査されるため、同期信号から走査の受信までの時間から位置を推定できる。 VIVEのHMDは内部に32個の赤外線受光素子が埋め込まれている。 SteamVR Tracking HDK https://www.triadsemi.com/product/steamvr-tracking-hdk/ トラッキング対象となるオブジェクトを作成するための開発キット。 基板を自作オブジェクトの中に仕込むことでVRトラッカーを自作できる。 "},"develop/device/cpu.html":{"url":"develop/device/cpu.html","title":"CPU","keywords":"","body":"CPU 主要メーカー Intel（アメリカ：カリフォルニア） Pentium Core Series AMD（Advanced Micro Device）（アメリカ：カリフォルニア） AMD Series ARM（Advanced RISC Machine）（イギリス：ケンブリッジ） ARM Microchip（アメリカ：アリゾナ） PIC Atmel（アメリカ：カリフォルニア） ※ 2016年に買収によりMicrochipの子会社化 AVR 用語 命令セット（instruction set / collection of instructions） CPUが解読・実行できる命令の集まりのこと。 命令セットの仕様はハードウェアレベルで実装されるため通常はプロセッサーごとに命令セットが異なる。 RISC（Reduced Instruction Set Computer） 比較的単純な回路で基本的な命令セットのみを実現するという設計方針。 CISC（Complex Instruction Set Computer） 複雑な回路でより多くの複雑な命令セットを実現するというという設計方針。 オペランドで指定するアドレスの個数による分類 0アドレス命令形式 1アドレス命令形式 2アドレス命令形式 3アドレス命令形式 セグメント方式 プログラムやデータをセグメントという可変な大きさのまとまりで管理するメモリ管理方式。 互換CPU・互換プロセッサー CPUにおける互換性とは命令セットが同じであることを指す。 x86 Intelが開発したマイクロプロセッサの命令セットアーキテクチャ。 1978年 Intel 8086・8088 16bitレジスタ・16bit外部データバス（8088は8bit）・20bitのアドレス指定（1MiBアドレス空間） 4つのセグメントレジスタ＋16bitでセグメントの切り替えなしに20bitのアドレス指定が行える https://www.intel.co.jp/content/dam/www/public/ijkk/jp/ja/documents/developer/IA32_Arh_Dev_Man_Vol1_Online_i.pdf x64 Intelが開発したx86の後継。 "},"develop/device/gpu.html":{"url":"develop/device/gpu.html","title":"GPU","keywords":"","body":"GPU関連の用語 GPUとは Graphics Processing Unitの略で画像処理を高速に実行できるよう設計されたコンピューターの構成要素のひとつ。 画像の描画に必要な演算を並列化し、高速に処理することができる。 主なGPU開発企業 ほぼ2社独占状態。 NVIDIA AMD 主なGPUシリーズ NVIDIA GeForce / AMD Radeon DirectX用に最適化されている。ゲーム向け。 NVIDIA Quadro / AMD FirePro OpenGL用に最適化されている。3DCGやCAD向け。 NVIDIA Telsa / AMD FireStream GPGPU（General-purpose computing on graphics processing units）向けに最適化されている。 NVIDIA Tegra モバイル用。 開発プラットフォーム CUDA（Compute Unified Device Architecture） NVIDIAが開発したGPUプログラミング向けの統合開発環境。 対応言語はC/C++に準拠（ただし、C++は一部の構文にのみ対応）したCUDA C/C++で、ファイル拡張子にはcu、cuhなどが用いられる。 CUDA 7の時点でラムダ式などC++11の一部の規格に対応済み。 その他、CUDA ToolkitというSDKが公開されている。 CUDA ToolkitにはC++のテンプレートプログラミングライブラリ（主にvectorとか）のThrustなどが含まれており、これらを通してCUDA以外の開発環境でもGPUの資産を利用することができる。 "},"develop/prolog/abstract.html":{"url":"develop/prolog/abstract.html","title":"概要","keywords":"","body":"Prolog Prologと述語論理 Prologは一階述語論理をベースにした言語だが、Horn節（Horn clause）と呼ばれる制約された論理式を対象としている。 環境 Prologには様々な処理系が存在するが、今回はSWI Prologで実行している。 Macならbrewからインストールできる。 インタプリタ swiplでインタプリタが起動する。 [filename].でファイルを読み込む。ファイル名に英数字以外の文字を含む場合は''で囲む。 [user].でインタプリタ上で質問以外の分を書くことができる。 Ctrl-dで書き込みを終了する。 halt.でインタプリタを終了する。 "},"develop/git/environment.html":{"url":"develop/git/environment.html","title":"自分用の設定","keywords":"","body":"Git 自分用のalias git config --global alias.st status git config --global alias.glog \"log --all --graph --date=short --decorate=short --pretty=format:'%Cgreen%h %Creset%cd %Cblue%cn %Creset%s'\" ちなみに設定ファイルは/etc/gitconfigに保存される。 "},"develop/python/environment.html":{"url":"develop/python/environment.html","title":"環境","keywords":"","body":"Python環境 Pythonインストール ここからインストールする。 pip pipはPythonのライブラリ（パッケージ）を管理するためのパッケージマネージャー。 主にPyPI（Python Package Index）に登録されているパッケージのインストールに利用する。 またWheel形式で配布されているパッケージのインストールもpipを通して行う。 python2まではeasy_installを介してpipをインストールする必要があったが、python3ではデフォルトで付いてくるのでインストールの必要はない。 Windowsでpipをつかうとき pipはクライアント側でソースコードをビルドしてパッケージをインストールするが、デフォルトでmakeに対応していないWindowsではビルドに失敗してインストールできないことがある。 もし環境に適合するwheelファイル（パッケージのバイナリを圧縮したもの）が配布されていれば手動でダウンロードし、pipコマンドで解凍・インストールできる。 iPython PythonのREPL環境用のパッケージ。 補完機能やシンタックスハイライトなどデフォルトのpython.exeより使い勝手がいい。 pipでインストールするとipython.exeが落ちてくるので、次からこれを使うようにすればいい。 "},"develop/python/matplotlib_template.html":{"url":"develop/python/matplotlib_template.html","title":"matplotlib template","keywords":"","body":"matplotlib template 2次元 折れ線 import matplotlib.pyplot as plt import numpy as np xs = np.arange(0.1, 10, 0.5) ys = 1 / xs plt.plot(xs, ys, c='blue', label='$y=\\\\frac{1}{x}$') plt.title('sample graph') plt.xlabel('x') plt.ylabel('y') plt.legend() plt.show() 散布図 import matplotlib.pyplot as plt import numpy as np rx = np.random.rand(50) ry = np.random.rand(50) plt.scatter(rx, ry, c='red', label='group1') bx = np.random.rand(50) by = np.random.rand(50) plt.scatter(bx, by, c='blue', label='group2') plt.title('sample graph') plt.xlabel('x') plt.ylabel('y') plt.legend(loc='upper right') plt.show() ヒストグラム import matplotlib.pyplot as plt import numpy as np # 平均 50, 標準偏差 10 の正規乱数を1,000件生成 xs = np.random.normal(50, 10, 1000) plt.hist(xs, bins=20) plt.title('sample graph') plt.xlabel('x') plt.ylabel('y') plt.show() 3次元 ワイヤーフレーム/サーフェース from mpl_toolkits.mplot3d import Axes3D import matplotlib.pyplot as plt import numpy as np def func(x, y): return x**2+y**2 x = np.arange(-10, 10, 0.1) y = np.arange(-10, 10, 0.1) X, Y = np.meshgrid(x, y) Z = func(X, Y) fig = plt.figure() ax = Axes3D(fig) ax.plot_wireframe(X,Y,Z) #ax.plot_surface(X,Y,Z) plt.show() "},"develop/python/matrix_operation.html":{"url":"develop/python/matrix_operation.html","title":"行列演算","keywords":"","body":"Pythonで行列演算 numpy.arrayとnumpy.matrixがあるが、numpy.arrayを使っている人が多い、というかnumpy.matrixの存在が空気になりつつある。 定義 A=⎡⎢⎣123456789⎤⎥⎦ import numpy as np A = np.array([[1,2,3],[4,5,6],[7,8,9]]) 加減算 A+B=⎡⎢⎣123456789⎤⎥⎦+⎡⎢⎣147258369⎤⎥⎦=⎡⎢⎣261061014101418⎤⎥⎦ A−B=⎡⎢⎣123456789⎤⎥⎦−⎡⎢⎣147258369⎤⎥⎦=⎡⎢⎣0−2−420−2420⎤⎥⎦ import numpy as np A = np.array([[1,2,3],[4,5,6],[7,8,9]]) B = np.array([[1,4,7],[2,5,8],[3,6,9]]) print(A + B) print(A - B) 積 import numpy as np A = np.array([[1,2,3],[4,5,6],[7,8,9]]) B = np.array([[1,4,7],[2,5,8],[3,6,9]]) print(np.dot(A, B)) # A*B にすると m_ij = a_ij * b_ij の行列ができてしまう 逆行列 A−1を求める時はnumpy.linalg.inv(A)を使う。 ただし、求めた逆行列を使ってA−1bを求めたいときはnumpy.linalg.solve(A,b)を使った方が高速になる模様。 参考：http://d.hatena.ne.jp/sleepy_yoshi/20120513/p1 import numpy as np A = np.array([[1,1,-1],[-2,0,1],[0,2,1]]) b = np.array([1,2,3]) print(np.linalg.inv(A)) print(np.linalg.solve(A, b)) "},"develop/python/juman_knp.html":{"url":"develop/python/juman_knp.html","title":"JUMAN/KNP","keywords":"","body":"JUMAN++ 京都大学の黒橋・河原研究室が開発した日本語の形態素解析ライブラリ。 言語モデルにRecurrent Neural Network Language Model(RNNLM)を採用しており、既存のMeCabなどより精度がよいと言われる。 install Linuxしか対応していないとのことなのでdockerで入れるのがよさそう。 dockerfile JUMAN++の方が高機能だが重いらしい。また、KNPはJUMANを入れていないとビルドできなかったので、とりあえず両方入れている。 FROM alpine:latest RUN apk add --update --no-cache wget boost-dev g++ make zlib-dev git \\ && cd ~/ \\ && wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/juman/juman-7.01.tar.bz2 \\ && tar xf juman-7.01.tar.bz2 \\ && rm juman-7.01.tar.bz2 \\ && cd juman-7.01/ \\ && ./configure \\ && make && make install \\ && cd ~/ \\ && rm -R juman-7.01/ \\ && wget http://lotus.kuee.kyoto-u.ac.jp/nl-resource/jumanpp/jumanpp-1.01.tar.xz \\ && tar xf jumanpp-1.01.tar.xz \\ && rm jumanpp-1.01.tar.xz \\ && cd jumanpp-1.01/ \\ && ./configure \\ && make && make install \\ && cd ~/ \\ && rm -R jumanpp-1.01/ \\ && wget http://nlp.ist.i.kyoto-u.ac.jp/nl-resource/knp/knp-4.17.tar.bz2 \\ && tar xf knp-4.17.tar.bz2 \\ && rm knp-4.17.tar.bz2 \\ && cd knp-4.17/ \\ && ./configure \\ && make && make install \\ && cd ~/ \\ && rm -R knp-4.17/ RUN apk add python3 \\ && cd ~/ \\ && python3 -m pip install six \\ && wget http://lotus.kuee.kyoto-u.ac.jp/nl-resource/pyknp/pyknp-0.3.tar.gz \\ && tar xf pyknp-0.3.tar.gz \\ && rm pyknp-0.3.tar.gz \\ && cd pyknp-0.3/ \\ && python3 setup.py install CMD sh pyknp pythonラッパー。ただし、python3ではうまく動かなかった。 以下はとりあえず構文解析だけ使う方法。 インストール cd pyknp-3.01 python3 setup.py install 使い方 from pyknp import MList import subprocess res = subprocess.Popen(\"echo '明日は晴れるだろう' | jumanpp\", shell=True, stdout=subprocess.PIPE).communicate()[0].decode('utf-8') ml = MList(res) for m in ml.mrph_list(): print(m.midasi) print(m.yomi) print(m.genkei) print(m.hinsi) print(m.hinsi_id) print(m.bunrui) print(m.bunrui_id) print(m.katuyou1) print(m.katuyou1_id) print(m.katuyou2) print(m.katuyou2_id) print(m.imis) print('----------') "},"develop/cpp/memo.html":{"url":"develop/cpp/memo.html","title":"メモ","keywords":"","body":"C++メモ エコシステム プリプロセッサ コンパイラーに投げられたソースコードはプリプロセッサに通され、#include、#defineなどのプリプロセッサディレクティブが処理される。 プリプロセッサを通った直後のソースコードはclang++ -E main.cppで見ることができる。 分割コンパイル すべてのリンクは行わず可能な範囲のリンク（stdとか）だけを行い、指定されたソースファイルに対応するオブジェクトファイルを生成する。 clang++ -c main.cppで実行できる。 アーカイブの作成 ar -r **.a {オブジェクトファイルを列挙}でアーカイブ（静的ライブラリ）が作成できる。 静的リンク clang++ {ソースファイル・オブジェクトファイル・ライブラリを列挙}で普通にコンパイルすると静的リンクが行われる。 動的リンク clang++ -dynamiclib **.cpp -o lib**.dylibで動的リンクライブラリを作成、clang++ -L{path to dylib} -l** main.cppで動的リンクを利用する実行ファイルを作成する。 配列の初期化 基本的に1つ1つ初期化する必要がある。 ただし、new int[20](){1, 2}のようにコンストラクタを使ったときは指定のない範囲は0で初期化される。 クラスと構造体 C++のclassとstructの違いはメンバーがデフォルトでpublicになるかprivateになるかだけ。 オブジェクト間の代入や値渡しはコピーになる。 引数 引数で値渡しをすると、コンストラクタは呼び出されないがデストラクタは呼び出される。 返り値として返す場合も一時オブジェクトが作成され、もとのオブジェクトにコピーした後、一時オブジェクトを廃棄する際にデストラクタが実行される。 そのため、内部で動的にメモリを確保しているオブジェクトを代入・値渡しするのは基本NG。 コピーコンストラクタをうまく使えばこの問題を回避できる。 フレンド関数 class myclass { int a; public: void set_a(int); int get_a(); friend int func(myclass); }; int func(myclass ob) { myclass ob2; //引数・関数の内部変数のmyclassのprivateメンバーにアクセスできる cout 共用体 複数の変数にメモリを共有させたもの。 型名を省略すると無名共用体となり、個々のメンバーはグローバル変数と同じ要領でアクセスできるようになる。 union hoge { double d; unsigned char bytes[sizeof(double)]; }; int main() { hoge obj; obj.d = 1.2345; for (int i = 0; i インライン関数 インラインに関する構文はあくまでコンパイラに対する「要求」であり、条件によってはインライン化されないこともある（static変数を参照している、switch文やgoto文を利用している、再帰しているなど）。 細かい部分はコンパイラ依存。 例1 inlineキーワードを使う。 class myclass { int a; public: void set_a(int); int get_a(); }; inline void myclass::set_a(int num) { a = num; } inline int myclass::get_a() { return a; } 例2 classの宣言内に直接書く。 class myclass { int a; public: void set_a(int num) { a = num; }; int get_a() { return a; }; }; "},"develop/cpp/file_string.html":{"url":"develop/cpp/file_string.html","title":"ファイル・文字列","keywords":"","body":"ファイル・文字列 文字列->数値 stringstreamを使うとよしなにしてくれるので楽。 #include #include using namespace std; int main() { stringstream ss; double d; ss > d; cout 文字列のフォーマット coutでフォーマットを指定するならboostを使わないといけない。 #include #include using namespace std; int main() { cout 面倒なのでstdio.hを使う方が無難ではある。 文字列のsplit boostにsplitがあるが、専用のAPIを覚えるのも面倒なので自前で実装する例を示す。 char区切り文字 #include #include using namespace std; template void split(const std::string& s, char delim, Enumerable& res) { res.clear(); std::stringstream ss(s); std::string item; while (std::getline(ss, item, delim)) { if (!item.empty()) { res.push_back(item); } } } string区切り文字 template void split(const std::string& s, const std::string& delim, Enumerable& res) { res.clear(); std::string::size_type prep = 0; while (prep != std::string::npos) { std::string::size_type p = s.find(delim, prep); if (p == string::npos) { res.push_back(s.substr(prep)); break; } else { res.push_back(s.substr(prep, p - prep)); } prep = p + delim.size(); } } ファイルから1行ずつ読み込み #include #include using namespace std; int main() { ifstream fr; string line; fr.open(\"input.txt\", ios::in); if (!fr.is_open()) cout "},"develop/cpp/bit_array.html":{"url":"develop/cpp/bit_array.html","title":"ビット配列を用いた演算","keywords":"","body":"ビット配列を用いた演算 C言語で大規模なフラグを管理するときに利用する。 C++ではbool[]を使えば良いが、boolは1変数あたり1byteが確保されるためそこそこ空間計算量に無駄がある。 この実装を使えばデータ容量を1/8程度に抑えられるため、空間計算量のオーダーを1つ弱下げることができる。 次のようなマクロを定義するのが鉄板らしい（C FAQという資料が出典？）。 // int型をバケットとし、バケットの配列 uint64_t[] で1つの整数を管理する // int型のビット数=バケット1つのサイズ #define BUCKET_BITS (uint64_t)(sizeof(uint64_t) * 8) // (b+1)番目のビットだけが1のバケットを返す #define BITMASK(b) (1ul "},"develop/cpp/sequential_process.html":{"url":"develop/cpp/sequential_process.html","title":"シーケンシャル処理","keywords":"","body":"シーケンシャル処理 に色々あるっぽい。 linqの遅延実行のような機能はないので、毎回結果を格納する領域を確保しておく必要がある。 all/any/none std::all_of,std::any_of,std::none_ofを使う。 #include #include int main() { int nums[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; if (std::all_of(nums, nums + sizeof(nums) / sizeof(int), [](int x) { return x >= 0; })) std::cout foreach 同じ配列上で処理を行う場合はstd::for_eachを使う。 #include #include int main() { int nums[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; std::for_each(nums, nums + sizeof(nums) / sizeof(int), [](int& x) { x *= 2; }); for (auto x : nums) std::cout map std::transformを使う。 変換先の領域は予め確保しておく必要がある。 戻り値は末尾ポインタ。 メモリの使用量が気になる場合はstd::vectorへコピーして後からresizeで縮める。 #include #include int main() { int nums[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; char chs[10]; char* end = std::transform(nums, nums + sizeof(nums) / sizeof(int), chs, [](int x) { return 'a' + x; }); std::for_each(chs, end, [](char x) { std::cout filter std::copy_ifを使う。 map同様にコピー先の領域は予め確保しておく必要がある。 戻り値は末尾ポインタ。 #include #include int main() { int nums[] = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; int odds[10]; int* end = std::copy_if(nums, nums + sizeof(nums) / sizeof(int), odds, [](int x) { return x % 2; }); std::for_each(odds, end, [](int x) { std::cout if & erase forとeraseを組み合わせる。 #include #include int main() { std::vector nums = {0, 1, 2, 3, 4, 5, 6, 7, 8, 9}; for (auto it = nums.begin(); it != nums.end();) { if (*it % 2 == 0) it = nums.erase(it); else it++; } for (auto n : nums) std::cout "},"develop/cs/dotnet_history.html":{"url":"develop/cs/dotnet_history.html","title":".Netの歴史","keywords":"","body":".Netの歴史 History 1990s Next Generation Windows Services(NGWS)の名前で.NET Frameworkの開発が進む ------------------------------------------------------------------------------------------------------ 2000-06 \"a new platform based on Internert standards\"として.NET Framework発表 2000-12 Common Language Infrastructure(CLI/共通言語基盤)の仕様が公開される -> ソフトウェアベンダーXimian(ジミアン)のミゲル・デ・イカザが関心を持ちMono Projectを開始 ------------------------------------------------------------------------------------------------------ 2001 .NET 1.0 beta released 2001-07-19 Mono Projectがオープンソース化 -> 少人数ではリソースが足りないとの判断から ------------------------------------------------------------------------------------------------------ 2002-02-13 .NET 1.0 released ------------------------------------------------------------------------------------------------------ 2003-04-24 .NET 1.1 released 2003-08 XimianがNovellに買収される ------------------------------------------------------------------------------------------------------ 2004-06-30 Mono 1.0 released -> C#1.0対応 ------------------------------------------------------------------------------------------------------ 2005-11-07 .NET 2.0 released ------------------------------------------------------------------------------------------------------ 2006-11-06 .NET 3.0 released 2006-11-09 Mono 1.2 released -> C#2.0対応 ------------------------------------------------------------------------------------------------------ 2007-11-19 .NET 3.5 released ------------------------------------------------------------------------------------------------------ 2008-10-06 Mono 2.0 released -> C#3.0対応 ------------------------------------------------------------------------------------------------------ 2009-01-13 Mono 2.2 released 2009-03-30 Mono 2.4 released 2009-12-15 Mono 2.6 released ------------------------------------------------------------------------------------------------------ 2010-04-12 .NET 4.0 released 2010-09-22 Mono 2.8 released -> C#4.0対応 ------------------------------------------------------------------------------------------------------ 2011-04 NovellがAttachmateに買収されMono Projectの中心メンバーがレイオフ(解雇)される 2011-05 -> 一部のメンバーによりXamarin設立 ------------------------------------------------------------------------------------------------------ 2012-08-15 .NET 4.5 released 2012-10-18 Mono 3.0 released -> C#5.0対応 2012-12 Xamarin.Mac released ------------------------------------------------------------------------------------------------------ 2013-02 Xamarin 2.0 released -> Xamarin.Android/Xamarin.iOS/Xamarin Studio/Xamarin for Visual Studio 2013-10-17 .NET 4.5.1 released 2013-11 XamarinとMicrosoftがパートナーシップを結ぶ ------------------------------------------------------------------------------------------------------ 2014-05-05 .NET 4.5.2 released 2014-05-28 Xamarin 3.0 released -> Xamarin.Forms 2014-11-12 Visual Studio Community 2013 released -> Expressの機能に加え、拡張機能・プロジェクトテンプレートなどが利用可能に 2014-11 .NET Core公開/オープンソース化 ------------------------------------------------------------------------------------------------------ 2015-04-29 Mono 4.0 released -> .NET4.5/C#6.0対応 2015-07-20 .NET 4.6 released 2015-11-30 .NET 4.6.1 released ------------------------------------------------------------------------------------------------------ 2016-02-24 MicrosoftがXamarinを買収 -> Xamarin製品が無償化/オープンソース化 2016-06-27 .NET Core 1.0 released 2016-08-02 .NET 4.6.2 released 参考： http://en.wikipedia.org/wiki/.NET_Framework_version_history#ASP.NET http://en.wikipedia.org/wiki/Mono_(software)) http://en.wikipedia.org/wiki/Xamarin http://ascii.jp/elem/000/001/156/1156721/ "},"develop/gitbook/my_setting.html":{"url":"develop/gitbook/my_setting.html","title":"自分用の設定","keywords":"","body":"GitBook 自分用の設定 Plugin mathjax-commonhtml gitbook-plugin-mathjaxを使うとmathjax形式になってしまうため、htmlにレンダリングしてくれるものを採用。 mermaid-2 Atomのmarkdown-preview-enhancedと互換性を保つため、タグではなくコードブロックを使いたかった。 expandable-chapters SUMMARYでインデントをつけると、レンダリングしたときに折りたたみできるようになる。 search-pro マルチバイト文字の検索・検索結果のハイライトの機能追加。 導入方法 node: v7.10.0 npm: 4.2.0 GitBook CLI version: 2.3.0 GitBook version: 3.2.2 mathjax-commonhtml: 0.0.6 expandable-chapters: 0.2.0 mermaid-2: 0.0.3 search-pro: 2.0.2 book.jsonに次の記述を追加する。 { \"plugins\":[\"mathjax-commonhtml\",\"expandable-chapters\",\"mermaid-2\",\"-lunr\",\"-search\",\"search-pro\"] } 次にプラグインをインストールする。 gitbook install ただし、なぜかmermaid-2だけはこれではうまく動作しなかった。 ので、mermaid-2だけnpmコマンドから直接インストールしておく。 npm install gitbook-plugin-mermaid-2 インストール後、index.jsの33行目あたりに1行追加する（参考）。 js: [ 'bower_components/mermaid/dist/mermaid.min.js', 'plugin.js' ] 以上。 "},"develop/keyboard/my_setting.html":{"url":"develop/keyboard/my_setting.html","title":"自分用の設定","keywords":"","body":"自分用のキーボード環境 Windows キーボードドライバーの設定をUSにしてFILCO Majestouch MINILA USを使用。 日本語入力はMicrosoft IMEをそのまま使用。 Macbook US配列のMacbookを使用。 システム環境設定 > キーボード > キーボード Macbook内蔵キーボード caps lock -> command control -> caps lock command -> control copy, paste, undoなどにaの隣のキーを使うため MINILA control -> command command -> control キーボード側でcaps lockとcontrolを交換してあるので、こう設定しておけば上と同じ要領で使える iTerm > configuration control -> command command -> control キーボードドライバーの設定を逆転させて元に戻してある コマンド中止（ctrl-c）や zsh のショートカット（ctrl-rとかctrl-p/ctrl-nとか）にaの隣のキーを使うため iTerm のショートカット（タブ操作等）はcommandで実行することになる 日本語入力 Google日本語入力をインストール（ことえりは予測変換がイケてない） システム環境設定 > キーボード > 入力ソース 「ABC」と「ひらがな（Google）」を選択 再起動しないとひらがながうまく認識されなかった 英・かなをインストール キーボードの左commandを英、右commandをかなに割り当て キーボードドライバーでcontrolとcommandを入れ替えてあるので画面上では「control L」「control R」と表示される システム環境設定 > キーボード > ショートカット > 入力ソース 「前の入力ソースに切り替え」にoption-` を割り当て MINILAには右スペシャルキーが存在しないので、US配列デフォルトのalt-` で入力ソースを切り替えられるようにしておく "},"develop/others/size_of_primitive_types.html":{"url":"develop/others/size_of_primitive_types.html","title":"プリミティブ型のサイズ","keywords":"","body":"プリミティブ型のサイズ C++ Configured with: --prefix=/Library/Developer/CommandLineTools/usr --with-gxx-include-dir=/usr/include/c++/4.2.1 Apple LLVM version 8.1.0 (clang-802.0.42) Target: x86_64-apple-darwin16.7.0 Thread model: posix #include #include using namespace std; int main() { cout sizeof(int) : 4 INT_MAX : 2147483647 sizeof(long) : 8 LONG_MAX : 9223372036854775807 sizeof(long long) : 8 LLONG_MAX : 9223372036854775807 rust rustc 1.19.0 (0ade33941 2017-07-17) use std::mem::size_of; fn main() { println!(\"size of i32 : {}\", size_of::()); println!(\"max value of i32 : {}\", i32::max_value()); println!(\"size of i64 : {}\", size_of::()); println!(\"max value of i64 : {}\", i64::max_value()); println!(\"size of isize : {}\", size_of::()); println!(\"max value of isize : {}\", isize::max_value()); } size of i32 : 4 max value of i32 : 2147483647 size of i64 : 8 max value of i64 : 9223372036854775807 size of isize : 8 max value of isize : 9223372036854775807 python 3系からはサイズに上限がなくなった（ただし当然ながらfloatのサイズには上限がある）。 "},"develop/others/arbitrary-precision_arithmetic.html":{"url":"develop/others/arbitrary-precision_arithmetic.html","title":"任意精度演算","keywords":"","body":"任意精度演算（arbitrary-precision arithmetic） 任意精度演算とは数値の精度を任意に設定できるような演算システムによる演算を指す。 通常の命令セットに組み込まれている32bit/64bitの整数・浮動小数点数では扱えない桁数の大きな数値を扱うために利用する。 プロセッサーのアキュムレーターではなくソフトウェア的な実装によって演算を行うためパフォーマンスは低下する。 主な利用目的として公開鍵番号方式の実装などがある。 使用例 多倍長整数 rustの場合はrust-numにBigIntがあるのでこれを使う。 現状decimalは公式には出ていない。 extern crate num; use num::bigint::BigInt; use std::io::{stdin, stdout, Write}; fn main() { let mut s1 = String::new(); let mut s2 = String::new(); print!(\"Please enter first number : \"); let _ = stdout().flush(); stdin().read_line(&mut s1).expect( \"Did not enter a correct string\", ); print!(\"Please enter first number : \"); let _ = stdout().flush(); stdin().read_line(&mut s2).expect( \"Did not enter a correct string\", ); match (s1.trim().parse::(), s2.trim().parse::()) { (Ok(n1), Ok(n2)) => println!(\"{}\", n1 + n2), _ => println!(\"parse faild\"), } } extern crate num; use num::bigint::BigInt; use num::bigint::ToBigInt; fn main() { let n = 1202303.to_bigint().unwrap(); let m = 1134523.to_bigint().unwrap(); println!(\"{}\", n * m); } C++の場合はGMP（GNU Multiple Precision Arithmetic library）というライブラリがある。 brew install gmp g++ main.cpp -lgmpxx -lgmp #include #include using namespace std; int main (void){ mpz_class a, b; a.set_str(\"1231345234523\", 10); b.set_str(\"2352342347856\", 10); a += b; cout 任意精度浮動小数点数 pythonのdecimalは任意精度演算に対応している。 from decimal import Decimal a = 32 - (54.2 - 52.0) / 0.1 b = int(32 - (54.2 - 52.0) / 0.1) #数値で書いた時点で基数2に変換されてしまうので文字列からdecimalに変換する c = 32 - (Decimal('54.2') - Decimal('52.0')) / Decimal('0.1') print(a, b, c) 9.999999999999972 9 10 C++とGMP。 表示にはC用のAPIを使うしかないっぽい。 #include #include using namespace std; int main (void){ mpf_class a, b; a.set_str(\"12313452.34523\", 10); b.set_str(\"235.2342347856\", 10); a += b; mpf_out_str(stdout, 10, 0, a.get_mpf_t()); cout "},"develop/others/ansi_escape_sequences.html":{"url":"develop/others/ansi_escape_sequences.html","title":"ANSIエスケープシーケンス","keywords":"","body":"ANSIエスケープシーケンス（ANSI escape sequences） ANSIエスケープシーケンスとはAmerican National Standards Instituteに規定されているターミナルの表示を細かく操作するための特殊コマンドの集まりを指す。 ターミナルによっては対応していないことも多い。 特にWindows周りはだめっぽい。 Cygwin+TeraTermなら一応動作するらしい。 CSI（Control Sequence Introducer） 下記の形式で表現されるコマンド群をCSIと呼ぶ。 ESC[n1;n2;... なおESCはASCII文字の27,0x1bに相当する。 主なCSI コマンド 動作 \\x1b[ n A 上にnカーソル移動（省略すると1） \\x1b[ n B 下にnカーソル移動（省略すると1） \\x1b[ n C 右にnカーソル移動（省略すると1） \\x1b[ n D 左にnカーソル移動（省略すると1） \\x1b[ n E n行下の行頭へカーソル移動（省略すると1） \\x1b[ n F n行上の行頭へカーソル移動（省略すると1） \\x1b[ n G 左端からnの位置へカーソル移動（左端が1、省略すると1） \\x1b[ n ; m H or f 上からn、左端からmの位置へカーソル移動（上・左端が1、省略すると1） \\x1b[ n J 画面消去 0:カーソルより後ろ 1:カーソルより前 2:全体（省略すると0） \\x1b[ n K 行消去 0:カーソルより後ろ 1:カーソルより前 2:全体（省略すると0） \\x1b[ n S n行文次にスクロール（省略すると1） \\x1b[ n T n行文前にスクロール（省略すると1） \\x1b[ n m SGRパラメーターの設定（色を変えたり色々できる） 主なSGRパラメーター 対応されてないことが多いものもちらほら。 コマンド 動作 \\x1b[0m パラメーターリセット \\x1b[1m 太字指定 \\x1b[2m 薄くする \\x1b[3m イタリック \\x1b[4m アンダーライン \\x1b[5m 点滅 \\x1b[6m 高速点滅 \\x1b[7m 色反転 \\x1b[8m 隠し文字（コピペすると見える） \\x1b[9m 取り消し \\x1b[30m~\\x1b[37m 色指定（黒 赤 緑 黄 青 マゼンタ シアン 白） \\x1b[38m 拡張色指定 カラーインデックス:5;x RGB:1;r;g;b \\x1b[39m 文字色リセット \\x1b[40~\\x1b[47 背景色指定（黒 赤 緑 黄 青 マゼンタ シアン 白） \\x1b[48m 拡張背景色指定 カラーインデックス:5;x RGB:1;r;g;b \\x1b[49m 背景色リセット 使用例 1行目に緑で「n%」2行目にプログレスバーを描画するプログラム。 #include #define PROGSTEP 5 using namespace std; int main (){ cout 14% |=== | "},"develop/others/interprocess_communication.html":{"url":"develop/others/interprocess_communication.html","title":"プロセス間通信","keywords":"","body":"プロセス間通信 手法 プロセス間でデータをやり取りするための手法はいくつか存在する。 基本的にOS依存のため、特定のOSで動作しなかったりAPIが異なったりする。 メッセージキュー ソケット パイプ セマフォ 共有メモリ メモリマップドファイル python パイプ subprocessを使えばとりあえず動いた。 ただし、書き込みが終わった後にflushが必要なため、子プロセス側で明示的にflushしていないケースではうまくいかなかった。 子 #include using namespace std; int main() { int a; cin >> a; cout 親 import subprocess as sub # shellを経由するときは shell = True のオプションを付ける p = sub.Popen(\"./a.out\", stdin=sub.PIPE, stdout=sub.PIPE, ) p.stdin.write(\"5\\n\".encode()) lines = p.stdout.read() print(lines) if p.poll() is None: p.terminate() "}}