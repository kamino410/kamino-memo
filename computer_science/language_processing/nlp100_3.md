# 言語処理100本ノック 2015

http://www.cl.ecei.tohoku.ac.jp/nlp100/

## 第3章 正規表現

Wikipediaの記事を以下のフォーマットで書き出したファイルjawiki-country.json.gzがある．

* 1行に1記事の情報がJSON形式で格納される
* 各行には記事名が"title"キーに，記事本文が"text"キーの辞書オブジェクトに格納され，そのオブジェクトがJSON形式で書き出される
* ファイル全体はgzipで圧縮される

[jawiki-country.json](./jawiki-country.json)

以下の処理を行うプログラムを作成せよ．

### 20. JSONデータの読み込み

Wikipedia記事のJSONファイルを読み込み，「イギリス」に関する記事本文を表示せよ．問題21-29では，ここで抽出した記事本文に対して実行せよ．

```py
import json

with open('jawiki-country.json') as f:
    for line in f:
        jdata = json.loads(line)
        if jdata["title"] == "イギリス":
            print(jdata["text"])
```

### 21. カテゴリ名を含む行を抽出

記事中でカテゴリ名を宣言している行を抽出せよ．

#### 補足

pythonの正規表現は基本は最長マッチ。
最短マッチさせたいときは`.+?`のように`?`を加える。

```py
import re

with open('jawiki-country.json') as f:
    for line in f:
        for m in re.findall(r'\[\[Category:.+?\]\]', line):
            print(m)
```

### 22. カテゴリ名の抽出

記事のカテゴリ名を（行単位ではなく名前で）抽出せよ．

```py
import re

with open('jawiki-country.json') as f:
    for line in f:
        for m in re.findall(r'(?<=\[\[Category:).+?(?=\]\])', line):
            print(m)
```

### 23. セクション構造

記事中に含まれるセクション名とそのレベル（例えば"== セクション名 =="なら1）を表示せよ．

#### 補足

pythonの正規表現でグループを定義した場合、グループごとに分割されたtupleが返ってくる。

```py
import re

with open('jawiki-country.json') as f:
    for line in f:
        for m in re.findall(r'(={2,})(.+?)\1', line):
            print(m[1] + '\t' + str(len(m[0])-1))
```

### 24. ファイル参照の抽出

記事から参照されているメディアファイルをすべて抜き出せ．

#### 補足

JSONに書かれたRedmine記法的なものなので、改行が平文字の`\n`で書かれている部分がある。

```py
import re

with open('jawiki-country.json') as f:
    for line in f:
        for m in re.findall(r'(ファイル|File):(.+?)[\|\]\\]', line):
            print(m[1])
```

### 25. テンプレートの抽出

記事中に含まれる「基礎情報」テンプレートのフィールド名と値を抽出し，辞書オブジェクトとして格納せよ．

```py
import re, json

res = {}
with open('jawiki-country.json') as f:
    for line in f:
        dic = {}
        for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line):
            for p in re.findall(r'\\n\|\s*(.+?)\s*=\s*(.*?)\\n\|', m[0]):
                dic[p[0]] = p[1]
        res[json.loads(line)['title']] = dic
```

### 26. 強調マークアップの除去

25の処理時に，テンプレートの値からMediaWikiの強調マークアップ（弱い強調，強調，強い強調のすべて）を除去してテキストに変換せよ（参考: マークアップ早見表）．

#### 補足

強調は`''hoge''`,`'''fuga'''`,`'''''piyo'''''`の3種類。

```py
import re, json

res = {}
with open('jawiki-country.json') as f:
    for line in f:
        dic = {}
        for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line):
            text = re.sub(r"'{2,}", '', m[0]) #強調表記の除去
            for p in re.findall(r'\\n\|\s*(.+?)\s*=\s*(.*?)\\n\|', text):
                dic[p[0]] = p[1]
        res[json.loads(line)['title']] = dic
```

### 27. 内部リンクの除去

26の処理に加えて，テンプレートの値からMediaWikiの内部リンクマークアップを除去し，テキストに変換せよ（参考: マークアップ早見表）．

#### 補足

* `[hoge]` -> hoge
* `[hoge|fuga]` -> fuga
* `[hoge#fuga|piyo]` -> fuga

```py
import re, json

res = {}
with open('jawiki-country.json') as f:
    for line in f:
        dic = {}
        for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line):
            #強調表記の除去
            text = re.sub(r"'{2,}", '', m[0])
            #内部リンクの除去
            text = re.sub(r'\[\[(?!ファイル:|File:)(((?!\]\]).)+?\|)?(.+?)\]\]', r'\3', text)
            for p in re.findall(r'\\n\|\s*(.+?)\s*=\s*(.*?)\\n\|', text):
                dic[p[0]] = p[1]
        res[json.loads(line)['title']] = dic
```

### 28. MediaWikiマークアップの除去

27の処理に加えて，テンプレートの値からMediaWikiマークアップを可能な限り除去し，国の基本情報を整形せよ．

```py
import re, json

res = {}
with open('jawiki-country.json') as f:
    for line in f:
        dic = {}
        for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line):
            #強調表記の除去
            text = re.sub(r"'{2,}", '', m[0])
            #内部リンク・画像情報の除去
            text = re.sub(r'\[\[(((?!\]\]).)+?\|)?([^\|]+?)\]\]', r'\3', text)
            #外部リンクの除去
            text = re.sub(r'\[http.+?\]', '', text)
            #htmlタグの除去
            text = re.sub(r'<.+?>', '', text)
            for p in re.findall(r'\\n\|\s*(.+?)\s*=\s*(.*?)\\n\|', text):
                dic[p[0]] = p[1]
        res[json.loads(line)['title']] = dic
#完全ではないけどとりあえずいいことにする
```

### 29. 国旗画像のURLを取得する

```py
import re, json, requests

res = {}
with open('jawiki-country.json') as f:
    for line in f:
        for m in re.findall(r'{{基礎情報(((?!{{).|({{.+?}}))+?)}}', line):
            for p in re.findall(r'\\n\|\s*(.+?)\s*=\s*(.*?)\\n\|', m[0]):
                if p[0] == '国旗画像' or p[0] == '国章画像':
                    filename = re.search(r':(.+?)\|', p[1])
                    if filename is not None:
                        print(json.loads(line)['title'] + '\t' + filename[1])
                        url = "https://en.wikipedia.org/w/api.php"
                        payload = {"action": "query",
                                   "titles": "File:{}".format(filename[1]),
                                   "prop": "imageinfo",
                                   "format": "json",
                                   "iiprop": "url"}

                        jdata = requests.get(url, params=payload).json()
                        print(re.search(r"'url'\s*:\s*'(.+?)'", str(jdata))[1])
```
